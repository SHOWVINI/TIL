{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"2jYXfX6z5SmX"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.linear_model import LogisticRegression\n","\n","cancer = load_breast_cancer()"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"GRo5xTew5JTP"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","\n","scaler = StandardScaler()\n","data_scaled = scaler.fit_transform(cancer.data)\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    data_scaled,\n","    cancer.target,\n","    test_size=0.3,\n","    random_state=0\n",")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":74},"executionInfo":{"elapsed":379,"status":"ok","timestamp":1722229924782,"user":{"displayName":"소민호","userId":"13788803923072454204"},"user_tz":-540},"id":"UKAr138_5TmH","outputId":"a5e4ef14-ce1c-4bb1-ccbd-bf773fce4c7f"},"outputs":[{"data":{"text/plain":["LogisticRegression()"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["lr_clf = LogisticRegression() # 기본 solver는 lbfgs\n","lr_clf.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"WI8OCPPF5yA3"},"source":["# 평가"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":364,"status":"ok","timestamp":1722230022725,"user":{"displayName":"소민호","userId":"13788803923072454204"},"user_tz":-540},"id":"dDBQuGYN59dA","outputId":"d0bbab26-5578-4766-bd64-1a1b6a0728ca"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy : 0.977, ROC_AUC : 0.972\n"]}],"source":["from sklearn.metrics import accuracy_score, roc_auc_score\n","\n","lr_pred = lr_clf.predict(X_test)\n","print(\"Accuracy : {:.3f}, ROC_AUC : {:.3f}\".format(accuracy_score(y_test, lr_pred), roc_auc_score(y_test, lr_pred)))"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":866,"status":"ok","timestamp":1722230144299,"user":{"displayName":"소민호","userId":"13788803923072454204"},"user_tz":-540},"id":"r7DktWNj6JVf","outputId":"c7e94094-2fb4-4a3a-d730-5d7acfb75c9e"},"outputs":[{"name":"stdout","output_type":"stream","text":["lbfgs\n","Accuracy : 0.977, ROC_AUC : 0.972\n","\n","liblinear\n","Accuracy : 0.982, ROC_AUC : 0.979\n","\n","newton-cg\n","Accuracy : 0.977, ROC_AUC : 0.972\n","\n","sag\n","Accuracy : 0.982, ROC_AUC : 0.979\n","\n","saga\n","Accuracy : 0.982, ROC_AUC : 0.979\n","\n"]}],"source":["# solver에 따른 성능 변화 측정\n","solvers = ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga']\n","\n","for solver in solvers:\n","  lr_clf = LogisticRegression(solver=solver, max_iter=600) # max_iter : 최적화 횟수\n","  lr_clf.fit(X_train, y_train)\n","\n","  lr_pred = lr_clf.predict(X_test)\n","\n","  print(solver)\n","  print(\"Accuracy : {:.3f}, ROC_AUC : {:.3f}\".format(accuracy_score(y_test, lr_pred), roc_auc_score(y_test, lr_pred)))\n","  print()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":603},"executionInfo":{"elapsed":1698,"status":"ok","timestamp":1722230195619,"user":{"displayName":"소민호","userId":"13788803923072454204"},"user_tz":-540},"id":"D3seJp3N6ne-","outputId":"11d0735f-14fa-463d-b337-d2b973b3c555"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","18 fits failed out of a total of 72.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","18 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n","    solver = _check_solver(self.solver, self.penalty, self.dual)\n","  File \"/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n","    raise ValueError(\n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.96485659 0.94555834 0.92261209        nan 0.97891024 0.97364708\n"," 0.96131997        nan 0.97539218 0.97539218 0.96660169        nan\n"," 0.97539218 0.97539218 0.96660169        nan 0.97011974 0.97011974\n"," 0.96662025        nan 0.96661097 0.96661097 0.96134781        nan]\n","  warnings.warn(\n"]},{"data":{"text/plain":["GridSearchCV(cv=3, estimator=LogisticRegression(),\n","             param_grid={'C': [0.01, 0.1, 1, 1, 5, 10], 'penalty': ['l2', 'l1'],\n","                         'solver': ['liblinear', 'lbfgs']},\n","             scoring='accuracy')"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# GridSearch\n","from sklearn.model_selection import GridSearchCV\n","\n","params={'solver':['liblinear', 'lbfgs'],\n","        'penalty':['l2', 'l1'],\n","        'C':[0.01, 0.1, 1, 1, 5, 10]}\n","\n","grid_clf = GridSearchCV(\n","    LogisticRegression(),\n","    param_grid=params,\n","    scoring='accuracy',\n","    cv=3\n",")\n","\n","grid_clf.fit(data_scaled, cancer.target)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":332,"status":"ok","timestamp":1722230206492,"user":{"displayName":"소민호","userId":"13788803923072454204"},"user_tz":-540},"id":"ACNXRvNt6zz1","outputId":"f1e566db-ee5c-443c-ec6d-80f1f26dfd18"},"outputs":[{"name":"stdout","output_type":"stream","text":["최적 하이퍼 파라미터:{'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}, 최적 평균 정확도:0.979\n"]}],"source":["print('최적 하이퍼 파라미터:{}, 최적 평균 정확도:{:.3f}'.format(grid_clf.best_params_, grid_clf.best_score_))"]},{"cell_type":"markdown","metadata":{"id":"Xwn0KyjG62zE"},"source":["### 다중 분류 전략\n","1. OVR (One Vs Rest) - OVA (One Vs All) ★★★★★\n","  - 클래스가 K개 존재하는 경우(K는 3이상) 1개의 클래스를 제외한 나머지 다른 클래스들을 K개 만들어 각각의 이진 분류를 수행\n","  - 이진 분류에대한 확률을 구하고, 그 확률이 제일 높은 상황을 최종 클래스로 판별\n","    - 0번 클래스에 대해서 `[1, 2]`클래스를 묶어준다. -> `0 vs [1, 2]`\n","    - 1번 클래스에 대해서 `[0, 2]`클래스를 묶어준다. -> `1 vs [0, 2]`\n","    - 2번 클래스에 대해서 `[0, 1]`클래스를 묶어준다. -> `2 vs [0, 1]`\n","\n","2. OVO ( One Vs One )\n","- 하나씩 하나씩 비교하는 분류기(모델)를 여러 개 만든다.\n","- `0 vs 1`, `0 vs 2`, `1 vs 2`\n","* `0 vs 1`, `0 vs 2`, `0 vs 3`, `1 vs 2`, `1 vs 3`, `2 vs 3`\n","  * 분류기 개수 K개의 클래스가 있다고 가정: $K\\times \\frac{K-1}{2}$ 개의 분류기 생성\n","\n","**보통 OVR 방법을 더 선호한다**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2P4STdFt7DoF"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TyNIBmpn70O7"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1J9WfxaY3Jl3-9vOHMBPuCTkQKzqVeuPC","timestamp":1722230996719}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"}},"nbformat":4,"nbformat_minor":0}
