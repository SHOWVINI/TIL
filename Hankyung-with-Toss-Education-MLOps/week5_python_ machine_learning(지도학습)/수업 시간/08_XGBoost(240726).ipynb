{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUl1EP16eRWa"
      },
      "source": [
        "## mac의 m시리즈에서는 XGBoost 실행을 못시킴. 이 파일 실행시킬 때는 구글 colab 사용해서 진행하기.\n",
        "## (240726 수업부터 앞으로 코랩으로 진행)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL6viNzwd-1U",
        "outputId": "3075e94b-f5d0-4fd3-92b1-7bbb178e72da"
      },
      "outputs": [],
      "source": [
        "# %pip install xgboost==1.5.0\n",
        "# %pip install pandas==1.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pOvPW4Sa1Av",
        "outputId": "bb8a41d2-63e0-4244-ab32-b6cc80931d6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.5.0\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "print(xgb.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "4kqwBsxQbSIt"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 코드 설명\n",
        "\n",
        "# import warnings\n",
        "# 이 줄은 파이썬의 표준 라이브러리 중 하나인 warnings 모듈을 가져옵니다.\n",
        "# warnings 모듈은 코드 실행 중에 발생할 수 있는 경고 메시지를 제어할 수 있게 해줍니다.\n",
        "# 경고 메시지는 코드의 잠재적인 문제를 알려주지만, 프로그램의 실행을 중단시키지는 않습니다.\n",
        "# 예를 들어, deprecated(사용 중단 예정)된 함수나 라이브러리를 사용할 때 경고 메시지가 출력될 수 있습니다.\n",
        "\n",
        "# warnings.filterwarnings('ignore')\n",
        "# 이 줄은 warnings 모듈의 filterwarnings 함수를 사용하여 특정 유형의 경고 메시지를 무시하도록 설정합니다.\n",
        "# 여기서 'ignore'는 경고 메시지를 무시하도록 설정하는 명령어입니다.\n",
        "\n",
        "# 왜 사용하나요?\n",
        "\n",
        "# 깨끗한 출력: 경고 메시지를 무시함으로써 프로그램 실행 중에 출력되는 불필요한 메시지를 제거하여, 출력 결과를 더 깔끔하게 볼 수 있습니다.\n",
        "# 불필요한 경고 무시: 특정 경고가 중요하지 않거나 이미 알고 있는 경우, 해당 경고를 무시함으로써 코드 실행에 방해가 되지 않게 할 수 있습니다.\n",
        "\n",
        "# 언제 사용하나요?\n",
        "\n",
        "# Deprecated 경고 무시: 오래된 라이브러리나 함수 사용 시 발생하는 경고를 무시하고 싶을 때.\n",
        "# 테스트 코드: 테스트 코드에서 경고 메시지가 많을 경우, 경고를 무시하고 싶을 때.\n",
        "# 일시적 해결: 특정 경고를 일시적으로 무시하고 나중에 해결하고자 할 때.\n",
        "\n",
        "# 주의사항\n",
        "\n",
        "# 중요 경고 무시 주의: 모든 경고를 무시하면 중요한 문제를 놓칠 수 있습니다. 꼭 필요한 경우에만 사용하세요.\n",
        "# 코드 리뷰: 팀 프로젝트에서 코드를 작성할 때는 다른 팀원과 상의하여 경고 무시 설정을 사용하세요. 경고를 무시하는 것이 좋은 해결책인지 판단이 필요합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "ScN3DVEibSLu",
        "outputId": "542a6e9a-8793-4e7a-994e-b4e568a1f027"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0        17.99         10.38          122.80     1001.0          0.11840   \n",
              "1        20.57         17.77          132.90     1326.0          0.08474   \n",
              "2        19.69         21.25          130.00     1203.0          0.10960   \n",
              "3        11.42         20.38           77.58      386.1          0.14250   \n",
              "4        20.29         14.34          135.10     1297.0          0.10030   \n",
              "\n",
              "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0           0.27760          0.3001              0.14710         0.2419   \n",
              "1           0.07864          0.0869              0.07017         0.1812   \n",
              "2           0.15990          0.1974              0.12790         0.2069   \n",
              "3           0.28390          0.2414              0.10520         0.2597   \n",
              "4           0.13280          0.1980              0.10430         0.1809   \n",
              "\n",
              "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
              "0                 0.07871  ...          17.33           184.60      2019.0   \n",
              "1                 0.05667  ...          23.41           158.80      1956.0   \n",
              "2                 0.05999  ...          25.53           152.50      1709.0   \n",
              "3                 0.09744  ...          26.50            98.87       567.7   \n",
              "4                 0.05883  ...          16.67           152.20      1575.0   \n",
              "\n",
              "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
              "0            0.1622             0.6656           0.7119                0.2654   \n",
              "1            0.1238             0.1866           0.2416                0.1860   \n",
              "2            0.1444             0.4245           0.4504                0.2430   \n",
              "3            0.2098             0.8663           0.6869                0.2575   \n",
              "4            0.1374             0.2050           0.4000                0.1625   \n",
              "\n",
              "   worst symmetry  worst fractal dimension  target  \n",
              "0          0.4601                  0.11890       0  \n",
              "1          0.2750                  0.08902       0  \n",
              "2          0.3613                  0.08758       0  \n",
              "3          0.6638                  0.17300       0  \n",
              "4          0.2364                  0.07678       0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "\n",
        "data_df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
        "data_df['target'] = cancer.target\n",
        "data_df.head()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# load_breast_cancer: 사이킷런의 데이터셋 모듈에서 유방암 데이터셋을 가져오는 함수입니다.\n",
        "# pandas as pd: 판다스 라이브러리를 pd라는 별칭으로 가져옵니다. 판다스는 데이터 조작과 분석을 위한 강력한 라이브러리입니다.\n",
        "\n",
        "# load_breast_cancer() 함수를 사용하여 유방암 데이터셋을 로드합니다. 이 함수는 사이킷런의 내장 데이터셋 중 하나인 유방암 데이터를 반환합니다.\n",
        "\n",
        "# cancer.data: 유방암 데이터셋의 특성(feature) 데이터를 포함합니다. 각 행은 하나의 데이터 포인트를 나타내며, 각 열은 하나의 특성을 나타냅니다.\n",
        "# cancer.feature_names: 특성의 이름을 포함하는 리스트입니다.\n",
        "# pd.DataFrame(): 특성 데이터를 포함하는 판다스 데이터프레임을 생성합니다. columns 매개변수를 사용하여 데이터프레임의 열 이름을 설정합니다.\n",
        "\n",
        "# cancer.target: 각 데이터 포인트의 레이블(0 또는 1)을 포함합니다. 0은 악성 종양, 1은 양성 종양을 나타냅니다.\n",
        "# data_df['target']: 데이터프레임에 'target'이라는 새로운 열을 추가하고, 각 데이터 포인트의 레이블을 할당합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-tRYqqgzbSOW"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터셋을 학습 세트와 테스트 세트로 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data_df.drop(\"target\", axis=1),  # 입력 데이터 (특성들)\n",
        "    data_df['target'],               # 출력 데이터 (레이블)\n",
        "    random_state=42                  # 무작위 분할을 위한 시드 값\n",
        ")\n",
        "\n",
        "# 학습 세트를 다시 학습 세트와 검증 세트로 분할\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train,                         # 학습 데이터 (특성들)\n",
        "    y_train,                         # 학습 데이터 (레이블)\n",
        "    random_state=42                  # 무작위 분할을 위한 시드 값\n",
        ")\n",
        "\n",
        "# 코드의 역할 요약\n",
        "\n",
        "# 1. 데이터셋을 학습 세트와 테스트 세트로 분할\n",
        "\n",
        "# data_df에서 'target' 열을 제외한 데이터(특성들)를 X_train과 X_test로 분할.\n",
        "# data_df['target']을 y_train과 y_test로 분할.\n",
        "# random_state=42: 무작위 분할을 재현 가능하게 하기 위해 시드 값 설정.\n",
        "\n",
        "# 2. 학습 세트를 다시 학습 세트와 검증 세트로 분할\n",
        "\n",
        "# X_train을 다시 X_train과 X_valid로 분할.\n",
        "# y_train을 다시 y_train과 y_valid로 분할.\n",
        "# random_state=42: 무작위 분할을 재현 가능하게 하기 위해 시드 값 설정.\n",
        "\n",
        "# 요약\n",
        "\n",
        "# X_train, y_train: 모델 학습에 사용되는 데이터.\n",
        "# X_valid, y_valid: 모델 검증에 사용되는 데이터.\n",
        "# X_test, y_test: 최종 모델 평가에 사용되는 데이터.\n",
        "# 이렇게 데이터를 나누면 학습, 검증, 테스트 단계에서 각각 다른 데이터 세트를 사용할 수 있어 모델의 성능을 보다 정확하게 평가할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-T0EHFfbSQV"
      },
      "source": [
        "# DMatrix 변환\n",
        "- 넘파이 배열, 판다스 데이터 프레임을 DMatrix로 변환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Co41F-6tdJN1",
        "outputId": "7fd9e846-cea9-4a0b-e149-abe020d81094"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1.5.0'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "LULc2t9ect9G"
      },
      "outputs": [],
      "source": [
        "# 학습, 검증, 테스트 데이터를 DMatrix 객체로 변환\n",
        "dtr = xgb.DMatrix(data=X_train, label=y_train)\n",
        "dval = xgb.DMatrix(data=X_valid, label=y_valid)\n",
        "dtest = xgb.DMatrix(data=X_test, label=y_test)\n",
        "\n",
        "# 이 코드는 XGBoost의 DMatrix 객체를 생성하는 예제입니다.\n",
        "# DMatrix는 XGBoost의 데이터 구조로, 학습, 검증 및 테스트 데이터를 효율적으로 관리하고 처리할 수 있게 해줍니다.\n",
        "\n",
        "\n",
        "# 1. DMatrix 객체 생성\n",
        "\n",
        "# X_train: 학습 데이터의 특성(features)을 나타냅니다.\n",
        "# y_train: 학습 데이터의 레이블(labels)을 나타냅니다.\n",
        "# xgb.DMatrix: XGBoost의 DMatrix 객체를 생성하는 함수입니다. 이 객체는 내부적으로 데이터와 레이블을 효율적으로 저장하고 처리할 수 있도록 합니다.\n",
        "# dtr: 학습 데이터를 위한 DMatrix 객체입니다.\n",
        "\n",
        "# 2. 검증 데이터에 대한 DMatrix 객체 생성\n",
        "# X_valid: 검증 데이터의 특성(features)을 나타냅니다.\n",
        "# y_valid: 검증 데이터의 레이블(labels)을 나타냅니다.\n",
        "# dval: 검증 데이터를 위한 DMatrix 객체입니다.\n",
        "\n",
        "# 3. 테스트 데이터에 대한 DMatrix 객체 생성\n",
        "\n",
        "# X_test: 테스트 데이터의 특성(features)을 나타냅니다.\n",
        "# y_test: 테스트 데이터의 레이블(labels)을 나타냅니다.\n",
        "# dtest: 테스트 데이터를 위한 DMatrix 객체입니다.\n",
        "\n",
        "# 요약\n",
        "\n",
        "# DMatrix: XGBoost에서 데이터를 효율적으로 관리하고 처리하기 위해 사용하는 데이터 구조입니다.\n",
        "\n",
        "# dtr: 학습 데이터를 위한 DMatrix 객체.\n",
        "# dval: 검증 데이터를 위한 DMatrix 객체.\n",
        "# dtest: 테스트 데이터를 위한 DMatrix 객체.\n",
        "\n",
        "# 이렇게 데이터를 DMatrix 객체로 변환하면, XGBoost 모델을 학습하고 평가할 때 데이터를 보다 효율적으로 사용할 수 있습니다.\n",
        "# DMatrix는 특히 대용량 데이터셋을 처리할 때 메모리 사용량을 최적화하고, 학습 속도를 향상시키는 데 도움이 됩니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5dIgnEqdDy1"
      },
      "source": [
        "# XGB 하이퍼 파라미터 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "2dDE9B6gfuRF"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    \"max_depth\": 3,\n",
        "    'eta': 0.05,\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'logloss'\n",
        "}\n",
        "\n",
        "# 최대 400회 훈련\n",
        "num_rounds = 400\n",
        "\n",
        "\n",
        "# 이 코드는 XGBoost 모델의 하이퍼파라미터를 설정하고, 모델 훈련을 최대 400회 반복하도록 지정합니다.\n",
        "\n",
        "# max_depth: 각 결정 트리의 최대 깊이를 지정합니다. 깊이가 깊을수록 모델이 더 복잡해지고 과적합될 가능성이 높아집니다. 여기서는 3으로 설정하여 과적합을 방지합니다.\n",
        "# eta: 학습률(learning rate)로, 각 단계에서 모델이 업데이트되는 정도를 제어합니다. 값이 작을수록 학습 속도가 느리지만 더 세밀하게 조정할 수 있습니다. 여기서는 0.05로 설정되었습니다.\n",
        "# objective: 학습의 목적을 정의합니다. 'binary'은 이진 분류 문제를 의미하며, 로지스틱 회귀를 사용합니다.\n",
        "# eval_metric: 평가 지표를 설정합니다. 'logloss'는 로그 손실(logarithmic loss)로, 예측의 불확실성을 측정하는 데 사용됩니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEkrgDRPe4gU"
      },
      "source": [
        "# 훈련"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "O8J6YhZ4gCKW",
        "outputId": "c4c56d4f-9958-40db-ce07-250aee3c726a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\ttrain-logloss:0.62706\teval-logloss:0.60229\n",
            "[1]\ttrain-logloss:0.59030\teval-logloss:0.57112\n",
            "[2]\ttrain-logloss:0.55534\teval-logloss:0.54548\n",
            "[3]\ttrain-logloss:0.52351\teval-logloss:0.52160\n",
            "[4]\ttrain-logloss:0.49440\teval-logloss:0.50040\n",
            "[5]\ttrain-logloss:0.46768\teval-logloss:0.48104\n",
            "[6]\ttrain-logloss:0.44391\teval-logloss:0.45909\n",
            "[7]\ttrain-logloss:0.42107\teval-logloss:0.44270\n",
            "[8]\ttrain-logloss:0.39994\teval-logloss:0.42712\n",
            "[9]\ttrain-logloss:0.38036\teval-logloss:0.41490\n",
            "[10]\ttrain-logloss:0.36265\teval-logloss:0.40124\n",
            "[11]\ttrain-logloss:0.34564\teval-logloss:0.39045\n",
            "[12]\ttrain-logloss:0.32978\teval-logloss:0.38058\n",
            "[13]\ttrain-logloss:0.31499\teval-logloss:0.37156\n",
            "[14]\ttrain-logloss:0.30116\teval-logloss:0.36372\n",
            "[15]\ttrain-logloss:0.28823\teval-logloss:0.35494\n",
            "[16]\ttrain-logloss:0.27603\teval-logloss:0.34791\n",
            "[17]\ttrain-logloss:0.26459\teval-logloss:0.34123\n",
            "[18]\ttrain-logloss:0.25401\teval-logloss:0.33128\n",
            "[19]\ttrain-logloss:0.24382\teval-logloss:0.32515\n",
            "[20]\ttrain-logloss:0.23430\teval-logloss:0.31550\n",
            "[21]\ttrain-logloss:0.22505\teval-logloss:0.30932\n",
            "[22]\ttrain-logloss:0.21647\teval-logloss:0.30441\n",
            "[23]\ttrain-logloss:0.20822\teval-logloss:0.29882\n",
            "[24]\ttrain-logloss:0.20046\teval-logloss:0.29302\n",
            "[25]\ttrain-logloss:0.19320\teval-logloss:0.28585\n",
            "[26]\ttrain-logloss:0.18627\teval-logloss:0.28214\n",
            "[27]\ttrain-logloss:0.17979\teval-logloss:0.27542\n",
            "[28]\ttrain-logloss:0.17360\teval-logloss:0.27101\n",
            "[29]\ttrain-logloss:0.16741\teval-logloss:0.26692\n",
            "[30]\ttrain-logloss:0.16191\teval-logloss:0.26138\n",
            "[31]\ttrain-logloss:0.15633\teval-logloss:0.25778\n",
            "[32]\ttrain-logloss:0.15130\teval-logloss:0.25384\n",
            "[33]\ttrain-logloss:0.14654\teval-logloss:0.24898\n",
            "[34]\ttrain-logloss:0.14187\teval-logloss:0.24565\n",
            "[35]\ttrain-logloss:0.13689\teval-logloss:0.24303\n",
            "[36]\ttrain-logloss:0.13260\teval-logloss:0.24008\n",
            "[37]\ttrain-logloss:0.12809\teval-logloss:0.23782\n",
            "[38]\ttrain-logloss:0.12440\teval-logloss:0.23332\n",
            "[39]\ttrain-logloss:0.12031\teval-logloss:0.23141\n",
            "[40]\ttrain-logloss:0.11645\teval-logloss:0.22918\n",
            "[41]\ttrain-logloss:0.11300\teval-logloss:0.22756\n",
            "[42]\ttrain-logloss:0.10967\teval-logloss:0.22503\n",
            "[43]\ttrain-logloss:0.10680\teval-logloss:0.22155\n",
            "[44]\ttrain-logloss:0.10377\teval-logloss:0.22021\n",
            "[45]\ttrain-logloss:0.10118\teval-logloss:0.21726\n",
            "[46]\ttrain-logloss:0.09843\teval-logloss:0.21614\n",
            "[47]\ttrain-logloss:0.09575\teval-logloss:0.21432\n",
            "[48]\ttrain-logloss:0.09319\teval-logloss:0.21245\n",
            "[49]\ttrain-logloss:0.09100\teval-logloss:0.20976\n",
            "[50]\ttrain-logloss:0.08869\teval-logloss:0.20898\n",
            "[51]\ttrain-logloss:0.08660\teval-logloss:0.20511\n",
            "[52]\ttrain-logloss:0.08440\teval-logloss:0.20432\n",
            "[53]\ttrain-logloss:0.08240\teval-logloss:0.20377\n",
            "[54]\ttrain-logloss:0.08044\teval-logloss:0.20226\n",
            "[55]\ttrain-logloss:0.07870\teval-logloss:0.20006\n",
            "[56]\ttrain-logloss:0.07679\teval-logloss:0.19792\n",
            "[57]\ttrain-logloss:0.07497\teval-logloss:0.19656\n",
            "[58]\ttrain-logloss:0.07316\teval-logloss:0.19591\n",
            "[59]\ttrain-logloss:0.07149\teval-logloss:0.19408\n",
            "[60]\ttrain-logloss:0.06986\teval-logloss:0.19181\n",
            "[61]\ttrain-logloss:0.06833\teval-logloss:0.19013\n",
            "[62]\ttrain-logloss:0.06680\teval-logloss:0.18879\n",
            "[63]\ttrain-logloss:0.06533\teval-logloss:0.18672\n",
            "[64]\ttrain-logloss:0.06395\teval-logloss:0.18380\n",
            "[65]\ttrain-logloss:0.06263\teval-logloss:0.18299\n",
            "[66]\ttrain-logloss:0.06136\teval-logloss:0.18226\n",
            "[67]\ttrain-logloss:0.06010\teval-logloss:0.18195\n",
            "[68]\ttrain-logloss:0.05888\teval-logloss:0.17940\n",
            "[69]\ttrain-logloss:0.05766\teval-logloss:0.17763\n",
            "[70]\ttrain-logloss:0.05657\teval-logloss:0.17679\n",
            "[71]\ttrain-logloss:0.05549\teval-logloss:0.17397\n",
            "[72]\ttrain-logloss:0.05440\teval-logloss:0.17225\n",
            "[73]\ttrain-logloss:0.05328\teval-logloss:0.17081\n",
            "[74]\ttrain-logloss:0.05233\teval-logloss:0.17037\n",
            "[75]\ttrain-logloss:0.05143\teval-logloss:0.17032\n",
            "[76]\ttrain-logloss:0.05041\teval-logloss:0.16916\n",
            "[77]\ttrain-logloss:0.04951\teval-logloss:0.16715\n",
            "[78]\ttrain-logloss:0.04857\teval-logloss:0.16607\n",
            "[79]\ttrain-logloss:0.04774\teval-logloss:0.16527\n",
            "[80]\ttrain-logloss:0.04686\teval-logloss:0.16428\n",
            "[81]\ttrain-logloss:0.04609\teval-logloss:0.16359\n",
            "[82]\ttrain-logloss:0.04516\teval-logloss:0.16234\n",
            "[83]\ttrain-logloss:0.04440\teval-logloss:0.16062\n",
            "[84]\ttrain-logloss:0.04364\teval-logloss:0.15869\n",
            "[85]\ttrain-logloss:0.04297\teval-logloss:0.15973\n",
            "[86]\ttrain-logloss:0.04227\teval-logloss:0.15865\n",
            "[87]\ttrain-logloss:0.04157\teval-logloss:0.15869\n",
            "[88]\ttrain-logloss:0.04085\teval-logloss:0.15693\n",
            "[89]\ttrain-logloss:0.04020\teval-logloss:0.15536\n",
            "[90]\ttrain-logloss:0.03937\teval-logloss:0.15452\n",
            "[91]\ttrain-logloss:0.03875\teval-logloss:0.15426\n",
            "[92]\ttrain-logloss:0.03815\teval-logloss:0.15260\n",
            "[93]\ttrain-logloss:0.03762\teval-logloss:0.15360\n",
            "[94]\ttrain-logloss:0.03706\teval-logloss:0.15268\n",
            "[95]\ttrain-logloss:0.03638\teval-logloss:0.15255\n",
            "[96]\ttrain-logloss:0.03574\teval-logloss:0.15246\n",
            "[97]\ttrain-logloss:0.03522\teval-logloss:0.15229\n",
            "[98]\ttrain-logloss:0.03472\teval-logloss:0.15128\n",
            "[99]\ttrain-logloss:0.03419\teval-logloss:0.15086\n",
            "[100]\ttrain-logloss:0.03369\teval-logloss:0.15006\n",
            "[101]\ttrain-logloss:0.03313\teval-logloss:0.15001\n",
            "[102]\ttrain-logloss:0.03267\teval-logloss:0.15087\n",
            "[103]\ttrain-logloss:0.03223\teval-logloss:0.14968\n",
            "[104]\ttrain-logloss:0.03171\teval-logloss:0.14908\n",
            "[105]\ttrain-logloss:0.03113\teval-logloss:0.14851\n",
            "[106]\ttrain-logloss:0.03064\teval-logloss:0.14795\n",
            "[107]\ttrain-logloss:0.03022\teval-logloss:0.14782\n",
            "[108]\ttrain-logloss:0.02980\teval-logloss:0.14645\n",
            "[109]\ttrain-logloss:0.02945\teval-logloss:0.14536\n",
            "[110]\ttrain-logloss:0.02898\teval-logloss:0.14537\n",
            "[111]\ttrain-logloss:0.02863\teval-logloss:0.14538\n",
            "[112]\ttrain-logloss:0.02825\teval-logloss:0.14529\n",
            "[113]\ttrain-logloss:0.02793\teval-logloss:0.14437\n",
            "[114]\ttrain-logloss:0.02757\teval-logloss:0.14367\n",
            "[115]\ttrain-logloss:0.02714\teval-logloss:0.14343\n",
            "[116]\ttrain-logloss:0.02675\teval-logloss:0.14302\n",
            "[117]\ttrain-logloss:0.02641\teval-logloss:0.14309\n",
            "[118]\ttrain-logloss:0.02605\teval-logloss:0.14254\n",
            "[119]\ttrain-logloss:0.02572\teval-logloss:0.14216\n",
            "[120]\ttrain-logloss:0.02540\teval-logloss:0.14200\n",
            "[121]\ttrain-logloss:0.02509\teval-logloss:0.14142\n",
            "[122]\ttrain-logloss:0.02474\teval-logloss:0.14126\n",
            "[123]\ttrain-logloss:0.02444\teval-logloss:0.14093\n",
            "[124]\ttrain-logloss:0.02419\teval-logloss:0.14100\n",
            "[125]\ttrain-logloss:0.02393\teval-logloss:0.14106\n",
            "[126]\ttrain-logloss:0.02361\teval-logloss:0.14092\n",
            "[127]\ttrain-logloss:0.02330\teval-logloss:0.13985\n",
            "[128]\ttrain-logloss:0.02303\teval-logloss:0.13964\n",
            "[129]\ttrain-logloss:0.02283\teval-logloss:0.13968\n",
            "[130]\ttrain-logloss:0.02255\teval-logloss:0.13935\n",
            "[131]\ttrain-logloss:0.02227\teval-logloss:0.13834\n",
            "[132]\ttrain-logloss:0.02200\teval-logloss:0.13746\n",
            "[133]\ttrain-logloss:0.02175\teval-logloss:0.13638\n",
            "[134]\ttrain-logloss:0.02158\teval-logloss:0.13635\n",
            "[135]\ttrain-logloss:0.02140\teval-logloss:0.13693\n",
            "[136]\ttrain-logloss:0.02111\teval-logloss:0.13712\n",
            "[137]\ttrain-logloss:0.02095\teval-logloss:0.13729\n",
            "[138]\ttrain-logloss:0.02077\teval-logloss:0.13735\n",
            "[139]\ttrain-logloss:0.02054\teval-logloss:0.13719\n",
            "[140]\ttrain-logloss:0.02038\teval-logloss:0.13685\n",
            "[141]\ttrain-logloss:0.02023\teval-logloss:0.13702\n",
            "[142]\ttrain-logloss:0.02007\teval-logloss:0.13754\n",
            "[143]\ttrain-logloss:0.01985\teval-logloss:0.13741\n",
            "[144]\ttrain-logloss:0.01974\teval-logloss:0.13682\n",
            "[145]\ttrain-logloss:0.01960\teval-logloss:0.13700\n",
            "[146]\ttrain-logloss:0.01945\teval-logloss:0.13705\n",
            "[147]\ttrain-logloss:0.01922\teval-logloss:0.13673\n",
            "[148]\ttrain-logloss:0.01912\teval-logloss:0.13585\n",
            "[149]\ttrain-logloss:0.01894\teval-logloss:0.13520\n",
            "[150]\ttrain-logloss:0.01879\teval-logloss:0.13504\n",
            "[151]\ttrain-logloss:0.01862\teval-logloss:0.13449\n",
            "[152]\ttrain-logloss:0.01850\teval-logloss:0.13447\n",
            "[153]\ttrain-logloss:0.01840\teval-logloss:0.13394\n",
            "[154]\ttrain-logloss:0.01827\teval-logloss:0.13402\n",
            "[155]\ttrain-logloss:0.01818\teval-logloss:0.13351\n",
            "[156]\ttrain-logloss:0.01801\teval-logloss:0.13339\n",
            "[157]\ttrain-logloss:0.01790\teval-logloss:0.13298\n",
            "[158]\ttrain-logloss:0.01777\teval-logloss:0.13305\n",
            "[159]\ttrain-logloss:0.01762\teval-logloss:0.13246\n",
            "[160]\ttrain-logloss:0.01751\teval-logloss:0.13178\n",
            "[161]\ttrain-logloss:0.01739\teval-logloss:0.13187\n",
            "[162]\ttrain-logloss:0.01729\teval-logloss:0.13196\n",
            "[163]\ttrain-logloss:0.01714\teval-logloss:0.13149\n",
            "[164]\ttrain-logloss:0.01704\teval-logloss:0.13161\n",
            "[165]\ttrain-logloss:0.01696\teval-logloss:0.13135\n",
            "[166]\ttrain-logloss:0.01681\teval-logloss:0.13125\n",
            "[167]\ttrain-logloss:0.01671\teval-logloss:0.13060\n",
            "[168]\ttrain-logloss:0.01661\teval-logloss:0.13023\n",
            "[169]\ttrain-logloss:0.01648\teval-logloss:0.12979\n",
            "[170]\ttrain-logloss:0.01640\teval-logloss:0.12955\n",
            "[171]\ttrain-logloss:0.01627\teval-logloss:0.12933\n",
            "[172]\ttrain-logloss:0.01612\teval-logloss:0.12901\n",
            "[173]\ttrain-logloss:0.01603\teval-logloss:0.12926\n",
            "[174]\ttrain-logloss:0.01594\teval-logloss:0.12937\n",
            "[175]\ttrain-logloss:0.01584\teval-logloss:0.12922\n",
            "[176]\ttrain-logloss:0.01576\teval-logloss:0.12899\n",
            "[177]\ttrain-logloss:0.01568\teval-logloss:0.12876\n",
            "[178]\ttrain-logloss:0.01556\teval-logloss:0.12866\n",
            "[179]\ttrain-logloss:0.01547\teval-logloss:0.12876\n",
            "[180]\ttrain-logloss:0.01539\teval-logloss:0.12815\n",
            "[181]\ttrain-logloss:0.01530\teval-logloss:0.12839\n",
            "[182]\ttrain-logloss:0.01521\teval-logloss:0.12850\n",
            "[183]\ttrain-logloss:0.01515\teval-logloss:0.12779\n",
            "[184]\ttrain-logloss:0.01505\teval-logloss:0.12745\n",
            "[185]\ttrain-logloss:0.01497\teval-logloss:0.12688\n",
            "[186]\ttrain-logloss:0.01485\teval-logloss:0.12660\n",
            "[187]\ttrain-logloss:0.01477\teval-logloss:0.12671\n",
            "[188]\ttrain-logloss:0.01469\teval-logloss:0.12658\n",
            "[189]\ttrain-logloss:0.01461\teval-logloss:0.12668\n",
            "[190]\ttrain-logloss:0.01454\teval-logloss:0.12649\n",
            "[191]\ttrain-logloss:0.01446\teval-logloss:0.12630\n",
            "[192]\ttrain-logloss:0.01438\teval-logloss:0.12594\n",
            "[193]\ttrain-logloss:0.01433\teval-logloss:0.12588\n",
            "[194]\ttrain-logloss:0.01425\teval-logloss:0.12543\n",
            "[195]\ttrain-logloss:0.01417\teval-logloss:0.12511\n",
            "[196]\ttrain-logloss:0.01406\teval-logloss:0.12484\n",
            "[197]\ttrain-logloss:0.01399\teval-logloss:0.12464\n",
            "[198]\ttrain-logloss:0.01392\teval-logloss:0.12410\n",
            "[199]\ttrain-logloss:0.01385\teval-logloss:0.12433\n",
            "[200]\ttrain-logloss:0.01375\teval-logloss:0.12409\n",
            "[201]\ttrain-logloss:0.01367\teval-logloss:0.12418\n",
            "[202]\ttrain-logloss:0.01364\teval-logloss:0.12405\n",
            "[203]\ttrain-logloss:0.01358\teval-logloss:0.12388\n",
            "[204]\ttrain-logloss:0.01348\teval-logloss:0.12365\n",
            "[205]\ttrain-logloss:0.01340\teval-logloss:0.12355\n",
            "[206]\ttrain-logloss:0.01335\teval-logloss:0.12338\n",
            "[207]\ttrain-logloss:0.01329\teval-logloss:0.12318\n",
            "[208]\ttrain-logloss:0.01323\teval-logloss:0.12291\n",
            "[209]\ttrain-logloss:0.01316\teval-logloss:0.12275\n",
            "[210]\ttrain-logloss:0.01309\teval-logloss:0.12233\n",
            "[211]\ttrain-logloss:0.01304\teval-logloss:0.12172\n",
            "[212]\ttrain-logloss:0.01295\teval-logloss:0.12150\n",
            "[213]\ttrain-logloss:0.01288\teval-logloss:0.12140\n",
            "[214]\ttrain-logloss:0.01283\teval-logloss:0.12080\n",
            "[215]\ttrain-logloss:0.01276\teval-logloss:0.12091\n",
            "[216]\ttrain-logloss:0.01271\teval-logloss:0.12109\n",
            "[217]\ttrain-logloss:0.01266\teval-logloss:0.12065\n",
            "[218]\ttrain-logloss:0.01258\teval-logloss:0.12045\n",
            "[219]\ttrain-logloss:0.01251\teval-logloss:0.12055\n",
            "[220]\ttrain-logloss:0.01246\teval-logloss:0.11997\n",
            "[221]\ttrain-logloss:0.01241\teval-logloss:0.12014\n",
            "[222]\ttrain-logloss:0.01236\teval-logloss:0.11957\n",
            "[223]\ttrain-logloss:0.01230\teval-logloss:0.11968\n",
            "[224]\ttrain-logloss:0.01227\teval-logloss:0.11989\n",
            "[225]\ttrain-logloss:0.01223\teval-logloss:0.11933\n",
            "[226]\ttrain-logloss:0.01215\teval-logloss:0.11915\n",
            "[227]\ttrain-logloss:0.01210\teval-logloss:0.11876\n",
            "[228]\ttrain-logloss:0.01204\teval-logloss:0.11886\n",
            "[229]\ttrain-logloss:0.01199\teval-logloss:0.11868\n",
            "[230]\ttrain-logloss:0.01195\teval-logloss:0.11839\n",
            "[231]\ttrain-logloss:0.01193\teval-logloss:0.11860\n",
            "[232]\ttrain-logloss:0.01187\teval-logloss:0.11822\n",
            "[233]\ttrain-logloss:0.01183\teval-logloss:0.11804\n",
            "[234]\ttrain-logloss:0.01179\teval-logloss:0.11759\n",
            "[235]\ttrain-logloss:0.01175\teval-logloss:0.11731\n",
            "[236]\ttrain-logloss:0.01170\teval-logloss:0.11695\n",
            "[237]\ttrain-logloss:0.01167\teval-logloss:0.11716\n",
            "[238]\ttrain-logloss:0.01161\teval-logloss:0.11698\n",
            "[239]\ttrain-logloss:0.01155\teval-logloss:0.11669\n",
            "[240]\ttrain-logloss:0.01152\teval-logloss:0.11642\n",
            "[241]\ttrain-logloss:0.01149\teval-logloss:0.11662\n",
            "[242]\ttrain-logloss:0.01146\teval-logloss:0.11635\n",
            "[243]\ttrain-logloss:0.01142\teval-logloss:0.11635\n",
            "[244]\ttrain-logloss:0.01137\teval-logloss:0.11630\n",
            "[245]\ttrain-logloss:0.01131\teval-logloss:0.11603\n",
            "[246]\ttrain-logloss:0.01127\teval-logloss:0.11589\n",
            "[247]\ttrain-logloss:0.01125\teval-logloss:0.11592\n",
            "[248]\ttrain-logloss:0.01122\teval-logloss:0.11578\n",
            "[249]\ttrain-logloss:0.01117\teval-logloss:0.11574\n",
            "[250]\ttrain-logloss:0.01113\teval-logloss:0.11574\n",
            "[251]\ttrain-logloss:0.01111\teval-logloss:0.11571\n",
            "[252]\ttrain-logloss:0.01106\teval-logloss:0.11545\n",
            "[253]\ttrain-logloss:0.01103\teval-logloss:0.11504\n",
            "[254]\ttrain-logloss:0.01101\teval-logloss:0.11507\n",
            "[255]\ttrain-logloss:0.01097\teval-logloss:0.11507\n",
            "[256]\ttrain-logloss:0.01093\teval-logloss:0.11503\n",
            "[257]\ttrain-logloss:0.01091\teval-logloss:0.11476\n",
            "[258]\ttrain-logloss:0.01089\teval-logloss:0.11449\n",
            "[259]\ttrain-logloss:0.01087\teval-logloss:0.11446\n",
            "[260]\ttrain-logloss:0.01082\teval-logloss:0.11442\n",
            "[261]\ttrain-logloss:0.01080\teval-logloss:0.11446\n",
            "[262]\ttrain-logloss:0.01078\teval-logloss:0.11454\n",
            "[263]\ttrain-logloss:0.01077\teval-logloss:0.11434\n",
            "[264]\ttrain-logloss:0.01075\teval-logloss:0.11457\n",
            "[265]\ttrain-logloss:0.01073\teval-logloss:0.11431\n",
            "[266]\ttrain-logloss:0.01071\teval-logloss:0.11404\n",
            "[267]\ttrain-logloss:0.01069\teval-logloss:0.11401\n",
            "[268]\ttrain-logloss:0.01067\teval-logloss:0.11405\n",
            "[269]\ttrain-logloss:0.01065\teval-logloss:0.11413\n",
            "[270]\ttrain-logloss:0.01063\teval-logloss:0.11436\n",
            "[271]\ttrain-logloss:0.01061\teval-logloss:0.11410\n",
            "[272]\ttrain-logloss:0.01059\teval-logloss:0.11409\n",
            "[273]\ttrain-logloss:0.01058\teval-logloss:0.11417\n",
            "[274]\ttrain-logloss:0.01056\teval-logloss:0.11440\n",
            "[275]\ttrain-logloss:0.01054\teval-logloss:0.11413\n",
            "[276]\ttrain-logloss:0.01052\teval-logloss:0.11410\n",
            "[277]\ttrain-logloss:0.01050\teval-logloss:0.11391\n",
            "[278]\ttrain-logloss:0.01048\teval-logloss:0.11395\n",
            "[279]\ttrain-logloss:0.01047\teval-logloss:0.11417\n",
            "[280]\ttrain-logloss:0.01045\teval-logloss:0.11391\n",
            "[281]\ttrain-logloss:0.01043\teval-logloss:0.11366\n",
            "[282]\ttrain-logloss:0.01041\teval-logloss:0.11388\n",
            "[283]\ttrain-logloss:0.01039\teval-logloss:0.11396\n",
            "[284]\ttrain-logloss:0.01038\teval-logloss:0.11404\n",
            "[285]\ttrain-logloss:0.01036\teval-logloss:0.11428\n",
            "[286]\ttrain-logloss:0.01034\teval-logloss:0.11403\n",
            "[287]\ttrain-logloss:0.01032\teval-logloss:0.11377\n",
            "[288]\ttrain-logloss:0.01031\teval-logloss:0.11375\n",
            "[289]\ttrain-logloss:0.01029\teval-logloss:0.11397\n",
            "[290]\ttrain-logloss:0.01027\teval-logloss:0.11405\n",
            "[291]\ttrain-logloss:0.01025\teval-logloss:0.11380\n",
            "[292]\ttrain-logloss:0.01024\teval-logloss:0.11379\n",
            "[293]\ttrain-logloss:0.01022\teval-logloss:0.11403\n",
            "[294]\ttrain-logloss:0.01020\teval-logloss:0.11378\n",
            "[295]\ttrain-logloss:0.01019\teval-logloss:0.11386\n",
            "[296]\ttrain-logloss:0.01017\teval-logloss:0.11390\n",
            "[297]\ttrain-logloss:0.01015\teval-logloss:0.11387\n",
            "[298]\ttrain-logloss:0.01014\teval-logloss:0.11369\n",
            "[299]\ttrain-logloss:0.01012\teval-logloss:0.11391\n",
            "[300]\ttrain-logloss:0.01010\teval-logloss:0.11366\n",
            "[301]\ttrain-logloss:0.01009\teval-logloss:0.11374\n",
            "[302]\ttrain-logloss:0.01007\teval-logloss:0.11396\n",
            "[303]\ttrain-logloss:0.01005\teval-logloss:0.11371\n",
            "[304]\ttrain-logloss:0.01004\teval-logloss:0.11379\n",
            "[305]\ttrain-logloss:0.01002\teval-logloss:0.11401\n",
            "[306]\ttrain-logloss:0.01000\teval-logloss:0.11376\n",
            "[307]\ttrain-logloss:0.00999\teval-logloss:0.11353\n",
            "[308]\ttrain-logloss:0.00997\teval-logloss:0.11357\n",
            "[309]\ttrain-logloss:0.00996\teval-logloss:0.11354\n",
            "[310]\ttrain-logloss:0.00994\teval-logloss:0.11376\n",
            "[311]\ttrain-logloss:0.00992\teval-logloss:0.11384\n",
            "[312]\ttrain-logloss:0.00991\teval-logloss:0.11360\n",
            "[313]\ttrain-logloss:0.00989\teval-logloss:0.11336\n",
            "[314]\ttrain-logloss:0.00988\teval-logloss:0.11358\n",
            "[315]\ttrain-logloss:0.00986\teval-logloss:0.11366\n",
            "[316]\ttrain-logloss:0.00985\teval-logloss:0.11348\n",
            "[317]\ttrain-logloss:0.00983\teval-logloss:0.11370\n",
            "[318]\ttrain-logloss:0.00981\teval-logloss:0.11346\n",
            "[319]\ttrain-logloss:0.00980\teval-logloss:0.11350\n",
            "[320]\ttrain-logloss:0.00978\teval-logloss:0.11348\n",
            "[321]\ttrain-logloss:0.00977\teval-logloss:0.11348\n",
            "[322]\ttrain-logloss:0.00975\teval-logloss:0.11356\n",
            "[323]\ttrain-logloss:0.00974\teval-logloss:0.11333\n",
            "[324]\ttrain-logloss:0.00972\teval-logloss:0.11354\n",
            "[325]\ttrain-logloss:0.00971\teval-logloss:0.11330\n",
            "[326]\ttrain-logloss:0.00969\teval-logloss:0.11352\n",
            "[327]\ttrain-logloss:0.00968\teval-logloss:0.11360\n",
            "[328]\ttrain-logloss:0.00966\teval-logloss:0.11336\n",
            "[329]\ttrain-logloss:0.00965\teval-logloss:0.11357\n",
            "[330]\ttrain-logloss:0.00963\teval-logloss:0.11365\n",
            "[331]\ttrain-logloss:0.00962\teval-logloss:0.11342\n",
            "[332]\ttrain-logloss:0.00960\teval-logloss:0.11341\n",
            "[333]\ttrain-logloss:0.00959\teval-logloss:0.11345\n",
            "[334]\ttrain-logloss:0.00958\teval-logloss:0.11328\n",
            "[335]\ttrain-logloss:0.00956\teval-logloss:0.11309\n",
            "[336]\ttrain-logloss:0.00955\teval-logloss:0.11330\n",
            "[337]\ttrain-logloss:0.00953\teval-logloss:0.11338\n",
            "[338]\ttrain-logloss:0.00952\teval-logloss:0.11318\n",
            "[339]\ttrain-logloss:0.00950\teval-logloss:0.11323\n",
            "[340]\ttrain-logloss:0.00949\teval-logloss:0.11321\n",
            "[341]\ttrain-logloss:0.00948\teval-logloss:0.11299\n",
            "[342]\ttrain-logloss:0.00946\teval-logloss:0.11320\n",
            "[343]\ttrain-logloss:0.00945\teval-logloss:0.11328\n",
            "[344]\ttrain-logloss:0.00943\teval-logloss:0.11305\n",
            "[345]\ttrain-logloss:0.00942\teval-logloss:0.11326\n",
            "[346]\ttrain-logloss:0.00941\teval-logloss:0.11334\n",
            "[347]\ttrain-logloss:0.00939\teval-logloss:0.11315\n",
            "[348]\ttrain-logloss:0.00938\teval-logloss:0.11333\n",
            "[349]\ttrain-logloss:0.00936\teval-logloss:0.11354\n",
            "[350]\ttrain-logloss:0.00935\teval-logloss:0.11332\n",
            "[351]\ttrain-logloss:0.00934\teval-logloss:0.11331\n",
            "[352]\ttrain-logloss:0.00932\teval-logloss:0.11335\n",
            "[353]\ttrain-logloss:0.00931\teval-logloss:0.11317\n",
            "[354]\ttrain-logloss:0.00930\teval-logloss:0.11320\n",
            "[355]\ttrain-logloss:0.00928\teval-logloss:0.11324\n",
            "[356]\ttrain-logloss:0.00927\teval-logloss:0.11323\n",
            "[357]\ttrain-logloss:0.00926\teval-logloss:0.11302\n",
            "[358]\ttrain-logloss:0.00924\teval-logloss:0.11309\n",
            "[359]\ttrain-logloss:0.00923\teval-logloss:0.11330\n",
            "[360]\ttrain-logloss:0.00922\teval-logloss:0.11337\n",
            "[361]\ttrain-logloss:0.00920\teval-logloss:0.11319\n",
            "[362]\ttrain-logloss:0.00919\teval-logloss:0.11340\n",
            "[363]\ttrain-logloss:0.00918\teval-logloss:0.11318\n",
            "[364]\ttrain-logloss:0.00916\teval-logloss:0.11326\n",
            "[365]\ttrain-logloss:0.00915\teval-logloss:0.11325\n",
            "[366]\ttrain-logloss:0.00914\teval-logloss:0.11330\n",
            "[367]\ttrain-logloss:0.00913\teval-logloss:0.11309\n",
            "[368]\ttrain-logloss:0.00911\teval-logloss:0.11288\n",
            "[369]\ttrain-logloss:0.00910\teval-logloss:0.11291\n",
            "[370]\ttrain-logloss:0.00909\teval-logloss:0.11296\n",
            "[371]\ttrain-logloss:0.00908\teval-logloss:0.11296\n",
            "[372]\ttrain-logloss:0.00906\teval-logloss:0.11278\n",
            "[373]\ttrain-logloss:0.00905\teval-logloss:0.11285\n",
            "[374]\ttrain-logloss:0.00904\teval-logloss:0.11290\n",
            "[375]\ttrain-logloss:0.00903\teval-logloss:0.11270\n",
            "[376]\ttrain-logloss:0.00901\teval-logloss:0.11269\n",
            "[377]\ttrain-logloss:0.00900\teval-logloss:0.11272\n",
            "[378]\ttrain-logloss:0.00899\teval-logloss:0.11255\n",
            "[379]\ttrain-logloss:0.00898\teval-logloss:0.11272\n",
            "[380]\ttrain-logloss:0.00897\teval-logloss:0.11279\n",
            "[381]\ttrain-logloss:0.00895\teval-logloss:0.11259\n",
            "[382]\ttrain-logloss:0.00894\teval-logloss:0.11276\n",
            "[383]\ttrain-logloss:0.00893\teval-logloss:0.11284\n",
            "[384]\ttrain-logloss:0.00892\teval-logloss:0.11289\n",
            "[385]\ttrain-logloss:0.00891\teval-logloss:0.11269\n",
            "[386]\ttrain-logloss:0.00890\teval-logloss:0.11272\n",
            "[387]\ttrain-logloss:0.00888\teval-logloss:0.11252\n",
            "[388]\ttrain-logloss:0.00887\teval-logloss:0.11252\n",
            "[389]\ttrain-logloss:0.00886\teval-logloss:0.11257\n",
            "[390]\ttrain-logloss:0.00885\teval-logloss:0.11240\n",
            "[391]\ttrain-logloss:0.00884\teval-logloss:0.11247\n",
            "[392]\ttrain-logloss:0.00883\teval-logloss:0.11247\n",
            "[393]\ttrain-logloss:0.00881\teval-logloss:0.11253\n",
            "[394]\ttrain-logloss:0.00880\teval-logloss:0.11233\n",
            "[395]\ttrain-logloss:0.00879\teval-logloss:0.11247\n",
            "[396]\ttrain-logloss:0.00878\teval-logloss:0.11255\n",
            "[397]\ttrain-logloss:0.00877\teval-logloss:0.11255\n",
            "[398]\ttrain-logloss:0.00876\teval-logloss:0.11235\n",
            "[399]\ttrain-logloss:0.00875\teval-logloss:0.11238\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'num_parallel_tree'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[33], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m eval_list \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     (dtr, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      3\u001b[0m     (dval, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m ]\n\u001b[0;32m----> 6\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 하이퍼 파라미터\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 최대 학습 횟수\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 성능 개선이 50 라운드 이내에 이루어지지 않으면 학습 중단\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 평가 세트 지정\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/xgboost/training.py:188\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(params, dtrain, num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, evals\u001b[38;5;241m=\u001b[39m(), obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, feval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    116\u001b[0m           maximize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, evals_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    117\u001b[0m           verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xgb_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# pylint: disable=too-many-statements,too-many-branches, attribute-defined-outside-init\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train a booster with given parameters.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    Booster : a trained booster model\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m     bst \u001b[38;5;241m=\u001b[39m \u001b[43m_train_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxgb_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bst\n",
            "File \u001b[0;32m/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/xgboost/training.py:93\u001b[0m, in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     88\u001b[0m     evals_result\u001b[38;5;241m.\u001b[39mupdate(callbacks\u001b[38;5;241m.\u001b[39mhistory)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# These should be moved into callback functions `after_training`, but until old\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# callbacks are removed, the train function is the only place for setting the\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# attributes.\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m num_parallel_tree, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_get_booster_layer_trees\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bst\u001b[38;5;241m.\u001b[39mattr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_score\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     bst\u001b[38;5;241m.\u001b[39mbest_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(bst\u001b[38;5;241m.\u001b[39mattr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_score\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
            "File \u001b[0;32m/opt/anaconda3/envs/ml-env/lib/python3.8/site-packages/xgboost/core.py:1271\u001b[0m, in \u001b[0;36m_get_booster_layer_trees\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m   1264\u001b[0m     num_parallel_tree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\n\u001b[1;32m   1265\u001b[0m         config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearner\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgradient_booster\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgbtree\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgbtree_train_param\u001b[39m\u001b[38;5;124m\"\u001b[39m][\n\u001b[1;32m   1266\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_parallel_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1267\u001b[0m         ]\n\u001b[1;32m   1268\u001b[0m     )\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m booster \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgbtree\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1270\u001b[0m     num_parallel_tree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\n\u001b[0;32m-> 1271\u001b[0m         \u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlearner\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgradient_booster\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgbtree_train_param\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_parallel_tree\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1274\u001b[0m     )\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown booster: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbooster\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'num_parallel_tree'"
          ]
        }
      ],
      "source": [
        "eval_list = [\n",
        "    (dtr, 'train'),\n",
        "    (dval, 'eval')\n",
        "]\n",
        "\n",
        "xgb_model = xgb.train(\n",
        "    params=params, # 하이퍼 파라미터\n",
        "    dtrain=dtr,\n",
        "    num_boost_round=num_rounds, # 최대 학습 횟수\n",
        "    early_stopping_rounds=50, # 성능 개선이 50 라운드 이내에 이루어지지 않으면 학습 중단\n",
        "    evals=eval_list # 평가 세트 지정\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ5yqWevmq0x",
        "outputId": "97f93b7e-048f-4921-9659-a8e2bcbda2e9"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'xgb_model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m pred_props \u001b[38;5;241m=\u001b[39m \u001b[43mxgb_model\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(dtest)\n\u001b[1;32m      4\u001b[0m pred_props[:\u001b[38;5;241m10\u001b[39m] \u001b[38;5;66;03m# 양성 클래스의 확률\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'xgb_model' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "pred_props = xgb_model.predict(dtest)\n",
        "pred_props[:10] # 양성 클래스의 확률"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adnRDOIEmqyp",
        "outputId": "490316b6-6ba0-4a5e-a5c2-2fdd0f352919"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 0, 0, 1, 1, 0, 0, 1, 0, 1]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "threshold = 0.5\n",
        "\n",
        "preds = [1 if x > threshold else 0 for x in pred_props ]\n",
        "preds[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg7XIWkvkLdn"
      },
      "source": [
        "# XGBoost - Scikit Learn Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkH6ORLPmquA"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "l1VMW1Qzmqrn",
        "outputId": "e0780f27-8aec-4985-b641-ba5c0e4e4ef7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric='logloss',\n",
              "              feature_types=None, gamma=None, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
              "              max_leaves=None, min_child_weight=None, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=400,\n",
              "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xgb_clf = XGBClassifier(\n",
        "    n_estimators=400, # 학습 횟수\n",
        "    learning_rate = 0.05, # 학습률(eta)\n",
        "    max_depth=3,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "xgb_clf.fit(X_train, y_train, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rqR-mIVmqpS",
        "outputId": "de5397a3-f8f2-4355-eae4-410e99ce8c04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 1, 0, 0, 1, 0, 1])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds = xgb_clf.predict(X_test)\n",
        "preds[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFsCXNwjmqmt",
        "outputId": "6ff0d4d3-c9bd-4841-a63e-40030d6946d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[7.3437452e-02, 9.2656255e-01],\n",
              "       [9.9860471e-01, 1.3952850e-03],\n",
              "       [9.9924982e-01, 7.5019279e-04],\n",
              "       [1.5795231e-03, 9.9842048e-01],\n",
              "       [2.6434660e-04, 9.9973565e-01],\n",
              "       [9.9915171e-01, 8.4831589e-04],\n",
              "       [9.9709845e-01, 2.9015488e-03],\n",
              "       [3.3829182e-01, 6.6170818e-01],\n",
              "       [5.5896002e-01, 4.4103998e-01],\n",
              "       [3.5931468e-03, 9.9640685e-01]], dtype=float32)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_proba = xgb_clf.predict_proba(X_test)\n",
        "pred_proba[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6dZJJ7JmqkS"
      },
      "outputs": [],
      "source": [
        "# Early Stopping 적용\n",
        "xgb_clf = XGBClassifier(\n",
        "    n_estimators=400,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "95FLrtjzm7lO",
        "outputId": "5dfe0306-734a-4044-c685-f20919ee1177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-logloss:0.62706\tvalidation_1-logloss:0.60229\n",
            "[1]\tvalidation_0-logloss:0.59030\tvalidation_1-logloss:0.57112\n",
            "[2]\tvalidation_0-logloss:0.55534\tvalidation_1-logloss:0.54548\n",
            "[3]\tvalidation_0-logloss:0.52351\tvalidation_1-logloss:0.52160\n",
            "[4]\tvalidation_0-logloss:0.49440\tvalidation_1-logloss:0.50040\n",
            "[5]\tvalidation_0-logloss:0.46768\tvalidation_1-logloss:0.48104\n",
            "[6]\tvalidation_0-logloss:0.44391\tvalidation_1-logloss:0.45909\n",
            "[7]\tvalidation_0-logloss:0.42107\tvalidation_1-logloss:0.44270\n",
            "[8]\tvalidation_0-logloss:0.39994\tvalidation_1-logloss:0.42712\n",
            "[9]\tvalidation_0-logloss:0.38036\tvalidation_1-logloss:0.41490\n",
            "[10]\tvalidation_0-logloss:0.36265\tvalidation_1-logloss:0.40124\n",
            "[11]\tvalidation_0-logloss:0.34564\tvalidation_1-logloss:0.39045\n",
            "[12]\tvalidation_0-logloss:0.32978\tvalidation_1-logloss:0.38058\n",
            "[13]\tvalidation_0-logloss:0.31499\tvalidation_1-logloss:0.37156\n",
            "[14]\tvalidation_0-logloss:0.30116\tvalidation_1-logloss:0.36372\n",
            "[15]\tvalidation_0-logloss:0.28823\tvalidation_1-logloss:0.35494\n",
            "[16]\tvalidation_0-logloss:0.27603\tvalidation_1-logloss:0.34791\n",
            "[17]\tvalidation_0-logloss:0.26459\tvalidation_1-logloss:0.34123\n",
            "[18]\tvalidation_0-logloss:0.25401\tvalidation_1-logloss:0.33128\n",
            "[19]\tvalidation_0-logloss:0.24382\tvalidation_1-logloss:0.32515\n",
            "[20]\tvalidation_0-logloss:0.23430\tvalidation_1-logloss:0.31550\n",
            "[21]\tvalidation_0-logloss:0.22505\tvalidation_1-logloss:0.30932\n",
            "[22]\tvalidation_0-logloss:0.21647\tvalidation_1-logloss:0.30441\n",
            "[23]\tvalidation_0-logloss:0.20822\tvalidation_1-logloss:0.29882\n",
            "[24]\tvalidation_0-logloss:0.20046\tvalidation_1-logloss:0.29302\n",
            "[25]\tvalidation_0-logloss:0.19320\tvalidation_1-logloss:0.28585\n",
            "[26]\tvalidation_0-logloss:0.18627\tvalidation_1-logloss:0.28214\n",
            "[27]\tvalidation_0-logloss:0.17979\tvalidation_1-logloss:0.27542\n",
            "[28]\tvalidation_0-logloss:0.17360\tvalidation_1-logloss:0.27101\n",
            "[29]\tvalidation_0-logloss:0.16741\tvalidation_1-logloss:0.26692\n",
            "[30]\tvalidation_0-logloss:0.16191\tvalidation_1-logloss:0.26138\n",
            "[31]\tvalidation_0-logloss:0.15633\tvalidation_1-logloss:0.25778\n",
            "[32]\tvalidation_0-logloss:0.15130\tvalidation_1-logloss:0.25384\n",
            "[33]\tvalidation_0-logloss:0.14654\tvalidation_1-logloss:0.24898\n",
            "[34]\tvalidation_0-logloss:0.14187\tvalidation_1-logloss:0.24565\n",
            "[35]\tvalidation_0-logloss:0.13689\tvalidation_1-logloss:0.24303\n",
            "[36]\tvalidation_0-logloss:0.13260\tvalidation_1-logloss:0.24008\n",
            "[37]\tvalidation_0-logloss:0.12809\tvalidation_1-logloss:0.23782\n",
            "[38]\tvalidation_0-logloss:0.12440\tvalidation_1-logloss:0.23332\n",
            "[39]\tvalidation_0-logloss:0.12031\tvalidation_1-logloss:0.23141\n",
            "[40]\tvalidation_0-logloss:0.11645\tvalidation_1-logloss:0.22918\n",
            "[41]\tvalidation_0-logloss:0.11300\tvalidation_1-logloss:0.22756\n",
            "[42]\tvalidation_0-logloss:0.10967\tvalidation_1-logloss:0.22503\n",
            "[43]\tvalidation_0-logloss:0.10680\tvalidation_1-logloss:0.22155\n",
            "[44]\tvalidation_0-logloss:0.10377\tvalidation_1-logloss:0.22021\n",
            "[45]\tvalidation_0-logloss:0.10118\tvalidation_1-logloss:0.21726\n",
            "[46]\tvalidation_0-logloss:0.09843\tvalidation_1-logloss:0.21614\n",
            "[47]\tvalidation_0-logloss:0.09575\tvalidation_1-logloss:0.21432\n",
            "[48]\tvalidation_0-logloss:0.09319\tvalidation_1-logloss:0.21245\n",
            "[49]\tvalidation_0-logloss:0.09100\tvalidation_1-logloss:0.20976\n",
            "[50]\tvalidation_0-logloss:0.08869\tvalidation_1-logloss:0.20898\n",
            "[51]\tvalidation_0-logloss:0.08660\tvalidation_1-logloss:0.20511\n",
            "[52]\tvalidation_0-logloss:0.08440\tvalidation_1-logloss:0.20432\n",
            "[53]\tvalidation_0-logloss:0.08240\tvalidation_1-logloss:0.20377\n",
            "[54]\tvalidation_0-logloss:0.08044\tvalidation_1-logloss:0.20226\n",
            "[55]\tvalidation_0-logloss:0.07870\tvalidation_1-logloss:0.20006\n",
            "[56]\tvalidation_0-logloss:0.07679\tvalidation_1-logloss:0.19792\n",
            "[57]\tvalidation_0-logloss:0.07497\tvalidation_1-logloss:0.19656\n",
            "[58]\tvalidation_0-logloss:0.07316\tvalidation_1-logloss:0.19591\n",
            "[59]\tvalidation_0-logloss:0.07149\tvalidation_1-logloss:0.19408\n",
            "[60]\tvalidation_0-logloss:0.06986\tvalidation_1-logloss:0.19181\n",
            "[61]\tvalidation_0-logloss:0.06833\tvalidation_1-logloss:0.19013\n",
            "[62]\tvalidation_0-logloss:0.06680\tvalidation_1-logloss:0.18879\n",
            "[63]\tvalidation_0-logloss:0.06533\tvalidation_1-logloss:0.18672\n",
            "[64]\tvalidation_0-logloss:0.06395\tvalidation_1-logloss:0.18380\n",
            "[65]\tvalidation_0-logloss:0.06263\tvalidation_1-logloss:0.18299\n",
            "[66]\tvalidation_0-logloss:0.06136\tvalidation_1-logloss:0.18226\n",
            "[67]\tvalidation_0-logloss:0.06010\tvalidation_1-logloss:0.18195\n",
            "[68]\tvalidation_0-logloss:0.05888\tvalidation_1-logloss:0.17940\n",
            "[69]\tvalidation_0-logloss:0.05766\tvalidation_1-logloss:0.17763\n",
            "[70]\tvalidation_0-logloss:0.05657\tvalidation_1-logloss:0.17679\n",
            "[71]\tvalidation_0-logloss:0.05549\tvalidation_1-logloss:0.17397\n",
            "[72]\tvalidation_0-logloss:0.05440\tvalidation_1-logloss:0.17225\n",
            "[73]\tvalidation_0-logloss:0.05328\tvalidation_1-logloss:0.17081\n",
            "[74]\tvalidation_0-logloss:0.05233\tvalidation_1-logloss:0.17037\n",
            "[75]\tvalidation_0-logloss:0.05143\tvalidation_1-logloss:0.17032\n",
            "[76]\tvalidation_0-logloss:0.05041\tvalidation_1-logloss:0.16916\n",
            "[77]\tvalidation_0-logloss:0.04951\tvalidation_1-logloss:0.16715\n",
            "[78]\tvalidation_0-logloss:0.04857\tvalidation_1-logloss:0.16607\n",
            "[79]\tvalidation_0-logloss:0.04774\tvalidation_1-logloss:0.16527\n",
            "[80]\tvalidation_0-logloss:0.04686\tvalidation_1-logloss:0.16428\n",
            "[81]\tvalidation_0-logloss:0.04609\tvalidation_1-logloss:0.16359\n",
            "[82]\tvalidation_0-logloss:0.04516\tvalidation_1-logloss:0.16234\n",
            "[83]\tvalidation_0-logloss:0.04440\tvalidation_1-logloss:0.16062\n",
            "[84]\tvalidation_0-logloss:0.04364\tvalidation_1-logloss:0.15869\n",
            "[85]\tvalidation_0-logloss:0.04297\tvalidation_1-logloss:0.15973\n",
            "[86]\tvalidation_0-logloss:0.04227\tvalidation_1-logloss:0.15865\n",
            "[87]\tvalidation_0-logloss:0.04157\tvalidation_1-logloss:0.15869\n",
            "[88]\tvalidation_0-logloss:0.04085\tvalidation_1-logloss:0.15693\n",
            "[89]\tvalidation_0-logloss:0.04020\tvalidation_1-logloss:0.15536\n",
            "[90]\tvalidation_0-logloss:0.03937\tvalidation_1-logloss:0.15452\n",
            "[91]\tvalidation_0-logloss:0.03875\tvalidation_1-logloss:0.15426\n",
            "[92]\tvalidation_0-logloss:0.03815\tvalidation_1-logloss:0.15260\n",
            "[93]\tvalidation_0-logloss:0.03762\tvalidation_1-logloss:0.15360\n",
            "[94]\tvalidation_0-logloss:0.03706\tvalidation_1-logloss:0.15268\n",
            "[95]\tvalidation_0-logloss:0.03638\tvalidation_1-logloss:0.15255\n",
            "[96]\tvalidation_0-logloss:0.03574\tvalidation_1-logloss:0.15246\n",
            "[97]\tvalidation_0-logloss:0.03522\tvalidation_1-logloss:0.15229\n",
            "[98]\tvalidation_0-logloss:0.03472\tvalidation_1-logloss:0.15128\n",
            "[99]\tvalidation_0-logloss:0.03419\tvalidation_1-logloss:0.15086\n",
            "[100]\tvalidation_0-logloss:0.03369\tvalidation_1-logloss:0.15006\n",
            "[101]\tvalidation_0-logloss:0.03313\tvalidation_1-logloss:0.15001\n",
            "[102]\tvalidation_0-logloss:0.03267\tvalidation_1-logloss:0.15087\n",
            "[103]\tvalidation_0-logloss:0.03223\tvalidation_1-logloss:0.14968\n",
            "[104]\tvalidation_0-logloss:0.03171\tvalidation_1-logloss:0.14908\n",
            "[105]\tvalidation_0-logloss:0.03113\tvalidation_1-logloss:0.14851\n",
            "[106]\tvalidation_0-logloss:0.03064\tvalidation_1-logloss:0.14795\n",
            "[107]\tvalidation_0-logloss:0.03022\tvalidation_1-logloss:0.14782\n",
            "[108]\tvalidation_0-logloss:0.02980\tvalidation_1-logloss:0.14645\n",
            "[109]\tvalidation_0-logloss:0.02945\tvalidation_1-logloss:0.14536\n",
            "[110]\tvalidation_0-logloss:0.02898\tvalidation_1-logloss:0.14537\n",
            "[111]\tvalidation_0-logloss:0.02863\tvalidation_1-logloss:0.14538\n",
            "[112]\tvalidation_0-logloss:0.02825\tvalidation_1-logloss:0.14529\n",
            "[113]\tvalidation_0-logloss:0.02793\tvalidation_1-logloss:0.14437\n",
            "[114]\tvalidation_0-logloss:0.02757\tvalidation_1-logloss:0.14367\n",
            "[115]\tvalidation_0-logloss:0.02714\tvalidation_1-logloss:0.14343\n",
            "[116]\tvalidation_0-logloss:0.02675\tvalidation_1-logloss:0.14302\n",
            "[117]\tvalidation_0-logloss:0.02641\tvalidation_1-logloss:0.14309\n",
            "[118]\tvalidation_0-logloss:0.02605\tvalidation_1-logloss:0.14254\n",
            "[119]\tvalidation_0-logloss:0.02572\tvalidation_1-logloss:0.14216\n",
            "[120]\tvalidation_0-logloss:0.02540\tvalidation_1-logloss:0.14200\n",
            "[121]\tvalidation_0-logloss:0.02509\tvalidation_1-logloss:0.14142\n",
            "[122]\tvalidation_0-logloss:0.02474\tvalidation_1-logloss:0.14126\n",
            "[123]\tvalidation_0-logloss:0.02444\tvalidation_1-logloss:0.14093\n",
            "[124]\tvalidation_0-logloss:0.02419\tvalidation_1-logloss:0.14100\n",
            "[125]\tvalidation_0-logloss:0.02393\tvalidation_1-logloss:0.14106\n",
            "[126]\tvalidation_0-logloss:0.02361\tvalidation_1-logloss:0.14092\n",
            "[127]\tvalidation_0-logloss:0.02330\tvalidation_1-logloss:0.13985\n",
            "[128]\tvalidation_0-logloss:0.02303\tvalidation_1-logloss:0.13964\n",
            "[129]\tvalidation_0-logloss:0.02283\tvalidation_1-logloss:0.13968\n",
            "[130]\tvalidation_0-logloss:0.02255\tvalidation_1-logloss:0.13935\n",
            "[131]\tvalidation_0-logloss:0.02227\tvalidation_1-logloss:0.13834\n",
            "[132]\tvalidation_0-logloss:0.02200\tvalidation_1-logloss:0.13746\n",
            "[133]\tvalidation_0-logloss:0.02175\tvalidation_1-logloss:0.13638\n",
            "[134]\tvalidation_0-logloss:0.02158\tvalidation_1-logloss:0.13635\n",
            "[135]\tvalidation_0-logloss:0.02140\tvalidation_1-logloss:0.13693\n",
            "[136]\tvalidation_0-logloss:0.02111\tvalidation_1-logloss:0.13712\n",
            "[137]\tvalidation_0-logloss:0.02095\tvalidation_1-logloss:0.13729\n",
            "[138]\tvalidation_0-logloss:0.02077\tvalidation_1-logloss:0.13735\n",
            "[139]\tvalidation_0-logloss:0.02054\tvalidation_1-logloss:0.13719\n",
            "[140]\tvalidation_0-logloss:0.02038\tvalidation_1-logloss:0.13685\n",
            "[141]\tvalidation_0-logloss:0.02023\tvalidation_1-logloss:0.13702\n",
            "[142]\tvalidation_0-logloss:0.02007\tvalidation_1-logloss:0.13754\n",
            "[143]\tvalidation_0-logloss:0.01985\tvalidation_1-logloss:0.13741\n",
            "[144]\tvalidation_0-logloss:0.01974\tvalidation_1-logloss:0.13682\n",
            "[145]\tvalidation_0-logloss:0.01960\tvalidation_1-logloss:0.13700\n",
            "[146]\tvalidation_0-logloss:0.01945\tvalidation_1-logloss:0.13705\n",
            "[147]\tvalidation_0-logloss:0.01922\tvalidation_1-logloss:0.13673\n",
            "[148]\tvalidation_0-logloss:0.01912\tvalidation_1-logloss:0.13585\n",
            "[149]\tvalidation_0-logloss:0.01894\tvalidation_1-logloss:0.13520\n",
            "[150]\tvalidation_0-logloss:0.01879\tvalidation_1-logloss:0.13504\n",
            "[151]\tvalidation_0-logloss:0.01862\tvalidation_1-logloss:0.13449\n",
            "[152]\tvalidation_0-logloss:0.01850\tvalidation_1-logloss:0.13447\n",
            "[153]\tvalidation_0-logloss:0.01840\tvalidation_1-logloss:0.13394\n",
            "[154]\tvalidation_0-logloss:0.01827\tvalidation_1-logloss:0.13402\n",
            "[155]\tvalidation_0-logloss:0.01818\tvalidation_1-logloss:0.13351\n",
            "[156]\tvalidation_0-logloss:0.01801\tvalidation_1-logloss:0.13339\n",
            "[157]\tvalidation_0-logloss:0.01790\tvalidation_1-logloss:0.13298\n",
            "[158]\tvalidation_0-logloss:0.01777\tvalidation_1-logloss:0.13305\n",
            "[159]\tvalidation_0-logloss:0.01762\tvalidation_1-logloss:0.13246\n",
            "[160]\tvalidation_0-logloss:0.01751\tvalidation_1-logloss:0.13178\n",
            "[161]\tvalidation_0-logloss:0.01739\tvalidation_1-logloss:0.13187\n",
            "[162]\tvalidation_0-logloss:0.01729\tvalidation_1-logloss:0.13196\n",
            "[163]\tvalidation_0-logloss:0.01714\tvalidation_1-logloss:0.13149\n",
            "[164]\tvalidation_0-logloss:0.01704\tvalidation_1-logloss:0.13161\n",
            "[165]\tvalidation_0-logloss:0.01696\tvalidation_1-logloss:0.13135\n",
            "[166]\tvalidation_0-logloss:0.01681\tvalidation_1-logloss:0.13125\n",
            "[167]\tvalidation_0-logloss:0.01671\tvalidation_1-logloss:0.13060\n",
            "[168]\tvalidation_0-logloss:0.01661\tvalidation_1-logloss:0.13023\n",
            "[169]\tvalidation_0-logloss:0.01648\tvalidation_1-logloss:0.12979\n",
            "[170]\tvalidation_0-logloss:0.01640\tvalidation_1-logloss:0.12955\n",
            "[171]\tvalidation_0-logloss:0.01627\tvalidation_1-logloss:0.12933\n",
            "[172]\tvalidation_0-logloss:0.01612\tvalidation_1-logloss:0.12901\n",
            "[173]\tvalidation_0-logloss:0.01603\tvalidation_1-logloss:0.12926\n",
            "[174]\tvalidation_0-logloss:0.01594\tvalidation_1-logloss:0.12937\n",
            "[175]\tvalidation_0-logloss:0.01584\tvalidation_1-logloss:0.12922\n",
            "[176]\tvalidation_0-logloss:0.01576\tvalidation_1-logloss:0.12899\n",
            "[177]\tvalidation_0-logloss:0.01568\tvalidation_1-logloss:0.12876\n",
            "[178]\tvalidation_0-logloss:0.01556\tvalidation_1-logloss:0.12866\n",
            "[179]\tvalidation_0-logloss:0.01547\tvalidation_1-logloss:0.12876\n",
            "[180]\tvalidation_0-logloss:0.01539\tvalidation_1-logloss:0.12815\n",
            "[181]\tvalidation_0-logloss:0.01530\tvalidation_1-logloss:0.12839\n",
            "[182]\tvalidation_0-logloss:0.01521\tvalidation_1-logloss:0.12850\n",
            "[183]\tvalidation_0-logloss:0.01515\tvalidation_1-logloss:0.12779\n",
            "[184]\tvalidation_0-logloss:0.01505\tvalidation_1-logloss:0.12745\n",
            "[185]\tvalidation_0-logloss:0.01497\tvalidation_1-logloss:0.12688\n",
            "[186]\tvalidation_0-logloss:0.01485\tvalidation_1-logloss:0.12660\n",
            "[187]\tvalidation_0-logloss:0.01477\tvalidation_1-logloss:0.12671\n",
            "[188]\tvalidation_0-logloss:0.01469\tvalidation_1-logloss:0.12658\n",
            "[189]\tvalidation_0-logloss:0.01461\tvalidation_1-logloss:0.12668\n",
            "[190]\tvalidation_0-logloss:0.01454\tvalidation_1-logloss:0.12649\n",
            "[191]\tvalidation_0-logloss:0.01446\tvalidation_1-logloss:0.12630\n",
            "[192]\tvalidation_0-logloss:0.01438\tvalidation_1-logloss:0.12594\n",
            "[193]\tvalidation_0-logloss:0.01433\tvalidation_1-logloss:0.12588\n",
            "[194]\tvalidation_0-logloss:0.01425\tvalidation_1-logloss:0.12543\n",
            "[195]\tvalidation_0-logloss:0.01417\tvalidation_1-logloss:0.12511\n",
            "[196]\tvalidation_0-logloss:0.01406\tvalidation_1-logloss:0.12484\n",
            "[197]\tvalidation_0-logloss:0.01399\tvalidation_1-logloss:0.12464\n",
            "[198]\tvalidation_0-logloss:0.01392\tvalidation_1-logloss:0.12410\n",
            "[199]\tvalidation_0-logloss:0.01385\tvalidation_1-logloss:0.12433\n",
            "[200]\tvalidation_0-logloss:0.01375\tvalidation_1-logloss:0.12409\n",
            "[201]\tvalidation_0-logloss:0.01367\tvalidation_1-logloss:0.12418\n",
            "[202]\tvalidation_0-logloss:0.01364\tvalidation_1-logloss:0.12405\n",
            "[203]\tvalidation_0-logloss:0.01358\tvalidation_1-logloss:0.12388\n",
            "[204]\tvalidation_0-logloss:0.01348\tvalidation_1-logloss:0.12365\n",
            "[205]\tvalidation_0-logloss:0.01340\tvalidation_1-logloss:0.12355\n",
            "[206]\tvalidation_0-logloss:0.01335\tvalidation_1-logloss:0.12338\n",
            "[207]\tvalidation_0-logloss:0.01329\tvalidation_1-logloss:0.12318\n",
            "[208]\tvalidation_0-logloss:0.01323\tvalidation_1-logloss:0.12291\n",
            "[209]\tvalidation_0-logloss:0.01316\tvalidation_1-logloss:0.12275\n",
            "[210]\tvalidation_0-logloss:0.01309\tvalidation_1-logloss:0.12233\n",
            "[211]\tvalidation_0-logloss:0.01304\tvalidation_1-logloss:0.12172\n",
            "[212]\tvalidation_0-logloss:0.01295\tvalidation_1-logloss:0.12150\n",
            "[213]\tvalidation_0-logloss:0.01288\tvalidation_1-logloss:0.12140\n",
            "[214]\tvalidation_0-logloss:0.01283\tvalidation_1-logloss:0.12080\n",
            "[215]\tvalidation_0-logloss:0.01276\tvalidation_1-logloss:0.12091\n",
            "[216]\tvalidation_0-logloss:0.01271\tvalidation_1-logloss:0.12109\n",
            "[217]\tvalidation_0-logloss:0.01266\tvalidation_1-logloss:0.12065\n",
            "[218]\tvalidation_0-logloss:0.01258\tvalidation_1-logloss:0.12045\n",
            "[219]\tvalidation_0-logloss:0.01251\tvalidation_1-logloss:0.12055\n",
            "[220]\tvalidation_0-logloss:0.01246\tvalidation_1-logloss:0.11997\n",
            "[221]\tvalidation_0-logloss:0.01241\tvalidation_1-logloss:0.12014\n",
            "[222]\tvalidation_0-logloss:0.01236\tvalidation_1-logloss:0.11957\n",
            "[223]\tvalidation_0-logloss:0.01230\tvalidation_1-logloss:0.11968\n",
            "[224]\tvalidation_0-logloss:0.01227\tvalidation_1-logloss:0.11989\n",
            "[225]\tvalidation_0-logloss:0.01223\tvalidation_1-logloss:0.11933\n",
            "[226]\tvalidation_0-logloss:0.01215\tvalidation_1-logloss:0.11915\n",
            "[227]\tvalidation_0-logloss:0.01210\tvalidation_1-logloss:0.11876\n",
            "[228]\tvalidation_0-logloss:0.01204\tvalidation_1-logloss:0.11886\n",
            "[229]\tvalidation_0-logloss:0.01199\tvalidation_1-logloss:0.11868\n",
            "[230]\tvalidation_0-logloss:0.01195\tvalidation_1-logloss:0.11839\n",
            "[231]\tvalidation_0-logloss:0.01193\tvalidation_1-logloss:0.11860\n",
            "[232]\tvalidation_0-logloss:0.01187\tvalidation_1-logloss:0.11822\n",
            "[233]\tvalidation_0-logloss:0.01183\tvalidation_1-logloss:0.11804\n",
            "[234]\tvalidation_0-logloss:0.01179\tvalidation_1-logloss:0.11759\n",
            "[235]\tvalidation_0-logloss:0.01175\tvalidation_1-logloss:0.11731\n",
            "[236]\tvalidation_0-logloss:0.01170\tvalidation_1-logloss:0.11695\n",
            "[237]\tvalidation_0-logloss:0.01167\tvalidation_1-logloss:0.11716\n",
            "[238]\tvalidation_0-logloss:0.01161\tvalidation_1-logloss:0.11698\n",
            "[239]\tvalidation_0-logloss:0.01155\tvalidation_1-logloss:0.11669\n",
            "[240]\tvalidation_0-logloss:0.01152\tvalidation_1-logloss:0.11642\n",
            "[241]\tvalidation_0-logloss:0.01149\tvalidation_1-logloss:0.11662\n",
            "[242]\tvalidation_0-logloss:0.01146\tvalidation_1-logloss:0.11635\n",
            "[243]\tvalidation_0-logloss:0.01142\tvalidation_1-logloss:0.11635\n",
            "[244]\tvalidation_0-logloss:0.01137\tvalidation_1-logloss:0.11630\n",
            "[245]\tvalidation_0-logloss:0.01131\tvalidation_1-logloss:0.11603\n",
            "[246]\tvalidation_0-logloss:0.01127\tvalidation_1-logloss:0.11589\n",
            "[247]\tvalidation_0-logloss:0.01125\tvalidation_1-logloss:0.11592\n",
            "[248]\tvalidation_0-logloss:0.01122\tvalidation_1-logloss:0.11578\n",
            "[249]\tvalidation_0-logloss:0.01117\tvalidation_1-logloss:0.11574\n",
            "[250]\tvalidation_0-logloss:0.01113\tvalidation_1-logloss:0.11574\n",
            "[251]\tvalidation_0-logloss:0.01111\tvalidation_1-logloss:0.11571\n",
            "[252]\tvalidation_0-logloss:0.01106\tvalidation_1-logloss:0.11545\n",
            "[253]\tvalidation_0-logloss:0.01103\tvalidation_1-logloss:0.11504\n",
            "[254]\tvalidation_0-logloss:0.01101\tvalidation_1-logloss:0.11507\n",
            "[255]\tvalidation_0-logloss:0.01097\tvalidation_1-logloss:0.11507\n",
            "[256]\tvalidation_0-logloss:0.01093\tvalidation_1-logloss:0.11503\n",
            "[257]\tvalidation_0-logloss:0.01091\tvalidation_1-logloss:0.11476\n",
            "[258]\tvalidation_0-logloss:0.01089\tvalidation_1-logloss:0.11449\n",
            "[259]\tvalidation_0-logloss:0.01087\tvalidation_1-logloss:0.11446\n",
            "[260]\tvalidation_0-logloss:0.01082\tvalidation_1-logloss:0.11442\n",
            "[261]\tvalidation_0-logloss:0.01080\tvalidation_1-logloss:0.11446\n",
            "[262]\tvalidation_0-logloss:0.01078\tvalidation_1-logloss:0.11454\n",
            "[263]\tvalidation_0-logloss:0.01077\tvalidation_1-logloss:0.11434\n",
            "[264]\tvalidation_0-logloss:0.01075\tvalidation_1-logloss:0.11457\n",
            "[265]\tvalidation_0-logloss:0.01073\tvalidation_1-logloss:0.11431\n",
            "[266]\tvalidation_0-logloss:0.01071\tvalidation_1-logloss:0.11404\n",
            "[267]\tvalidation_0-logloss:0.01069\tvalidation_1-logloss:0.11401\n",
            "[268]\tvalidation_0-logloss:0.01067\tvalidation_1-logloss:0.11405\n",
            "[269]\tvalidation_0-logloss:0.01065\tvalidation_1-logloss:0.11413\n",
            "[270]\tvalidation_0-logloss:0.01063\tvalidation_1-logloss:0.11436\n",
            "[271]\tvalidation_0-logloss:0.01061\tvalidation_1-logloss:0.11410\n",
            "[272]\tvalidation_0-logloss:0.01059\tvalidation_1-logloss:0.11409\n",
            "[273]\tvalidation_0-logloss:0.01058\tvalidation_1-logloss:0.11417\n",
            "[274]\tvalidation_0-logloss:0.01056\tvalidation_1-logloss:0.11440\n",
            "[275]\tvalidation_0-logloss:0.01054\tvalidation_1-logloss:0.11413\n",
            "[276]\tvalidation_0-logloss:0.01052\tvalidation_1-logloss:0.11410\n",
            "[277]\tvalidation_0-logloss:0.01050\tvalidation_1-logloss:0.11391\n",
            "[278]\tvalidation_0-logloss:0.01048\tvalidation_1-logloss:0.11395\n",
            "[279]\tvalidation_0-logloss:0.01047\tvalidation_1-logloss:0.11417\n",
            "[280]\tvalidation_0-logloss:0.01045\tvalidation_1-logloss:0.11391\n",
            "[281]\tvalidation_0-logloss:0.01043\tvalidation_1-logloss:0.11366\n",
            "[282]\tvalidation_0-logloss:0.01041\tvalidation_1-logloss:0.11388\n",
            "[283]\tvalidation_0-logloss:0.01039\tvalidation_1-logloss:0.11396\n",
            "[284]\tvalidation_0-logloss:0.01038\tvalidation_1-logloss:0.11404\n",
            "[285]\tvalidation_0-logloss:0.01036\tvalidation_1-logloss:0.11428\n",
            "[286]\tvalidation_0-logloss:0.01034\tvalidation_1-logloss:0.11403\n",
            "[287]\tvalidation_0-logloss:0.01032\tvalidation_1-logloss:0.11377\n",
            "[288]\tvalidation_0-logloss:0.01031\tvalidation_1-logloss:0.11375\n",
            "[289]\tvalidation_0-logloss:0.01029\tvalidation_1-logloss:0.11397\n",
            "[290]\tvalidation_0-logloss:0.01027\tvalidation_1-logloss:0.11405\n",
            "[291]\tvalidation_0-logloss:0.01025\tvalidation_1-logloss:0.11380\n",
            "[292]\tvalidation_0-logloss:0.01024\tvalidation_1-logloss:0.11379\n",
            "[293]\tvalidation_0-logloss:0.01022\tvalidation_1-logloss:0.11403\n",
            "[294]\tvalidation_0-logloss:0.01020\tvalidation_1-logloss:0.11378\n",
            "[295]\tvalidation_0-logloss:0.01019\tvalidation_1-logloss:0.11386\n",
            "[296]\tvalidation_0-logloss:0.01017\tvalidation_1-logloss:0.11390\n",
            "[297]\tvalidation_0-logloss:0.01015\tvalidation_1-logloss:0.11387\n",
            "[298]\tvalidation_0-logloss:0.01014\tvalidation_1-logloss:0.11369\n",
            "[299]\tvalidation_0-logloss:0.01012\tvalidation_1-logloss:0.11391\n",
            "[300]\tvalidation_0-logloss:0.01010\tvalidation_1-logloss:0.11366\n",
            "[301]\tvalidation_0-logloss:0.01009\tvalidation_1-logloss:0.11374\n",
            "[302]\tvalidation_0-logloss:0.01007\tvalidation_1-logloss:0.11396\n",
            "[303]\tvalidation_0-logloss:0.01005\tvalidation_1-logloss:0.11371\n",
            "[304]\tvalidation_0-logloss:0.01004\tvalidation_1-logloss:0.11379\n",
            "[305]\tvalidation_0-logloss:0.01002\tvalidation_1-logloss:0.11401\n",
            "[306]\tvalidation_0-logloss:0.01000\tvalidation_1-logloss:0.11376\n",
            "[307]\tvalidation_0-logloss:0.00999\tvalidation_1-logloss:0.11353\n",
            "[308]\tvalidation_0-logloss:0.00997\tvalidation_1-logloss:0.11357\n",
            "[309]\tvalidation_0-logloss:0.00996\tvalidation_1-logloss:0.11354\n",
            "[310]\tvalidation_0-logloss:0.00994\tvalidation_1-logloss:0.11376\n",
            "[311]\tvalidation_0-logloss:0.00992\tvalidation_1-logloss:0.11384\n",
            "[312]\tvalidation_0-logloss:0.00991\tvalidation_1-logloss:0.11360\n",
            "[313]\tvalidation_0-logloss:0.00989\tvalidation_1-logloss:0.11336\n",
            "[314]\tvalidation_0-logloss:0.00988\tvalidation_1-logloss:0.11358\n",
            "[315]\tvalidation_0-logloss:0.00986\tvalidation_1-logloss:0.11366\n",
            "[316]\tvalidation_0-logloss:0.00985\tvalidation_1-logloss:0.11348\n",
            "[317]\tvalidation_0-logloss:0.00983\tvalidation_1-logloss:0.11370\n",
            "[318]\tvalidation_0-logloss:0.00981\tvalidation_1-logloss:0.11346\n",
            "[319]\tvalidation_0-logloss:0.00980\tvalidation_1-logloss:0.11350\n",
            "[320]\tvalidation_0-logloss:0.00978\tvalidation_1-logloss:0.11348\n",
            "[321]\tvalidation_0-logloss:0.00977\tvalidation_1-logloss:0.11348\n",
            "[322]\tvalidation_0-logloss:0.00975\tvalidation_1-logloss:0.11356\n",
            "[323]\tvalidation_0-logloss:0.00974\tvalidation_1-logloss:0.11333\n",
            "[324]\tvalidation_0-logloss:0.00972\tvalidation_1-logloss:0.11354\n",
            "[325]\tvalidation_0-logloss:0.00971\tvalidation_1-logloss:0.11330\n",
            "[326]\tvalidation_0-logloss:0.00969\tvalidation_1-logloss:0.11352\n",
            "[327]\tvalidation_0-logloss:0.00968\tvalidation_1-logloss:0.11360\n",
            "[328]\tvalidation_0-logloss:0.00966\tvalidation_1-logloss:0.11336\n",
            "[329]\tvalidation_0-logloss:0.00965\tvalidation_1-logloss:0.11357\n",
            "[330]\tvalidation_0-logloss:0.00963\tvalidation_1-logloss:0.11365\n",
            "[331]\tvalidation_0-logloss:0.00962\tvalidation_1-logloss:0.11342\n",
            "[332]\tvalidation_0-logloss:0.00960\tvalidation_1-logloss:0.11341\n",
            "[333]\tvalidation_0-logloss:0.00959\tvalidation_1-logloss:0.11345\n",
            "[334]\tvalidation_0-logloss:0.00958\tvalidation_1-logloss:0.11328\n",
            "[335]\tvalidation_0-logloss:0.00956\tvalidation_1-logloss:0.11309\n",
            "[336]\tvalidation_0-logloss:0.00955\tvalidation_1-logloss:0.11330\n",
            "[337]\tvalidation_0-logloss:0.00953\tvalidation_1-logloss:0.11338\n",
            "[338]\tvalidation_0-logloss:0.00952\tvalidation_1-logloss:0.11318\n",
            "[339]\tvalidation_0-logloss:0.00950\tvalidation_1-logloss:0.11323\n",
            "[340]\tvalidation_0-logloss:0.00949\tvalidation_1-logloss:0.11321\n",
            "[341]\tvalidation_0-logloss:0.00948\tvalidation_1-logloss:0.11299\n",
            "[342]\tvalidation_0-logloss:0.00946\tvalidation_1-logloss:0.11320\n",
            "[343]\tvalidation_0-logloss:0.00945\tvalidation_1-logloss:0.11328\n",
            "[344]\tvalidation_0-logloss:0.00943\tvalidation_1-logloss:0.11305\n",
            "[345]\tvalidation_0-logloss:0.00942\tvalidation_1-logloss:0.11326\n",
            "[346]\tvalidation_0-logloss:0.00941\tvalidation_1-logloss:0.11334\n",
            "[347]\tvalidation_0-logloss:0.00939\tvalidation_1-logloss:0.11315\n",
            "[348]\tvalidation_0-logloss:0.00938\tvalidation_1-logloss:0.11333\n",
            "[349]\tvalidation_0-logloss:0.00936\tvalidation_1-logloss:0.11354\n",
            "[350]\tvalidation_0-logloss:0.00935\tvalidation_1-logloss:0.11332\n",
            "[351]\tvalidation_0-logloss:0.00934\tvalidation_1-logloss:0.11331\n",
            "[352]\tvalidation_0-logloss:0.00932\tvalidation_1-logloss:0.11335\n",
            "[353]\tvalidation_0-logloss:0.00931\tvalidation_1-logloss:0.11317\n",
            "[354]\tvalidation_0-logloss:0.00930\tvalidation_1-logloss:0.11320\n",
            "[355]\tvalidation_0-logloss:0.00928\tvalidation_1-logloss:0.11324\n",
            "[356]\tvalidation_0-logloss:0.00927\tvalidation_1-logloss:0.11323\n",
            "[357]\tvalidation_0-logloss:0.00926\tvalidation_1-logloss:0.11302\n",
            "[358]\tvalidation_0-logloss:0.00924\tvalidation_1-logloss:0.11309\n",
            "[359]\tvalidation_0-logloss:0.00923\tvalidation_1-logloss:0.11330\n",
            "[360]\tvalidation_0-logloss:0.00922\tvalidation_1-logloss:0.11337\n",
            "[361]\tvalidation_0-logloss:0.00920\tvalidation_1-logloss:0.11319\n",
            "[362]\tvalidation_0-logloss:0.00919\tvalidation_1-logloss:0.11340\n",
            "[363]\tvalidation_0-logloss:0.00918\tvalidation_1-logloss:0.11318\n",
            "[364]\tvalidation_0-logloss:0.00916\tvalidation_1-logloss:0.11326\n",
            "[365]\tvalidation_0-logloss:0.00915\tvalidation_1-logloss:0.11325\n",
            "[366]\tvalidation_0-logloss:0.00914\tvalidation_1-logloss:0.11330\n",
            "[367]\tvalidation_0-logloss:0.00913\tvalidation_1-logloss:0.11309\n",
            "[368]\tvalidation_0-logloss:0.00911\tvalidation_1-logloss:0.11288\n",
            "[369]\tvalidation_0-logloss:0.00910\tvalidation_1-logloss:0.11291\n",
            "[370]\tvalidation_0-logloss:0.00909\tvalidation_1-logloss:0.11296\n",
            "[371]\tvalidation_0-logloss:0.00908\tvalidation_1-logloss:0.11296\n",
            "[372]\tvalidation_0-logloss:0.00906\tvalidation_1-logloss:0.11278\n",
            "[373]\tvalidation_0-logloss:0.00905\tvalidation_1-logloss:0.11285\n",
            "[374]\tvalidation_0-logloss:0.00904\tvalidation_1-logloss:0.11290\n",
            "[375]\tvalidation_0-logloss:0.00903\tvalidation_1-logloss:0.11270\n",
            "[376]\tvalidation_0-logloss:0.00901\tvalidation_1-logloss:0.11269\n",
            "[377]\tvalidation_0-logloss:0.00900\tvalidation_1-logloss:0.11272\n",
            "[378]\tvalidation_0-logloss:0.00899\tvalidation_1-logloss:0.11255\n",
            "[379]\tvalidation_0-logloss:0.00898\tvalidation_1-logloss:0.11272\n",
            "[380]\tvalidation_0-logloss:0.00897\tvalidation_1-logloss:0.11279\n",
            "[381]\tvalidation_0-logloss:0.00895\tvalidation_1-logloss:0.11259\n",
            "[382]\tvalidation_0-logloss:0.00894\tvalidation_1-logloss:0.11276\n",
            "[383]\tvalidation_0-logloss:0.00893\tvalidation_1-logloss:0.11284\n",
            "[384]\tvalidation_0-logloss:0.00892\tvalidation_1-logloss:0.11289\n",
            "[385]\tvalidation_0-logloss:0.00891\tvalidation_1-logloss:0.11269\n",
            "[386]\tvalidation_0-logloss:0.00890\tvalidation_1-logloss:0.11272\n",
            "[387]\tvalidation_0-logloss:0.00888\tvalidation_1-logloss:0.11252\n",
            "[388]\tvalidation_0-logloss:0.00887\tvalidation_1-logloss:0.11252\n",
            "[389]\tvalidation_0-logloss:0.00886\tvalidation_1-logloss:0.11257\n",
            "[390]\tvalidation_0-logloss:0.00885\tvalidation_1-logloss:0.11240\n",
            "[391]\tvalidation_0-logloss:0.00884\tvalidation_1-logloss:0.11247\n",
            "[392]\tvalidation_0-logloss:0.00883\tvalidation_1-logloss:0.11247\n",
            "[393]\tvalidation_0-logloss:0.00881\tvalidation_1-logloss:0.11253\n",
            "[394]\tvalidation_0-logloss:0.00880\tvalidation_1-logloss:0.11233\n",
            "[395]\tvalidation_0-logloss:0.00879\tvalidation_1-logloss:0.11247\n",
            "[396]\tvalidation_0-logloss:0.00878\tvalidation_1-logloss:0.11255\n",
            "[397]\tvalidation_0-logloss:0.00877\tvalidation_1-logloss:0.11255\n",
            "[398]\tvalidation_0-logloss:0.00876\tvalidation_1-logloss:0.11235\n",
            "[399]\tvalidation_0-logloss:0.00875\tvalidation_1-logloss:0.11238\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=400, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=None, ...)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evals = [\n",
        "    (X_train, y_train),\n",
        "    (X_valid, y_valid)\n",
        "]\n",
        "\n",
        "xgb_clf.fit(\n",
        "    X_train, y_train,\n",
        "    early_stopping_rounds = 50,\n",
        "    eval_set=evals,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z0lrf4Gn2Rn",
        "outputId": "ba084977-ac96-4842-9c5f-8fcd4545bc54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.01235224, 0.01258327, 0.00553193, 0.01693648, 0.00369544,\n",
              "       0.00555813, 0.01183528, 0.24660403, 0.00128275, 0.00869971,\n",
              "       0.01515575, 0.00208906, 0.01706614, 0.01396721, 0.00518284,\n",
              "       0.00460533, 0.00378786, 0.00211838, 0.00248873, 0.00207492,\n",
              "       0.04405012, 0.04099744, 0.22401944, 0.08619169, 0.00919142,\n",
              "       0.00310335, 0.01205984, 0.18114622, 0.00401972, 0.00160521],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Feature 중요도 확인\n",
        "xgb_clf.feature_importances_"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
