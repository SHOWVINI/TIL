{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRVrPA3WfjYN"
   },
   "source": [
    "# 빅데이터 분석기사 도움말 활용팁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "executionInfo": {
     "elapsed": 434,
     "status": "ok",
     "timestamp": 1718947119595,
     "user": {
      "displayName": "Ji-hoon Jung",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "r3qfl5zUSgYg",
    "outputId": "932b241a-68c6-4486-f9e7-cf3d0b2b2ac9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BootstrapMethod , CensoredData , ConstantInputWarning , Covariance , DegenerateDataWarning , FitError , MonteCarloMethod , NearConstantInputWarning , PermutationMethod , __all__ , __builtins__ , __cached__ , __doc__ , __file__ , __loader__ , __name__ , __package__ , __path__ , __spec__ , _ansari_swilk_statistics , _axis_nan_policy , _biasedurn , _binned_statistic , _binomtest , _bws_test , _censored_data , _common , _constants , _continuous_distns , _covariance , _crosstab , _discrete_distns , _distn_infrastructure , _distr_params , _entropy , _fit , _hypotests , _kde , _ksstats , _levy_stable , _mannwhitneyu , _mgc , _morestats , _mstats_basic , _mstats_extras , _multicomp , _multivariate , _mvn , _odds_ratio , _page_trend_test , _qmc , _qmc_cy , _qmvnt , _rcont , _relative_risk , _resampling , _rvs_sampling , _sampling , _sensitivity_analysis , _sobol , _stats , _stats_mstats_common , _stats_py , _stats_pythran , _survival , _tukeylambda_stats , _unuran , _variation , _warnings_errors , _wilcoxon , alexandergovern , alpha , anderson , anderson_ksamp , anglit , ansari , arcsine , argus , barnard_exact , bartlett , bayes_mvs , bernoulli , beta , betabinom , betanbinom , betaprime , biasedurn , binned_statistic , binned_statistic_2d , binned_statistic_dd , binom , binomtest , boltzmann , bootstrap , boschloo_exact , boxcox , boxcox_llf , boxcox_normmax , boxcox_normplot , bradford , brunnermunzel , burr , burr12 , bws_test , cauchy , chi , chi2 , chi2_contingency , chisquare , circmean , circstd , circvar , combine_pvalues , contingency , cosine , cramervonmises , cramervonmises_2samp , crystalball , cumfreq , describe , dgamma , differential_entropy , directional_stats , dirichlet , dirichlet_multinomial , distributions , dlaplace , dunnett , dweibull , ecdf , energy_distance , entropy , epps_singleton_2samp , erlang , expectile , expon , exponnorm , exponpow , exponweib , f , f_oneway , false_discovery_control , fatiguelife , find_repeats , fisher_exact , fisk , fit , fligner , foldcauchy , foldnorm , friedmanchisquare , gamma , gausshyper , gaussian_kde , genexpon , genextreme , gengamma , genhalflogistic , genhyperbolic , geninvgauss , genlogistic , gennorm , genpareto , geom , gibrat , gmean , gompertz , goodness_of_fit , gstd , gumbel_l , gumbel_r , gzscore , halfcauchy , halfgennorm , halflogistic , halfnorm , hmean , hypergeom , hypsecant , invgamma , invgauss , invweibull , invwishart , iqr , irwinhall , jarque_bera , jf_skew_t , johnsonsb , johnsonsu , kappa3 , kappa4 , kde , kendalltau , kruskal , ks_1samp , ks_2samp , ksone , kstat , kstatvar , kstest , kstwo , kstwobign , kurtosis , kurtosistest , laplace , laplace_asymmetric , levene , levy , levy_l , levy_stable , linregress , loggamma , logistic , loglaplace , lognorm , logrank , logser , loguniform , lomax , mannwhitneyu , matrix_normal , maxwell , median_abs_deviation , median_test , mielke , mode , moment , monte_carlo_test , mood , morestats , moyal , mstats , mstats_basic , mstats_extras , multinomial , multiscale_graphcorr , multivariate_hypergeom , multivariate_normal , multivariate_t , mvn , mvsdist , nakagami , nbinom , ncf , nchypergeom_fisher , nchypergeom_wallenius , nct , ncx2 , nhypergeom , norm , normaltest , norminvgauss , obrientransform , ortho_group , page_trend_test , pareto , pearson3 , pearsonr , percentileofscore , permutation_test , planck , pmean , pointbiserialr , poisson , poisson_means_test , power , power_divergence , powerlaw , powerlognorm , powernorm , ppcc_max , ppcc_plot , probplot , qmc , quantile_test , randint , random_correlation , random_table , rankdata , ranksums , rayleigh , rdist , recipinvgauss , reciprocal , rel_breitwigner , relfreq , rice , rv_continuous , rv_discrete , rv_histogram , rvs_ratio_uniforms , sampling , scoreatpercentile , sem , semicircular , shapiro , siegelslopes , sigmaclip , skellam , skew , skewcauchy , skewnorm , skewtest , sobol_indices , somersd , spearmanr , special_ortho_group , stats , studentized_range , t , test , theilslopes , tiecorrect , tmax , tmean , tmin , trapezoid , trapz , triang , trim1 , trim_mean , trimboth , truncexpon , truncnorm , truncpareto , truncweibull_min , tsem , tstd , ttest_1samp , ttest_ind , ttest_ind_from_stats , ttest_rel , tukey_hsd , tukeylambda , tvar , uniform , uniform_direction , unitary_group , variation , vonmises , vonmises_fisher , vonmises_line , wald , wasserstein_distance , wasserstein_distance_nd , weibull_max , weibull_min , weightedtau , wilcoxon , wishart , wrapcauchy , yeojohnson , yeojohnson_llf , yeojohnson_normmax , yeojohnson_normplot , yulesimon , zipf , zipfian , zmap , zscore'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "\" , \".join(dir(scipy.stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbWSKBguS5IO"
   },
   "source": [
    "- 설명서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1718947120294,
     "user": {
      "displayName": "Ji-hoon Jung",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "OnkS0tQxS6wH",
    "outputId": "3897bce1-5e85-4d59-8a6a-18f22ef04d3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function chi2_contingency in module scipy.stats.contingency:\n",
      "\n",
      "chi2_contingency(observed, correction=True, lambda_=None)\n",
      "    Chi-square test of independence of variables in a contingency table.\n",
      "    \n",
      "    This function computes the chi-square statistic and p-value for the\n",
      "    hypothesis test of independence of the observed frequencies in the\n",
      "    contingency table [1]_ `observed`.  The expected frequencies are computed\n",
      "    based on the marginal sums under the assumption of independence; see\n",
      "    `scipy.stats.contingency.expected_freq`.  The number of degrees of\n",
      "    freedom is (expressed using numpy functions and attributes)::\n",
      "    \n",
      "        dof = observed.size - sum(observed.shape) + observed.ndim - 1\n",
      "    \n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    observed : array_like\n",
      "        The contingency table. The table contains the observed frequencies\n",
      "        (i.e. number of occurrences) in each category.  In the two-dimensional\n",
      "        case, the table is often described as an \"R x C table\".\n",
      "    correction : bool, optional\n",
      "        If True, *and* the degrees of freedom is 1, apply Yates' correction\n",
      "        for continuity.  The effect of the correction is to adjust each\n",
      "        observed value by 0.5 towards the corresponding expected value.\n",
      "    lambda_ : float or str, optional\n",
      "        By default, the statistic computed in this test is Pearson's\n",
      "        chi-squared statistic [2]_.  `lambda_` allows a statistic from the\n",
      "        Cressie-Read power divergence family [3]_ to be used instead.  See\n",
      "        `scipy.stats.power_divergence` for details.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    res : Chi2ContingencyResult\n",
      "        An object containing attributes:\n",
      "    \n",
      "        statistic : float\n",
      "            The test statistic.\n",
      "        pvalue : float\n",
      "            The p-value of the test.\n",
      "        dof : int\n",
      "            The degrees of freedom.\n",
      "        expected_freq : ndarray, same shape as `observed`\n",
      "            The expected frequencies, based on the marginal sums of the table.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    scipy.stats.contingency.expected_freq\n",
      "    scipy.stats.fisher_exact\n",
      "    scipy.stats.chisquare\n",
      "    scipy.stats.power_divergence\n",
      "    scipy.stats.barnard_exact\n",
      "    scipy.stats.boschloo_exact\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    An often quoted guideline for the validity of this calculation is that\n",
      "    the test should be used only if the observed and expected frequencies\n",
      "    in each cell are at least 5.\n",
      "    \n",
      "    This is a test for the independence of different categories of a\n",
      "    population. The test is only meaningful when the dimension of\n",
      "    `observed` is two or more.  Applying the test to a one-dimensional\n",
      "    table will always result in `expected` equal to `observed` and a\n",
      "    chi-square statistic equal to 0.\n",
      "    \n",
      "    This function does not handle masked arrays, because the calculation\n",
      "    does not make sense with missing values.\n",
      "    \n",
      "    Like `scipy.stats.chisquare`, this function computes a chi-square\n",
      "    statistic; the convenience this function provides is to figure out the\n",
      "    expected frequencies and degrees of freedom from the given contingency\n",
      "    table. If these were already known, and if the Yates' correction was not\n",
      "    required, one could use `scipy.stats.chisquare`.  That is, if one calls::\n",
      "    \n",
      "        res = chi2_contingency(obs, correction=False)\n",
      "    \n",
      "    then the following is true::\n",
      "    \n",
      "        (res.statistic, res.pvalue) == stats.chisquare(obs.ravel(),\n",
      "                                                       f_exp=ex.ravel(),\n",
      "                                                       ddof=obs.size - 1 - dof)\n",
      "    \n",
      "    The `lambda_` argument was added in version 0.13.0 of scipy.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] \"Contingency table\",\n",
      "           https://en.wikipedia.org/wiki/Contingency_table\n",
      "    .. [2] \"Pearson's chi-squared test\",\n",
      "           https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test\n",
      "    .. [3] Cressie, N. and Read, T. R. C., \"Multinomial Goodness-of-Fit\n",
      "           Tests\", J. Royal Stat. Soc. Series B, Vol. 46, No. 3 (1984),\n",
      "           pp. 440-464.\n",
      "    .. [4] Berger, Jeffrey S. et al. \"Aspirin for the Primary Prevention of\n",
      "           Cardiovascular Events in Women and Men: A Sex-Specific\n",
      "           Meta-analysis of Randomized Controlled Trials.\"\n",
      "           JAMA, 295(3):306-313, :doi:`10.1001/jama.295.3.306`, 2006.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    In [4]_, the use of aspirin to prevent cardiovascular events in women\n",
      "    and men was investigated. The study notably concluded:\n",
      "    \n",
      "        ...aspirin therapy reduced the risk of a composite of\n",
      "        cardiovascular events due to its effect on reducing the risk of\n",
      "        ischemic stroke in women [...]\n",
      "    \n",
      "    The article lists studies of various cardiovascular events. Let's\n",
      "    focus on the ischemic stoke in women.\n",
      "    \n",
      "    The following table summarizes the results of the experiment in which\n",
      "    participants took aspirin or a placebo on a regular basis for several\n",
      "    years. Cases of ischemic stroke were recorded::\n",
      "    \n",
      "                          Aspirin   Control/Placebo\n",
      "        Ischemic stroke     176           230\n",
      "        No stroke         21035         21018\n",
      "    \n",
      "    Is there evidence that the aspirin reduces the risk of ischemic stroke?\n",
      "    We begin by formulating a null hypothesis :math:`H_0`:\n",
      "    \n",
      "        The effect of aspirin is equivalent to that of placebo.\n",
      "    \n",
      "    Let's assess the plausibility of this hypothesis with\n",
      "    a chi-square test.\n",
      "    \n",
      "    >>> import numpy as np\n",
      "    >>> from scipy.stats import chi2_contingency\n",
      "    >>> table = np.array([[176, 230], [21035, 21018]])\n",
      "    >>> res = chi2_contingency(table)\n",
      "    >>> res.statistic\n",
      "    6.892569132546561\n",
      "    >>> res.pvalue\n",
      "    0.008655478161175739\n",
      "    \n",
      "    Using a significance level of 5%, we would reject the null hypothesis in\n",
      "    favor of the alternative hypothesis: \"the effect of aspirin\n",
      "    is not equivalent to the effect of placebo\".\n",
      "    Because `scipy.stats.contingency.chi2_contingency` performs a two-sided\n",
      "    test, the alternative hypothesis does not indicate the direction of the\n",
      "    effect. We can use `stats.contingency.odds_ratio` to support the\n",
      "    conclusion that aspirin *reduces* the risk of ischemic stroke.\n",
      "    \n",
      "    Below are further examples showing how larger contingency tables can be\n",
      "    tested.\n",
      "    \n",
      "    A two-way example (2 x 3):\n",
      "    \n",
      "    >>> obs = np.array([[10, 10, 20], [20, 20, 20]])\n",
      "    >>> res = chi2_contingency(obs)\n",
      "    >>> res.statistic\n",
      "    2.7777777777777777\n",
      "    >>> res.pvalue\n",
      "    0.24935220877729619\n",
      "    >>> res.dof\n",
      "    2\n",
      "    >>> res.expected_freq\n",
      "    array([[ 12.,  12.,  16.],\n",
      "           [ 18.,  18.,  24.]])\n",
      "    \n",
      "    Perform the test using the log-likelihood ratio (i.e. the \"G-test\")\n",
      "    instead of Pearson's chi-squared statistic.\n",
      "    \n",
      "    >>> res = chi2_contingency(obs, lambda_=\"log-likelihood\")\n",
      "    >>> res.statistic\n",
      "    2.7688587616781319\n",
      "    >>> res.pvalue\n",
      "    0.25046668010954165\n",
      "    \n",
      "    A four-way example (2 x 2 x 2 x 2):\n",
      "    \n",
      "    >>> obs = np.array(\n",
      "    ...     [[[[12, 17],\n",
      "    ...        [11, 16]],\n",
      "    ...       [[11, 12],\n",
      "    ...        [15, 16]]],\n",
      "    ...      [[[23, 15],\n",
      "    ...        [30, 22]],\n",
      "    ...       [[14, 17],\n",
      "    ...        [15, 16]]]])\n",
      "    >>> res = chi2_contingency(obs)\n",
      "    >>> res.statistic\n",
      "    8.7584514426741897\n",
      "    >>> res.pvalue\n",
      "    0.64417725029295503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(scipy.stats.chi2_contingency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNa9GMFZf_DC"
   },
   "source": [
    "# 6회 기출문제 응용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6o8zU9sOa2h"
   },
   "source": [
    "## Section 1 응용\n",
    "- tips 데이터셋 활용한 적합성 검정\n",
    "- 정해진 비율의 차이가 실제로 존재하는지 확인하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1718947120294,
     "user": {
      "displayName": "Ji-hoon Jung",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "TiqqfLiyPPXK",
    "outputId": "73b98f82-e7b6-4e37-ef7c-3d48961860b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bftNacCtP3UZ"
   },
   "source": [
    "### 문제1\n",
    "- 문제 : Smoker가 'Yes'으로 분류된 남성과 여성의 비율을 소수점 이하 둘째 자리까지 출력하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "9AkcUr-LPzA0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "Male      0.645161\n",
       "Female    0.354839\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 코드\n",
    "\n",
    "sy = tips.loc[(tips[\"smoker\"] == \"Yes\"), :].reset_index(drop=True)\n",
    "\n",
    "sy['sex'].value_counts(dropna=False, normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UX8OFxcQ2sf"
   },
   "source": [
    "### 문제2\n",
    "- 팁을 준 고객들 중 남성과 여성의 비율이 50:50인지를 검정하는 간단한 적합도 검정을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1718947120294,
     "user": {
      "displayName": "Ji-hoon Jung",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "pFODLU6frrwJ",
    "outputId": "7ef2d91c-9452-4a77-fb0f-bc8e3f3eb6df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BootstrapMethod,CensoredData,ConstantInputWarning,Covariance,DegenerateDataWarning,FitError,MonteCarloMethod,NearConstantInputWarning,PermutationMethod,__all__,__builtins__,__cached__,__doc__,__file__,__loader__,__name__,__package__,__path__,__spec__,_ansari_swilk_statistics,_axis_nan_policy,_biasedurn,_binned_statistic,_binomtest,_bws_test,_censored_data,_common,_constants,_continuous_distns,_covariance,_crosstab,_discrete_distns,_distn_infrastructure,_distr_params,_entropy,_fit,_hypotests,_kde,_ksstats,_levy_stable,_mannwhitneyu,_mgc,_morestats,_mstats_basic,_mstats_extras,_multicomp,_multivariate,_mvn,_odds_ratio,_page_trend_test,_qmc,_qmc_cy,_qmvnt,_rcont,_relative_risk,_resampling,_rvs_sampling,_sampling,_sensitivity_analysis,_sobol,_stats,_stats_mstats_common,_stats_py,_stats_pythran,_survival,_tukeylambda_stats,_unuran,_variation,_warnings_errors,_wilcoxon,alexandergovern,alpha,anderson,anderson_ksamp,anglit,ansari,arcsine,argus,barnard_exact,bartlett,bayes_mvs,bernoulli,beta,betabinom,betanbinom,betaprime,biasedurn,binned_statistic,binned_statistic_2d,binned_statistic_dd,binom,binomtest,boltzmann,bootstrap,boschloo_exact,boxcox,boxcox_llf,boxcox_normmax,boxcox_normplot,bradford,brunnermunzel,burr,burr12,bws_test,cauchy,chi,chi2,chi2_contingency,chisquare,circmean,circstd,circvar,combine_pvalues,contingency,cosine,cramervonmises,cramervonmises_2samp,crystalball,cumfreq,describe,dgamma,differential_entropy,directional_stats,dirichlet,dirichlet_multinomial,distributions,dlaplace,dunnett,dweibull,ecdf,energy_distance,entropy,epps_singleton_2samp,erlang,expectile,expon,exponnorm,exponpow,exponweib,f,f_oneway,false_discovery_control,fatiguelife,find_repeats,fisher_exact,fisk,fit,fligner,foldcauchy,foldnorm,friedmanchisquare,gamma,gausshyper,gaussian_kde,genexpon,genextreme,gengamma,genhalflogistic,genhyperbolic,geninvgauss,genlogistic,gennorm,genpareto,geom,gibrat,gmean,gompertz,goodness_of_fit,gstd,gumbel_l,gumbel_r,gzscore,halfcauchy,halfgennorm,halflogistic,halfnorm,hmean,hypergeom,hypsecant,invgamma,invgauss,invweibull,invwishart,iqr,irwinhall,jarque_bera,jf_skew_t,johnsonsb,johnsonsu,kappa3,kappa4,kde,kendalltau,kruskal,ks_1samp,ks_2samp,ksone,kstat,kstatvar,kstest,kstwo,kstwobign,kurtosis,kurtosistest,laplace,laplace_asymmetric,levene,levy,levy_l,levy_stable,linregress,loggamma,logistic,loglaplace,lognorm,logrank,logser,loguniform,lomax,mannwhitneyu,matrix_normal,maxwell,median_abs_deviation,median_test,mielke,mode,moment,monte_carlo_test,mood,morestats,moyal,mstats,mstats_basic,mstats_extras,multinomial,multiscale_graphcorr,multivariate_hypergeom,multivariate_normal,multivariate_t,mvn,mvsdist,nakagami,nbinom,ncf,nchypergeom_fisher,nchypergeom_wallenius,nct,ncx2,nhypergeom,norm,normaltest,norminvgauss,obrientransform,ortho_group,page_trend_test,pareto,pearson3,pearsonr,percentileofscore,permutation_test,planck,pmean,pointbiserialr,poisson,poisson_means_test,power,power_divergence,powerlaw,powerlognorm,powernorm,ppcc_max,ppcc_plot,probplot,qmc,quantile_test,randint,random_correlation,random_table,rankdata,ranksums,rayleigh,rdist,recipinvgauss,reciprocal,rel_breitwigner,relfreq,rice,rv_continuous,rv_discrete,rv_histogram,rvs_ratio_uniforms,sampling,scoreatpercentile,sem,semicircular,shapiro,siegelslopes,sigmaclip,skellam,skew,skewcauchy,skewnorm,skewtest,sobol_indices,somersd,spearmanr,special_ortho_group,stats,studentized_range,t,test,theilslopes,tiecorrect,tmax,tmean,tmin,trapezoid,trapz,triang,trim1,trim_mean,trimboth,truncexpon,truncnorm,truncpareto,truncweibull_min,tsem,tstd,ttest_1samp,ttest_ind,ttest_ind_from_stats,ttest_rel,tukey_hsd,tukeylambda,tvar,uniform,uniform_direction,unitary_group,variation,vonmises,vonmises_fisher,vonmises_line,wald,wasserstein_distance,wasserstein_distance_nd,weibull_max,weibull_min,weightedtau,wilcoxon,wishart,wrapcauchy,yeojohnson,yeojohnson_llf,yeojohnson_normmax,yeojohnson_normplot,yulesimon,zipf,zipfian,zmap,zscore'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "\",\".join(dir(scipy.stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1718947120295,
     "user": {
      "displayName": "Ji-hoon Jung",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "TM9oSLdJuWUU",
    "outputId": "c21548b4-17a2-4a88-c2b1-da06b9afad0a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function chisquare in module scipy.stats._stats_py:\n",
      "\n",
      "chisquare(f_obs, f_exp=None, ddof=0, axis=0)\n",
      "    Calculate a one-way chi-square test.\n",
      "    \n",
      "    The chi-square test tests the null hypothesis that the categorical data\n",
      "    has the given frequencies.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    f_obs : array_like\n",
      "        Observed frequencies in each category.\n",
      "    f_exp : array_like, optional\n",
      "        Expected frequencies in each category.  By default the categories are\n",
      "        assumed to be equally likely.\n",
      "    ddof : int, optional\n",
      "        \"Delta degrees of freedom\": adjustment to the degrees of freedom\n",
      "        for the p-value.  The p-value is computed using a chi-squared\n",
      "        distribution with ``k - 1 - ddof`` degrees of freedom, where `k`\n",
      "        is the number of observed frequencies.  The default value of `ddof`\n",
      "        is 0.\n",
      "    axis : int or None, optional\n",
      "        The axis of the broadcast result of `f_obs` and `f_exp` along which to\n",
      "        apply the test.  If axis is None, all values in `f_obs` are treated\n",
      "        as a single data set.  Default is 0.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    res: Power_divergenceResult\n",
      "        An object containing attributes:\n",
      "    \n",
      "        statistic : float or ndarray\n",
      "            The chi-squared test statistic.  The value is a float if `axis` is\n",
      "            None or `f_obs` and `f_exp` are 1-D.\n",
      "        pvalue : float or ndarray\n",
      "            The p-value of the test.  The value is a float if `ddof` and the\n",
      "            result attribute `statistic` are scalars.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    scipy.stats.power_divergence\n",
      "    scipy.stats.fisher_exact : Fisher exact test on a 2x2 contingency table.\n",
      "    scipy.stats.barnard_exact : An unconditional exact test. An alternative\n",
      "        to chi-squared test for small sample sizes.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This test is invalid when the observed or expected frequencies in each\n",
      "    category are too small.  A typical rule is that all of the observed\n",
      "    and expected frequencies should be at least 5. According to [3]_, the\n",
      "    total number of samples is recommended to be greater than 13,\n",
      "    otherwise exact tests (such as Barnard's Exact test) should be used\n",
      "    because they do not overreject.\n",
      "    \n",
      "    Also, the sum of the observed and expected frequencies must be the same\n",
      "    for the test to be valid; `chisquare` raises an error if the sums do not\n",
      "    agree within a relative tolerance of ``1e-8``.\n",
      "    \n",
      "    The default degrees of freedom, k-1, are for the case when no parameters\n",
      "    of the distribution are estimated. If p parameters are estimated by\n",
      "    efficient maximum likelihood then the correct degrees of freedom are\n",
      "    k-1-p. If the parameters are estimated in a different way, then the\n",
      "    dof can be between k-1-p and k-1. However, it is also possible that\n",
      "    the asymptotic distribution is not chi-square, in which case this test\n",
      "    is not appropriate.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Lowry, Richard.  \"Concepts and Applications of Inferential\n",
      "           Statistics\". Chapter 8.\n",
      "           https://web.archive.org/web/20171022032306/http://vassarstats.net:80/textbook/ch8pt1.html\n",
      "    .. [2] \"Chi-squared test\", https://en.wikipedia.org/wiki/Chi-squared_test\n",
      "    .. [3] Pearson, Karl. \"On the criterion that a given system of deviations from the probable\n",
      "           in the case of a correlated system of variables is such that it can be reasonably\n",
      "           supposed to have arisen from random sampling\", Philosophical Magazine. Series 5. 50\n",
      "           (1900), pp. 157-175.\n",
      "    .. [4] Mannan, R. William and E. Charles. Meslow. \"Bird populations and\n",
      "           vegetation characteristics in managed and old-growth forests,\n",
      "           northeastern Oregon.\" Journal of Wildlife Management\n",
      "           48, 1219-1238, :doi:`10.2307/3801783`, 1984.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    In [4]_, bird foraging behavior was investigated in an old-growth forest\n",
      "    of Oregon.\n",
      "    In the forest, 44% of the canopy volume was Douglas fir,\n",
      "    24% was ponderosa pine, 29% was grand fir, and 3% was western larch.\n",
      "    The authors observed the behavior of several species of birds, one of\n",
      "    which was the red-breasted nuthatch. They made 189 observations of this\n",
      "    species foraging, recording 43 (\"23%\") of observations in Douglas fir,\n",
      "    52 (\"28%\") in ponderosa pine, 54 (\"29%\") in grand fir, and 40 (\"21%\") in\n",
      "    western larch.\n",
      "    \n",
      "    Using a chi-square test, we can test the null hypothesis that the\n",
      "    proportions of foraging events are equal to the proportions of canopy\n",
      "    volume. The authors of the paper considered a p-value less than 1% to be\n",
      "    significant.\n",
      "    \n",
      "    Using the above proportions of canopy volume and observed events, we can\n",
      "    infer expected frequencies.\n",
      "    \n",
      "    >>> import numpy as np\n",
      "    >>> f_exp = np.array([44, 24, 29, 3]) / 100 * 189\n",
      "    \n",
      "    The observed frequencies of foraging were:\n",
      "    \n",
      "    >>> f_obs = np.array([43, 52, 54, 40])\n",
      "    \n",
      "    We can now compare the observed frequencies with the expected frequencies.\n",
      "    \n",
      "    >>> from scipy.stats import chisquare\n",
      "    >>> chisquare(f_obs=f_obs, f_exp=f_exp)\n",
      "    Power_divergenceResult(statistic=228.23515947653874, pvalue=3.3295585338846486e-49)\n",
      "    \n",
      "    The p-value is well below the chosen significance level. Hence, the\n",
      "    authors considered the difference to be significant and concluded\n",
      "    that the relative proportions of foraging events were not the same\n",
      "    as the relative proportions of tree canopy volume.\n",
      "    \n",
      "    Following are other generic examples to demonstrate how the other\n",
      "    parameters can be used.\n",
      "    \n",
      "    When just `f_obs` is given, it is assumed that the expected frequencies\n",
      "    are uniform and given by the mean of the observed frequencies.\n",
      "    \n",
      "    >>> chisquare([16, 18, 16, 14, 12, 12])\n",
      "    Power_divergenceResult(statistic=2.0, pvalue=0.84914503608460956)\n",
      "    \n",
      "    With `f_exp` the expected frequencies can be given.\n",
      "    \n",
      "    >>> chisquare([16, 18, 16, 14, 12, 12], f_exp=[16, 16, 16, 16, 16, 8])\n",
      "    Power_divergenceResult(statistic=3.5, pvalue=0.62338762774958223)\n",
      "    \n",
      "    When `f_obs` is 2-D, by default the test is applied to each column.\n",
      "    \n",
      "    >>> obs = np.array([[16, 18, 16, 14, 12, 12], [32, 24, 16, 28, 20, 24]]).T\n",
      "    >>> obs.shape\n",
      "    (6, 2)\n",
      "    >>> chisquare(obs)\n",
      "    Power_divergenceResult(statistic=array([2.        , 6.66666667]), pvalue=array([0.84914504, 0.24663415]))\n",
      "    \n",
      "    By setting ``axis=None``, the test is applied to all data in the array,\n",
      "    which is equivalent to applying the test to the flattened array.\n",
      "    \n",
      "    >>> chisquare(obs, axis=None)\n",
      "    Power_divergenceResult(statistic=23.31034482758621, pvalue=0.015975692534127565)\n",
      "    >>> chisquare(obs.ravel())\n",
      "    Power_divergenceResult(statistic=23.310344827586206, pvalue=0.01597569253412758)\n",
      "    \n",
      "    `ddof` is the change to make to the default degrees of freedom.\n",
      "    \n",
      "    >>> chisquare([16, 18, 16, 14, 12, 12], ddof=1)\n",
      "    Power_divergenceResult(statistic=2.0, pvalue=0.7357588823428847)\n",
      "    \n",
      "    The calculation of the p-values is done by broadcasting the\n",
      "    chi-squared statistic with `ddof`.\n",
      "    \n",
      "    >>> chisquare([16, 18, 16, 14, 12, 12], ddof=[0,1,2])\n",
      "    Power_divergenceResult(statistic=2.0, pvalue=array([0.84914504, 0.73575888, 0.5724067 ]))\n",
      "    \n",
      "    `f_obs` and `f_exp` are also broadcast.  In the following, `f_obs` has\n",
      "    shape (6,) and `f_exp` has shape (2, 6), so the result of broadcasting\n",
      "    `f_obs` and `f_exp` has shape (2, 6).  To compute the desired chi-squared\n",
      "    statistics, we use ``axis=1``:\n",
      "    \n",
      "    >>> chisquare([16, 18, 16, 14, 12, 12],\n",
      "    ...           f_exp=[[16, 16, 16, 16, 16, 8], [8, 20, 20, 16, 12, 12]],\n",
      "    ...           axis=1)\n",
      "    Power_divergenceResult(statistic=array([3.5 , 9.25]), pvalue=array([0.62338763, 0.09949846]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(scipy.stats.chisquare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kb6e1_yp-cd0"
   },
   "source": [
    "- 팁을 준 고객들 중 남성과 여성의 비율이 50:50인지를 검정하는 간단한 적합도 검정을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "zUFtdeEuRAN5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "카이제곱 통계량: 7.838709677419355\n",
      "p-값: 0.0051\n"
     ]
    }
   ],
   "source": [
    "# 코드\n",
    "\n",
    "# 성별 비율 계산\n",
    "sex_counts = sy['sex'].value_counts()\n",
    "\n",
    "# 기대 비율 계산\n",
    "expected_counts = [0.5 * len(sy)] * 2\n",
    "\n",
    "# 카이제곱 적합도 검정 수행\n",
    "chi2_stat, p_val = scipy.stats.chisquare(f_obs=sex_counts, f_exp=expected_counts)\n",
    "\n",
    "print(\"카이제곱 통계량:\", chi2_stat)\n",
    "print(\"p-값:\", p_val.round(4))\n",
    "\n",
    "# 위 코드에서 chi2_stat는 카이제곱 통계량을, p_val은 p-값을 나타냅니다. \n",
    "# p-값이 유의 수준(예: 0.05)보다 작으면 귀무가설(남성과 여성의 비율이 50:50이다)을 기각할 수 있습니다.\n",
    "\n",
    "# 따라서 기각"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F88tK_2AReCl"
   },
   "source": [
    "### 문제3\n",
    "- 위의 통계량에 대한 유의확률(p-value)을 출력(반올림하여 소수점 이하 넷째 자리까지 계산)하고, 유의수준 5% 하에서 가설 검정의 결과를 (귀무가설 채택 / 기각) 중 하나를 선택하시오.\n",
    "- 가설검정\n",
    "  + 귀무가설 : 남성과 여성 고객의 비율이 50:50이다.\n",
    "  + 대립가설 : 남성과 여성 고객의 비율이 50:50이 아니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ecSZSYRRzoD"
   },
   "source": [
    "## Section 2 응용\n",
    "- diamonds 데이터셋 활용\n",
    "- 결측치(NA)를 포함하는 모든 행을 제거한 후, (carat, depth, table) 항목을 이용하여 price를 예측하는 다중 선형회귀 모형을 구축하고 다음 수행 결과를 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1718947120295,
     "user": {
      "displayName": "Ji-hoon Jung",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "on4sNLxYSg1Q",
    "outputId": "bc608e34-0351-4c6c-d0ef-2065c13a6a10"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat    cut color clarity  depth  table  price     x     y     z\n",
       "0   0.23  Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "diamonds = sns.load_dataset(\"diamonds\")\n",
    "diamonds.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1718947120295,
     "user": {
      "displayName": "Ji-hoon Jung",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "UPs5wFvpSro6",
    "outputId": "e92b9ad6-b3f9-4b05-a44f-8b73c2a2833f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = diamonds.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1718947120295,
     "user": {
      "displayName": "Ji-hoon Jung",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "gSXrxgASxhcY",
    "outputId": "3e72dc68-17ca-4872-af1d-2096235e0558"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53940, 10), (53940, 10))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, diamonds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuJQCmHFThGC",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 문제1\n",
    "- carat 항목에 대한 회귀계수를 구하시오. 단, 출력문은 print()를 이용하고 소수점 이하 넷째 자리에서 반올림하여 소수점 이하 셋째 자리까지 출력하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "iSYdj1nTTdM6"
   },
   "outputs": [],
   "source": [
    "# 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzIeUFsLYBY-"
   },
   "source": [
    "### 문제2\n",
    "- table 항목에 대한 t-통계량을 소수점 이하 셋째 자리까지 출력하시오.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldbMk2BedCTv"
   },
   "source": [
    "### 문제3\n",
    "- 다음 예측변수 값에 대한 Price를 예측하고, carat 항목의 계수값에 대한 95% 신뢰구간을 출력하시오.\n",
    "  + carat = 0.35,\n",
    "  + depth = 57.5\n",
    "  + table = 53.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EyoR6y7VgDqB"
   },
   "source": [
    "# 7회 기출문제 응용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrNsKyplTbOZ"
   },
   "source": [
    "## Section1 응용\n",
    "- boston 데이터 중에서 상관관계가 가장 작은 값을 구하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 78704,
     "status": "ok",
     "timestamp": 1720351862731,
     "user": {
      "displayName": "Ji-hoon Jung",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "0-vRLwu0zzw-",
    "outputId": "402d4e25-5586-4d8c-e79d-b6cb93f38ab6"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "executionInfo": {
     "elapsed": 2217,
     "status": "ok",
     "timestamp": 1720352769726,
     "user": {
      "displayName": "Ji-hoon Jung",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "ePVFpGsLTep-",
    "outputId": "89d1ecf1-5819-4479-a56d-4ec977883095"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/2024/한경-토스뱅크/통계실습문제/'\n",
    "df = pd.read_csv(DATA_PATH + \"boston.csv\", encoding=\"euc-kr\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "executionInfo": {
     "elapsed": 491,
     "status": "ok",
     "timestamp": 1720352772685,
     "user": {
      "displayName": "Ji-hoon Jung",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "Mfr8VEEqUJYF",
    "outputId": "885cfd47-e152-46bf-a103-f3988b64dd54"
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hc9GrCf9UN8k"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdQz5VCmUWAV"
   },
   "source": [
    "## Section2 응용\n",
    "- tips 데이터를 이용하여 total_bill과 tip 사이의 관계를 분석한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcRxgwrHMovj"
   },
   "source": [
    "### 문제 1\n",
    "- total bill을 이용하여 tip을 예측하는 모형을 구축하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LtTTXrXRUYzv"
   },
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zVsyILVNKHb"
   },
   "source": [
    "### 문제2\n",
    "- 구축된 모형에 대한 결정계수의 값을 출력하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7V2AWfAj8kkR"
   },
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xViNjQDPOtqn"
   },
   "source": [
    "### 문제3\n",
    "- tip에 대한 키의 오즈비(Odds Ratio, total bill의 변화가 몸무게 로그 오즈에 미치는 영향을 출력하시오)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TzTmye6Z8m4k"
   },
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q43tcEAvR3sm"
   },
   "source": [
    "## Section3 응용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvWWlIdRQlop"
   },
   "source": [
    "### 문제1\n",
    "- 독립변수 total_bill, tip으로 sex를 이용하여 성별(Male=0, Female=1)을 분류하는 모형을 구축하시오.\n",
    "- statsmodels.api에 포함되어 있는 Logit 함수를 이용하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LIg_BD9f8n5-"
   },
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VoTWZHBsQiJZ"
   },
   "source": [
    "### 문제2\n",
    "- 키, 몸무게에 대한 유의확률을 출력하고 최대 유의확률 값을 출력하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z64vX7Y88o1g"
   },
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23ofRMDYTWH6"
   },
   "source": [
    "### 문제3\n",
    "- 훈련:평가=70:30로 구분하여 평가 데이터에 대한 혼동행렬 ROC, AUC를 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 789
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1718947123776,
     "user": {
      "displayName": "Ji-hoon Jung",
      "userId": "03169308685755834042"
     },
     "user_tz": -540
    },
    "id": "432aG4xIQVTW",
    "outputId": "026afbd4-890a-4063-f66b-21f27d8c9332"
   },
   "outputs": [],
   "source": [
    "# 머신러닝 문제\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(12)\n",
    "\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "df = tips.copy()\n",
    "df = df.dropna()\n",
    "df.loc[:, '성별_변환'] = df['smoker'].replace({'Yes':0, 'No':1})\n",
    "print(tips.shape, df.shape)\n",
    "\n",
    "X = df.loc[:, ['total_bill', 'tip']]\n",
    "y = df['성별_변환']\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# 데이터셋 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=12\n",
    ")\n",
    "\n",
    "# 모델 생성\n",
    "model = sm.Logit(y_train, X_train).fit()\n",
    "print(model.summary())\n",
    "\n",
    "# 모델 예측값 생성\n",
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = np.where(y_pred_proba >= 0.5, 1, 0)\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "# roc_auc_score(y_test, y_pred) AUC 점수를 바로 구하는 코드\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "auc(fpr, tpr) # AUC 점수를 ROC_CURVE 메서드 활용\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr, tpr, color = 'darkblue')\n",
    "ax.plot([0, 1], [0, 1], lw=2, linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
