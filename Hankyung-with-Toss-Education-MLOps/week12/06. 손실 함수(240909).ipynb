{"cells":[{"cell_type":"markdown","metadata":{"id":"W1LefL1cpX0p"},"source":["# 손실함수\n","머신러닝 모델의 성능 지표(metric)\n","- Accuracy\n","- F1-Score\n","- Precision, Recall,\n","- ROC - AUC\n","- 추가적으로 딥러닝에서는 Loss라는 지표를 우선시 한다.언제? 훈련 할 때"]},{"cell_type":"markdown","metadata":{"id":"lPDpkKb8pdxh"},"source":["# 평균 제곱 오차 ( Mean Squared Error )\n","신경망에서의 MSE\n","$$\n","MSE = \\frac{1}{2}\\sum_k(y_k-t_k)^2\n","$$\n","\n","인간이 신경망을 공부할 때 사용하는 공부용 MSE 입니다..\n","\n","* $y_k$ : 신경망의 예측값\n","* $t_k$ : 정답 레이블\n","* $k$ : 출력층의 뉴런 개수\n","  * `강아지, 고양이, 말을 예측 하면` $k$는 3 - `클래스는 [0, 1, 2]`\n","  * MNIST 손글씨 데이터 셋이면 $k$는 10 - `클래스는 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]`\n","\n","----------\n","* 보통 신경망에서는 `MSE`를 잘 쓰지 않고 `Cross Entropy Error`를 활용\n","  * `MSE`는 신경망으로 회귀를 할 때 많이 사용\n","* `MSE`를 배우는 이유는 말 그대로 `loss`에 대한 이해를 하기 위함\n","* `MSE`는 신경망을 우리가 공부 할 때 개념을 익히는 데에 좋다. ( 실무에서는 사용 잘 안한다. )\n","* 정상적인 $\\frac{1}{n}$을 사용하지 않고 $\\frac{1}{2}$을 사용한 이유는\n","  * `MSE`를 미분 했을 때 남는게 순수한 오차라고 할 수 있는 $(y-t)$만 남기 때문에"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":444,"status":"ok","timestamp":1725866729997,"user":{"displayName":"소민호","userId":"13788803923072454204"},"user_tz":-540},"id":"22okor7GqCiP"},"outputs":[],"source":["import numpy as np\n","\n","# y : 예측\n","y = np.array([0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 60%\n","\n","# t : 타깃\n","t = np.array([0,      0,   1,   0,    0,   0,   0,   0,   0,   0]) # 정답은 2라는 이야기 이다. 클래스의 개수만큼 One Hot Encoding이 되어있는 상태"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":499,"status":"ok","timestamp":1725866766481,"user":{"displayName":"소민호","userId":"13788803923072454204"},"user_tz":-540},"id":"iObjIqmMrDex","outputId":"b9aeb6b4-fba4-4640-8836-ee527f50a5b7"},"outputs":[{"data":{"text/plain":["array([ 0.1 ,  0.05, -0.4 ,  0.  ,  0.05,  0.1 ,  0.  ,  0.1 ,  0.  ,\n","        0.  ])"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# 각 클래스 별 순수한 오차\n","y - t"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":477,"status":"ok","timestamp":1725866862538,"user":{"displayName":"소민호","userId":"13788803923072454204"},"user_tz":-540},"id":"hDxe8hpnrOwP"},"outputs":[],"source":["def mean_squared_error(y, t):\n","  return np.sum((y - t)**2) * 0.5"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":509,"status":"ok","timestamp":1725866903247,"user":{"displayName":"소민호","userId":"13788803923072454204"},"user_tz":-540},"id":"Ii7QsYEQrmNs","outputId":"b98c6032-1e90-494e-8187-1c328c27a848"},"outputs":[{"data":{"text/plain":["0.09750000000000003"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# 모델이 정답을 2로 추정 했을 때의 예측 오차(2로 예측한 확률이 0.6)\n","mean_squared_error(y, t)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":465,"status":"ok","timestamp":1725867065632,"user":{"displayName":"소민호","userId":"13788803923072454204"},"user_tz":-540},"id":"rNh0OIIQrv79","outputId":"e606f41f-1288-4c4e-efba-d91f8971f352"},"outputs":[{"name":"stdout","output_type":"stream","text":["정답을 2로 추정했을 때의 MSE값(0.6) : 0.098\n","정답을 2로 추정했을 때의 MSE값(0.8) : 0.027\n","정답을 2로 추정했을 때의 MSE값(0.1) : 0.657\n"]}],"source":["y = np.array([0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 60%\n","print(\"정답을 2로 추정했을 때의 MSE값(0.6) : {:.3f}\".format(mean_squared_error(y, t)))\n","\n","y = np.array([0.1, 0.05, 0.8, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 80%\n","print(\"정답을 2로 추정했을 때의 MSE값(0.8) : {:.3f}\".format(mean_squared_error(y, t)))\n","\n","y = np.array([0.7, 0.05, 0.1 , 0.0, 0.05, 0.0, 0.0, 0.1, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 10%\n","print(\"정답을 2로 추정했을 때의 MSE값(0.1) : {:.3f}\".format(mean_squared_error(y, t)))"]},{"cell_type":"markdown","metadata":{"id":"kMhbf791sWWv"},"source":["# 교차 엔트로피 오차( Cross Entropy Error )\n","$$\n","CEE = -\\sum_{k}t_k\\log{y_k}\n","$$\n","\n","* $t_k$는 `One Hot Encoding`이 되어있는 상태\n","* $k$는 클래스의 개수\n","* 정답 레이블의 소프트맥스의 결과가 0.6이면 $-\\log{0.6}$을 구한것과 똑같다."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1045,"status":"ok","timestamp":1725867488475,"user":{"displayName":"소민호","userId":"13788803923072454204"},"user_tz":-540},"id":"1kdnJ7emsnNc"},"outputs":[],"source":["def cross_entropy_error(y, t):\n","  delta = 1e-7 # epsilon이라고도 합니다. log 0이 되는 것을 방지\n","  return -np.sum(t * np.log(y + delta))"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":676,"status":"ok","timestamp":1725867498261,"user":{"displayName":"소민호","userId":"13788803923072454204"},"user_tz":-540},"id":"wfW2nR3OtweG","outputId":"7b4ce6d4-d448-41de-9ddf-d4114bba925c"},"outputs":[{"name":"stdout","output_type":"stream","text":["정답을 2로 추정했을 때의 CEE값(0.6) : 0.511\n","정답을 2로 추정했을 때의 CEE값(0.8) : 0.223\n","정답을 2로 추정했을 때의 CEE값(0.1) : 2.303\n"]}],"source":["t = np.array([0, 0, 1,   0,    0,   0,   0,   0,   0,   0]) # 정답은 2\n","\n","y = np.array([0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 60%\n","print(\"정답을 2로 추정했을 때의 CEE값(0.6) : {:.3f}\".format(cross_entropy_error(y, t)))\n","\n","y = np.array([0.1, 0.05, 0.8, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 80%\n","print(\"정답을 2로 추정했을 때의 CEE값(0.8) : {:.3f}\".format(cross_entropy_error(y, t)))\n","\n","y = np.array([0.7, 0.05, 0.1 , 0.0, 0.05, 0.0, 0.0, 0.1, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 10%\n","print(\"정답을 2로 추정했을 때의 CEE값(0.1) : {:.3f}\".format(cross_entropy_error(y, t)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1L-bUE29uBOe"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMeklsA8SiOaePk6lYheeAn","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.19"}},"nbformat":4,"nbformat_minor":0}
