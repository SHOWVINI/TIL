{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# 정리하자면:\n",
    "\n",
    "# DataLoader: 데이터 배치를 관리하고, 모델에 데이터를 공급하는 역할.\n",
    "# datasets: 다양한 데이터셋을 쉽게 로드할 수 있도록 도와주는 모듈.\n",
    "# ToTensor: 데이터를 PyTorch 텐서로 변환하는 전처리 과정.\n",
    "\n",
    "# 이 세 가지를 활용해 데이터셋을 불러오고, 이를 텐서로 변환한 후, 모델 학습을 위한 배치 단위로 관리할 수 있습니다.\n",
    "\n",
    "# DataLoader:\n",
    "\n",
    "#     DataLoader는 모델 학습에 사용되는 데이터셋을 쉽게 관리하고, 배치(batch) 단위로 나눠 모델에 공급할 수 있도록 도와줍니다.\n",
    "#     주된 역할은 데이터를 여러 개의 작은 배치로 나누고, 순차적으로 모델에 전달하여 효율적인 학습을 할 수 있게 하는 것입니다.\n",
    "#     주요 기능:\n",
    "#         데이터를 배치 크기대로 나눔 (batching).\n",
    "#         데이터셋을 섞음 (shuffling).\n",
    "#         멀티스레딩을 이용해 데이터 로딩 속도를 향상 (병렬 처리).\n",
    "#         이터레이터처럼 동작해 쉽게 데이터를 순차적으로 불러옴.\n",
    "\n",
    "# datasets:\n",
    "\n",
    "#     PyTorch에서 다양한 미리 정의된 데이터셋을 제공하는 모듈입니다. \n",
    "#         예를 들어, datasets.MNIST, datasets.CIFAR10 같은 유명한 데이터셋을 쉽게 불러올 수 있습니다.\n",
    "#     일반적으로 datasets 모듈을 이용해 데이터를 다운로드하고, 이를 바로 모델에 사용할 수 있는 형태로 변환할 수 있습니다.\n",
    "#     PyTorch는 다양한 이미지, 텍스트, 오디오 등의 데이터셋을 지원하며, 직접 데이터를 정의하는 것도 가능합니다.\n",
    "\n",
    "# ToTensor:\n",
    "\n",
    "#     ToTensor는 PIL 이미지 또는 NumPy 배열을 PyTorch 텐서(Tensor)로 변환하는 전처리 작업을 수행하는 변환(transform)입니다.\n",
    "#     특히 이미지를 모델에 입력할 수 있는 텐서 형태로 변환하고, 픽셀 값을 0과 1 사이로 정규화(255로 나누어)하는 작업을 수행합니다.\n",
    "#     보통 transforms 모듈과 함께 사용되며, 데이터 전처리 파이프라인의 일부분으로 사용됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\", # 데이터를 저장할 root 디렉토리\n",
    "    train=True, # 훈련용 데이터 설정\n",
    "    download=True, # 다운로드\n",
    "    transform=ToTensor() # 이미지 변환. 여기서는 TorchTesnor로 변환시킵니다.\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "# train=True: 모델을 학습하기 위한 데이터셋을 로드.\n",
    "\n",
    "# 훈련용 데이터셋을 가져옵니다.\n",
    "# 모델의 학습에 사용됩니다.\n",
    "# 데이터는 일반적으로 레이블과 함께 제공되며, 모델이 데이터를 학습하면서 가중치(weight)를 업데이트할 수 있도록 합니다.\n",
    "# 데이터셋에 **데이터 증강(augmentation)**과 같은 전처리 작업을 적용할 수 있습니다. 이는 모델이 더 일반화될 수 있도록 돕습니다.\n",
    "# 보통 에폭(epoch) 단위로 여러 번 반복해서 모델이 데이터셋을 학습합니다.\n",
    "\n",
    "# train=False: 학습된 모델의 성능을 평가하기 위한 테스트 데이터셋을 로드.\n",
    "\n",
    "# 테스트용 데이터셋을 가져옵니다.\n",
    "# 모델의 학습이 완료된 후, 성능을 평가하기 위해 사용됩니다.\n",
    "# 테스트 데이터는 모델이 본 적 없는 데이터로, 모델의 일반화 능력을 평가하는 데 중요합니다.\n",
    "# 테스트 과정에서는 가중치가 업데이트되지 않으며, 단지 모델의 예측 성능을 확인하는 데 사용됩니다.\n",
    "# 보통 **데이터 증강(augmentation)**을 적용하지 않습니다. 테스트 데이터는 모델의 성능을 정확하게 평가하기 위한 기준이기 때문에, 가능한 원본 데이터 그대로 사용하는 것이 일반적입니다.\n",
    "\n",
    "\n",
    "# **데이터 증강(Data Augmentation)**은 기존의 데이터셋을 인위적으로 변형하여 새로운 데이터를 생성함으로써 모델이 더 다양한 상황을 학습하도록 돕는 방법입니다. \n",
    "# 특히 컴퓨터 비전 분야에서 많이 사용되며, 데이터를 증강하면 모델의 일반화 성능을 향상시킬 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_dataloader  = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # nn.Sequential을 이용해 연속되는 레이어의 구조를 구성: 리스트처럼 여러 레이어 또는 연산을 전달받아, 전달된 순서대로 입력 데이터에 대해 연산을 수행\n",
    "            # 각 레이어나 연산을 일일이 호출하지 않고도 한 번에 처리할 수 있기 때문에, 간단한 모델을 정의할 때 매우 유용합니다.\n",
    "            # 모델의 forward 메서드에서 따로 연산을 정의할 필요 없이, 자동으로 순차적으로 진행됩니다.\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        y = self.linear_relu_stack(x)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model running on: mps\n",
      "==========================================================================\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# MPS 지원 여부 확인\n",
    "if torch.backends.mps.is_available():\n",
    "    device = 'mps'  # MPS 사용\n",
    "elif torch.cuda.is_available():\n",
    "    device = 'cuda'  # CUDA 사용 가능 시\n",
    "else:\n",
    "    device = 'cpu'  # 그 외에는 CPU 사용\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "# PyTorch에서 모델을 특정 장치(device)로 옮기는 코드입니다. \n",
    "# 여기서 device는 CPU, CUDA(GPU), 또는 Apple Silicon의 MPS 등을 가리킬 수 있습니다.\n",
    "\n",
    "# PyTorch에서는 CPU와 GPU 간의 연산이 엄격하게 구분되어 있기 때문에, 모델과 데이터를 동일한 장치에 있어야 합니다. \n",
    "# 즉, 모델이 GPU에 있으면 입력 데이터도 GPU에 있어야 하고, 모델이 CPU에 있으면 데이터도 CPU에 있어야 합니다. \n",
    "# 따라서 .to(device)를 사용하여 모델을 원하는 장치로 옮기는 것이 필요합니다.\n",
    "\n",
    "print(f\"Model running on: {device}\")\n",
    "\n",
    "print(\"==========================================================================\")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위 코드까지는 모두 03. PyTorch Modeling ⭐️(240923) 내용에서 배운 코드\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 훈련\n",
    "\n",
    "파이토치의 모델 훈련을 위해서는 손실함수, 최적화 함수를 등록해야 합니다. 특히 최적화 함수를 사용하기 위해서는 `model.parameters()` 메소드를 이용해 최적화 대상 파라미터를 지정해주면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 짱짱 중요함\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer : 경사하강법을 수행하기 위한 함수. 경사하강법은 어디에 수행해? W, b -> parameters\n",
    "# model에서 파라미터를 꺼내다가 최적화 함수에 등록\n",
    "\n",
    "# nn.CrossEntropyLoss()는 내부적으로 소프트맥스와 NLL 손실을 결합하여, 로지츠에서 바로 손실을 계산합니다. \n",
    "# 그렇기 때문에 별도의 소프트맥스 함수를 적용할 필요가 없습니다. 모델 출력(로지츠)을 그대로 입력으로 넣어주면 됩니다.\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 과정(훈련 루프 정의)\n",
    "#  1. dataloader에서 데이터를 꺼낸다.\n",
    "#  2. 데이터를 모델에 통과시킨다. (순전파를 통한 추론 - prediction(inference))\n",
    "#  3. 얻어낸 예측값을 이용해서 loss를 계산\n",
    "#  4. 역전파를 통한 미분값을 계산\n",
    "#  5. 얻어낸 미분 값으로 경사하강법을 수행(최적화)\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    # 데이터 로더에 있는 데이터 세트의 길이 가져오기\n",
    "    size = len(dataloader.dataset)\n",
    "    # 중요! model을 훈련 모드로 설정. ⭐️\n",
    "    model.train()\n",
    "\n",
    "        # **model.train()**을 호출하면, 드롭아웃과 배치 정규화 같은 레이어들이 학습에 맞는 방식으로 동작합니다.\n",
    "            # 드롭아웃: 일부 뉴런을 무작위로 비활성화.\n",
    "            # 배치 정규화: 각 배치의 평균과 분산을 사용.\n",
    "        \n",
    "        # 반대로, **model.eval()**은 평가(추론) 모드로, 이러한 레이어들이 학습이 아닌 정확한 추론을 수행하는 데 맞춰 동작합니다.\n",
    "            # 드롭아웃: 모든 뉴런을 사용.\n",
    "            # 배치 정규화: 학습 중 계산된 평균과 분산을 사용.\n",
    "\n",
    "    # 데이터 꺼내기. for문을 사용하면 자동으로 next(iter(dataloader))가 실행 된다.\n",
    "    for  batch, (X, y) in enumerate(dataloader):\n",
    "        # 현재 데이터 로더에 있는 데이터는 cpu에 존재하고 있기 때문에 이 데이터들을 gpu로 옮긴다.\n",
    "        #   모델이 위치한 곳과 데이터가 위치한 곳을 동일하게 맞춰준다.\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 순전파 수행\n",
    "        pred = model(X)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = loss_fn(pred, y) # 자동으로 소프트맥스가 적용됨.\n",
    "\n",
    "        # 역전파 수행(미분값 얻어내기)\n",
    "        optimizer.zero_grad() # 기존에 남아있던 기울기를 제거( 이전 배치의 기울기가 남아있으면 정확한 기울기를 구해내기가 힘들어요)\n",
    "        loss.backward() # 역전파. loss가 Leaf\n",
    "        optimizer.step() # 구한 미분값을 토대로 최적화를 수행(경사하강법)\n",
    "\n",
    "        # 배치가 100번 돌 때마다 화면에 출력\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"Train Loss : {loss:>7f} [ {current:>5d} / {size:>5d} ]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">전체 흐름 요약\n",
    "\n",
    "1. 모델을 훈련 모드로 설정 (model.train())\n",
    "\n",
    "\n",
    "2. 배치 단위로 데이터를 로딩 (dataloader)\n",
    "\n",
    "\n",
    "3. 입력 데이터를 장치(GPU/CPU)로 이동 (X.to(device), y.to(device))\n",
    "\n",
    "\n",
    "4. 모델에 입력 데이터를 전달해 예측 (model(X))\n",
    "\n",
    "\n",
    "5. 예측 값과 실제 값 간의 손실 계산 (loss_fn(pred, y))\n",
    "\n",
    "\n",
    "6. 이전 배치의 기울기를 초기화 (optimizer.zero_grad())\n",
    "\n",
    "\n",
    "7. 오차 역전파로 기울기 계산 (loss.backward())\n",
    "\n",
    "\n",
    "8. 최적화 알고리즘을 통해 가중치 업데이트 (optimizer.step())\n",
    "\n",
    "\n",
    "9. 100번째 배치마다 손실을 출력하여 학습 과정을 모니터링\n",
    "\n",
    "\n",
    "이 과정을 여러 에폭(epoch) 동안 반복하여 모델의 가중치를 점진적으로 업데이트하고, 성능을 향상시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론을 위한 테스트 과정(테스트 루프) 정의\n",
    "# 1. 테스트 데이터 로더에서 데이터 꺼내기\n",
    "# 2. 데이터를 모델에 통과(순전파)시켜서 예측값 얻어내기\n",
    "# 3. 성능(metric) 계산. - Loss, Accuracy 계산\n",
    "#   - Loss는 배치 별 평균 성능 계산\n",
    "#   - Accuracy는 전체 데이터에 대한 성능을 계산\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # 중요! 평가모드(추론모드) 설정\n",
    "    model.eval()\n",
    "\n",
    "    # 추론 과정은 기울기를 구할 필요가 없어요\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "\n",
    "            # 모델과 데이터는 항상 같은 환경에서 사용되어야 한다.\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # 예측\n",
    "            pred = model(X)\n",
    "\n",
    "            # Loss 계산\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "            # 맞춘거 개수 합치기\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    # 배치 개수 구하기\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    # 배치 별 loss, accuracy의 평균 구하기\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "\n",
    "    print(f\"Test Error : \\n Accuracy : {(100*correct):>0.1f}%, Avg Loss : {test_loss:>8f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 전체 흐름 요약:\n",
    "\n",
    "1. 모델을 평가 모드로 설정 (model.eval())\n",
    "\n",
    "\n",
    "2. 기울기 계산을 하지 않도록 설정 (torch.no_grad())\n",
    "\n",
    "\n",
    "3. 배치 단위로 데이터를 로딩 (dataloader)\n",
    "\n",
    "\n",
    "4. 입력 데이터를 장치(GPU/CPU)로 이동 (X.to(device), y.to(device))\n",
    "\n",
    "\n",
    "5. 모델에 입력 데이터를 전달해 예측 (model(X))\n",
    "\n",
    "\n",
    "6. 예측 값과 실제 값 간의 손실 계산 (loss_fn(pred, y))\n",
    "\n",
    "\n",
    "7. 정확도를 계산하여 맞춘 개수 합산 (pred.argmax(1) == y)\n",
    "\n",
    "\n",
    "8. 전체 배치가 끝난 후 손실과 정확도의 평균을 계산\n",
    "\n",
    "\n",
    "9. 결과 출력: 평균 손실과 정확도 표시\n",
    "\n",
    "이 과정을 통해 모델의 성능(손실과 정확도)을 평가하고, 훈련된 모델이 테스트 데이터에서 얼마나 잘 동작하는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 1\n",
      "-------------------------------------------\n",
      "Train Loss : 2.307013 [     0 / 60000 ]\n",
      "Train Loss : 1.529820 [  6400 / 60000 ]\n",
      "Train Loss : 1.096999 [ 12800 / 60000 ]\n",
      "Train Loss : 0.981642 [ 19200 / 60000 ]\n",
      "Train Loss : 0.891455 [ 25600 / 60000 ]\n",
      "Train Loss : 0.653020 [ 32000 / 60000 ]\n",
      "Train Loss : 0.736131 [ 38400 / 60000 ]\n",
      "Train Loss : 0.648572 [ 44800 / 60000 ]\n",
      "Train Loss : 0.699619 [ 51200 / 60000 ]\n",
      "Train Loss : 0.646846 [ 57600 / 60000 ]\n",
      "Test Error : \n",
      " Accuracy : 77.9%, Avg Loss : 0.648243\n",
      "\n",
      "Epochs 2\n",
      "-------------------------------------------\n",
      "Train Loss : 0.616934 [     0 / 60000 ]\n",
      "Train Loss : 0.792737 [  6400 / 60000 ]\n",
      "Train Loss : 0.681527 [ 12800 / 60000 ]\n",
      "Train Loss : 0.848099 [ 19200 / 60000 ]\n",
      "Train Loss : 0.814480 [ 25600 / 60000 ]\n",
      "Train Loss : 0.618155 [ 32000 / 60000 ]\n",
      "Train Loss : 0.719694 [ 38400 / 60000 ]\n",
      "Train Loss : 0.451992 [ 44800 / 60000 ]\n",
      "Train Loss : 0.578987 [ 51200 / 60000 ]\n",
      "Train Loss : 0.386426 [ 57600 / 60000 ]\n",
      "Test Error : \n",
      " Accuracy : 81.2%, Avg Loss : 0.551938\n",
      "\n",
      "Epochs 3\n",
      "-------------------------------------------\n",
      "Train Loss : 0.584168 [     0 / 60000 ]\n",
      "Train Loss : 0.552038 [  6400 / 60000 ]\n",
      "Train Loss : 0.519878 [ 12800 / 60000 ]\n",
      "Train Loss : 0.625959 [ 19200 / 60000 ]\n",
      "Train Loss : 0.492911 [ 25600 / 60000 ]\n",
      "Train Loss : 0.490547 [ 32000 / 60000 ]\n",
      "Train Loss : 0.411763 [ 38400 / 60000 ]\n",
      "Train Loss : 0.581635 [ 44800 / 60000 ]\n",
      "Train Loss : 0.485739 [ 51200 / 60000 ]\n",
      "Train Loss : 0.453812 [ 57600 / 60000 ]\n",
      "Test Error : \n",
      " Accuracy : 82.7%, Avg Loss : 0.503371\n",
      "\n",
      "Epochs 4\n",
      "-------------------------------------------\n",
      "Train Loss : 0.471638 [     0 / 60000 ]\n",
      "Train Loss : 0.505008 [  6400 / 60000 ]\n",
      "Train Loss : 0.442519 [ 12800 / 60000 ]\n",
      "Train Loss : 0.307909 [ 19200 / 60000 ]\n",
      "Train Loss : 0.406079 [ 25600 / 60000 ]\n",
      "Train Loss : 0.408986 [ 32000 / 60000 ]\n",
      "Train Loss : 0.530517 [ 38400 / 60000 ]\n",
      "Train Loss : 0.562581 [ 44800 / 60000 ]\n",
      "Train Loss : 0.431441 [ 51200 / 60000 ]\n",
      "Train Loss : 0.488528 [ 57600 / 60000 ]\n",
      "Test Error : \n",
      " Accuracy : 83.1%, Avg Loss : 0.478062\n",
      "\n",
      "Epochs 5\n",
      "-------------------------------------------\n",
      "Train Loss : 0.310969 [     0 / 60000 ]\n",
      "Train Loss : 0.511174 [  6400 / 60000 ]\n",
      "Train Loss : 0.446847 [ 12800 / 60000 ]\n",
      "Train Loss : 0.439981 [ 19200 / 60000 ]\n",
      "Train Loss : 0.608086 [ 25600 / 60000 ]\n",
      "Train Loss : 0.550067 [ 32000 / 60000 ]\n",
      "Train Loss : 0.482368 [ 38400 / 60000 ]\n",
      "Train Loss : 0.570799 [ 44800 / 60000 ]\n",
      "Train Loss : 0.617540 [ 51200 / 60000 ]\n",
      "Train Loss : 0.421256 [ 57600 / 60000 ]\n",
      "Test Error : \n",
      " Accuracy : 83.7%, Avg Loss : 0.457514\n",
      "\n",
      "Epochs 6\n",
      "-------------------------------------------\n",
      "Train Loss : 0.444353 [     0 / 60000 ]\n",
      "Train Loss : 0.443580 [  6400 / 60000 ]\n",
      "Train Loss : 0.530409 [ 12800 / 60000 ]\n",
      "Train Loss : 0.304354 [ 19200 / 60000 ]\n",
      "Train Loss : 0.469321 [ 25600 / 60000 ]\n",
      "Train Loss : 0.351275 [ 32000 / 60000 ]\n",
      "Train Loss : 0.533257 [ 38400 / 60000 ]\n",
      "Train Loss : 0.718570 [ 44800 / 60000 ]\n",
      "Train Loss : 0.535764 [ 51200 / 60000 ]\n",
      "Train Loss : 0.495824 [ 57600 / 60000 ]\n",
      "Test Error : \n",
      " Accuracy : 84.1%, Avg Loss : 0.442198\n",
      "\n",
      "Epochs 7\n",
      "-------------------------------------------\n",
      "Train Loss : 0.284308 [     0 / 60000 ]\n",
      "Train Loss : 0.490681 [  6400 / 60000 ]\n",
      "Train Loss : 0.389143 [ 12800 / 60000 ]\n",
      "Train Loss : 0.309336 [ 19200 / 60000 ]\n",
      "Train Loss : 0.286743 [ 25600 / 60000 ]\n",
      "Train Loss : 0.302680 [ 32000 / 60000 ]\n",
      "Train Loss : 0.529186 [ 38400 / 60000 ]\n",
      "Train Loss : 0.404423 [ 44800 / 60000 ]\n",
      "Train Loss : 0.434003 [ 51200 / 60000 ]\n",
      "Train Loss : 0.271450 [ 57600 / 60000 ]\n",
      "Test Error : \n",
      " Accuracy : 84.7%, Avg Loss : 0.431717\n",
      "\n",
      "Epochs 8\n",
      "-------------------------------------------\n",
      "Train Loss : 0.443826 [     0 / 60000 ]\n",
      "Train Loss : 0.505722 [  6400 / 60000 ]\n",
      "Train Loss : 0.479047 [ 12800 / 60000 ]\n",
      "Train Loss : 0.416751 [ 19200 / 60000 ]\n",
      "Train Loss : 0.421655 [ 25600 / 60000 ]\n",
      "Train Loss : 0.367244 [ 32000 / 60000 ]\n",
      "Train Loss : 0.201614 [ 38400 / 60000 ]\n",
      "Train Loss : 0.385635 [ 44800 / 60000 ]\n",
      "Train Loss : 0.283379 [ 51200 / 60000 ]\n",
      "Train Loss : 0.352131 [ 57600 / 60000 ]\n",
      "Test Error : \n",
      " Accuracy : 85.1%, Avg Loss : 0.419036\n",
      "\n",
      "Epochs 9\n",
      "-------------------------------------------\n",
      "Train Loss : 0.262121 [     0 / 60000 ]\n",
      "Train Loss : 0.454853 [  6400 / 60000 ]\n",
      "Train Loss : 0.521049 [ 12800 / 60000 ]\n",
      "Train Loss : 0.397304 [ 19200 / 60000 ]\n",
      "Train Loss : 0.372640 [ 25600 / 60000 ]\n",
      "Train Loss : 0.422383 [ 32000 / 60000 ]\n",
      "Train Loss : 0.383259 [ 38400 / 60000 ]\n",
      "Train Loss : 0.491725 [ 44800 / 60000 ]\n",
      "Train Loss : 0.523781 [ 51200 / 60000 ]\n",
      "Train Loss : 0.274655 [ 57600 / 60000 ]\n",
      "Test Error : \n",
      " Accuracy : 85.3%, Avg Loss : 0.412528\n",
      "\n",
      "Epochs 10\n",
      "-------------------------------------------\n",
      "Train Loss : 0.412960 [     0 / 60000 ]\n",
      "Train Loss : 0.351106 [  6400 / 60000 ]\n",
      "Train Loss : 0.358928 [ 12800 / 60000 ]\n",
      "Train Loss : 0.448815 [ 19200 / 60000 ]\n",
      "Train Loss : 0.442687 [ 25600 / 60000 ]\n",
      "Train Loss : 0.233736 [ 32000 / 60000 ]\n",
      "Train Loss : 0.428585 [ 38400 / 60000 ]\n",
      "Train Loss : 0.381911 [ 44800 / 60000 ]\n",
      "Train Loss : 0.335642 [ 51200 / 60000 ]\n",
      "Train Loss : 0.488559 [ 57600 / 60000 ]\n",
      "Test Error : \n",
      " Accuracy : 85.5%, Avg Loss : 0.406858\n",
      "\n",
      "Done!!!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(f\"Epochs {i + 1}\\n-------------------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "\n",
    "print(\"Done!!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
