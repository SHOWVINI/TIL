{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "https://hyunicecream.tistory.com/79"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoAHRoR2LjzT"
      },
      "source": [
        "# 파이토치(PyTorch란?)\n",
        "- PyTorch는 머신러닝 프레임워크 입니다.\n",
        "  - PyTorch의 Tensor는 Numpy배열과 매우 흡사합니다.\n",
        "- PyTorch를 사용하면 GPU 연동을 통해 효율적으로 딥러닝 모델을 학습할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8tu25pS2MXdD"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFlkstZaMErx"
      },
      "source": [
        "## 1) GPU 사용여부 체크하기\n",
        "- Colab 기준 **[수정 - 노트설정 - 하드웨어 가속기]**를 GPU로 바꿔줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "F_VacU34MHkz",
        "outputId": "a2d1fb66-14d8-4b47-aef7-a7686869f481"
      },
      "outputs": [],
      "source": [
        "# data = [[1, 2],\n",
        "#         [3, 4]]\n",
        "\n",
        "# x = torch.tensor(data)\n",
        "# print(x.is_cuda)\n",
        "\n",
        "# # Tensor를 GPU로 옮기기\n",
        "# x = x.cuda()\n",
        "# print(x.is_cuda)\n",
        "\n",
        "# # Tensor를 CPU로 옮기기\n",
        "# x = x.cpu()\n",
        "# print(x.is_cuda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "맥북에서는 위 코드 실행 불가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MPS 가속을 사용합니다.\n",
            "초기 상태 (CPU): False\n",
            "MPS 상태 확인: mps:0\n",
            "다시 CPU로 옮김: False\n"
          ]
        }
      ],
      "source": [
        "# Apple Silicon 기반의 MacBook에서는 CUDA가 지원되지 않으므로, GPU 가속을 위해 **MPS(Metal Performance Shaders)**를 사용해야 합니다. \n",
        "# 따라서 코드를 MPS를 사용할 수 있도록 변경하는 방식으로 수정해야 합니다. 또한, CPU에서 실행할 경우도 대비할 수 있도록 코드를 작성할 수 있습니다.\n",
        "\n",
        "# 다음은 MPS와 CPU를 함께 사용할 수 있도록 수정된 코드입니다:\n",
        "\n",
        "import torch\n",
        "\n",
        "# 데이터 생성\n",
        "data = [[1, 2],\n",
        "        [3, 4]]\n",
        "\n",
        "# 텐서 생성\n",
        "x = torch.tensor(data)\n",
        "\n",
        "# MPS(Apple Silicon GPU 가속) 또는 CPU 사용 결정\n",
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "    print(\"MPS 가속을 사용합니다.\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"MPS 가속을 사용할 수 없습니다. CPU를 사용합니다.\")\n",
        "\n",
        "# Tensor가 GPU(MPS)인지 확인 (초기에는 CPU에 있음)\n",
        "print(\"초기 상태 (CPU):\", x.is_cuda)\n",
        "\n",
        "# Tensor를 GPU(MPS)로 옮기기 (또는 CPU로 유지)\n",
        "x = x.to(device)\n",
        "print(\"MPS 상태 확인:\", x.device)\n",
        "\n",
        "# Tensor를 다시 CPU로 옮기기\n",
        "x = x.cpu()\n",
        "print(\"다시 CPU로 옮김:\", x.is_cuda)  # False가 출력됨\n",
        "\n",
        "\n",
        "\n",
        "# 출력 예시:\n",
        "# MPS 가속을 사용할 수 있는 환경에서는 MPS 가속을 사용합니다.라는 메시지가 출력되고, 텐서가 MPS로 옮겨집니다.\n",
        "# MPS가 없는 환경에서는 MPS 가속을 사용할 수 없습니다. CPU를 사용합니다.라는 메시지가 출력되고 텐서가 CPU에 남아있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usu6JJAQMjgC"
      },
      "source": [
        "서로 다른 장치(device)에 있는 텐서끼리 연산을 수행하면 오류가 발생합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3MfygPvMwKS"
      },
      "source": [
        "# 텐서 생성하기\n",
        "- PyTorch의 텐서(tensor)는 기능적으로 넘파이(numpy)와 매우 유사합니다.\n",
        "- 기본적으로 **다차원 배열**을 처리하기에 적합한 자료구조로 이해할 수 있습니다.\n",
        "- PyTorch의 텐서는 **\"자동 미분\"**기능을 제공합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PyTorch에서 \"텐서(Tensor)\"는 기본적으로 다차원 배열(multi-dimensional array) 또는 행렬의 일반화된 형태를 의미합니다. \n",
        "\n",
        "텐서는 데이터를 저장하고 처리하는 기본 단위이며, 벡터, 행렬, 그리고 더 높은 차원의 데이터를 모두 표현할 수 있습니다. \n",
        "\n",
        "PyTorch에서 텐서는 주로 수치 계산을 위해 사용되며, GPU를 활용한 병렬 계산을 통해 고속 연산이 가능합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp9J8k_8M_gi"
      },
      "source": [
        "## 1) 텐서의 속성\n",
        "- 텐서의 기본 속성은 다음과 같습니다.\n",
        "  - 모양(shape)\n",
        "  - 자료형(data type)\n",
        "  - 저장된 장치(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVTRJquqNJdD",
        "outputId": "67eadc6c-eb3a-436f-f28e-f869828e62e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.4555, 0.1537, 0.4372, 0.9650],\n",
            "        [0.3271, 0.6235, 0.2301, 0.1456],\n",
            "        [0.0862, 0.4208, 0.5036, 0.9807]])\n",
            "Shape : torch.Size([3, 4])\n",
            "Data Type : torch.float32\n",
            "Device : cpu\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand(3, 4)\n",
        "\n",
        "print(tensor)\n",
        "print(f\"Shape : {tensor.shape}\")\n",
        "print(f\"Data Type : {tensor.dtype}\")\n",
        "print(f\"Device : {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg_ZExtANSSL"
      },
      "source": [
        "## 2) 텐서 생성하기\n",
        "- 파이썬의 `list`에서 직접 텐서를 생성할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwL2RvsANari",
        "outputId": "82648398-3c87-46cb-fae5-dc06cceef8ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ],
      "source": [
        "data = [[1, 2],\n",
        "        [3, 4]]\n",
        "\n",
        "x = torch.tensor(data)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqh0DDVBNgGC"
      },
      "source": [
        "- numpy 배열에서 텐서를 생성할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNv9cxNwNkGa",
        "outputId": "e56c5bb2-cdd9-441e-ccbe-1d5cacf40ee7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([5])\n",
        "b = torch.tensor([7])\n",
        "\n",
        "c = (a + b).numpy()\n",
        "print(type(c))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zxkmd3QNqvq",
        "outputId": "b0752c1b-0639-420f-e0c9-d034e49f4943"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([120])\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ],
      "source": [
        "result = c * 10\n",
        "tensor = torch.from_numpy(result)\n",
        "print(tensor)\n",
        "print(type(tensor))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg6ZFRfNNwHy"
      },
      "source": [
        "## 3) 다른 텐서로부터 텐서 초기화 하기\n",
        "- 다른 텐서의 정보를 토대로 텐서를 초기화 할 수 있습니다.\n",
        "- **텐서의 속성**이란? 모양(shape)과 자료형(data type)을 일컫습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7-x_oK3N8eZ",
        "outputId": "7760b36a-dbe2-4894-c365-68430fc89329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 1],\n",
            "        [1, 1]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[5, 7],\n",
        "                  [1, 2]])\n",
        "\n",
        "# 텐서 x와 같은 모양을 가지지만, 값이 1인 텐서 생성하기\n",
        "x_ones = torch.ones_like(x)\n",
        "print(x_ones)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLDei5b1OG_i",
        "outputId": "4fce2113-cc06-4f22-932d-3700fdce2c32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.5115, 0.5716],\n",
            "        [0.3646, 0.2870]])\n"
          ]
        }
      ],
      "source": [
        "# 텐서 x와 같은 모양을 가지지만, 자료형을 float으로, 값은 랜덤하게 채우기\n",
        "x_rand = torch.rand_like(x, dtype=torch.float32) # uniform distribution [0, 1]\n",
        "print(x_rand)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9_vrf1FOQga"
      },
      "source": [
        "# 텐서의 형변환 및 차원 조작\n",
        "- 텐서는 넘파이 배열처럼 조작이 가능합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWdGTxYWPoxa"
      },
      "source": [
        "## 1) 텐서의 특정 차원에 접근하기\n",
        "- 텐서의 원하는 차원에 접근할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HWa7yXqPsx5",
        "outputId": "47d3d349-2c0f-4a45-a005-f4d80b3ca09b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3, 4])\n",
            "tensor([1, 5, 9])\n",
            "tensor([ 4,  8, 12])\n",
            "tensor([ 4,  8, 12])\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.tensor([\n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "\n",
        "print(tensor[0])\n",
        "print(tensor[:, 0])\n",
        "print(tensor[..., -1])\n",
        "print(tensor[:, -1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> print(tensor[..., -1])\n",
        "모든 차원에 대해 마지막 값을 선택합니다.\n",
        "\n",
        "...는 전체 차원을 의미하며, 마지막 차원에 대해 마지막 요소를 선택합니다.\n",
        "\n",
        "이 경우, 텐서는 2차원이므로 각 행에서 마지막 열을 선택하는 것과 같습니다.\n",
        "\n",
        "> print(tensor[:, -1])\n",
        "\n",
        "이 구문도 모든 행에서 마지막 열을 선택하는 역할을 합니다.\n",
        "\n",
        ":는 전체 행을 의미하고, -1은 마지막 열을 의미합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **:와 ...의 차이**\n",
        "\n",
        "\n",
        " - :는 특정 차원을 명시적으로 선택할 때 사용됩니다. \n",
        "\n",
        "예를 들어 tensor[:, -1]은 \"모든 행에서 마지막 열\"을 선택하는 것이며, 2차원 텐서에서 명시적으로 2차원의 각 요소를 다룹니다.\n",
        "\n",
        "- ...(ellipsis)는 여러 차원을 자동으로 처리할 수 있도록 돕습니다. \n",
        "\n",
        "다차원 텐서에서 어디에 위치한 차원이든 마지막 차원의 마지막 요소를 선택할 수 있습니다. \n",
        "\n",
        "예를 들어, 3차원, 4차원 또는 더 높은 차원에서 사용할 때도 일관된 방식으로 동작합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbxZu7H0P38y"
      },
      "source": [
        "## 2) 텐서 이어붙이기\n",
        "-텐서를 이어서 새로운 텐서를 만들 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBQrwPD7l8bv"
      },
      "source": [
        "### 2-1) cat\n",
        "단순하게 텐서를 축(dim)에 맞춰 연결합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIXqSEKUWK4z",
        "outputId": "b6ab2c3e-7644-4c5a-c3a1-a0929fb39130"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12],\n",
            "        [13, 14, 15, 16],\n",
            "        [17, 18, 19, 20],\n",
            "        [21, 22, 23, 24]])\n",
            "\n",
            "tensor([[ 1,  2,  3,  4, 13, 14, 15, 16],\n",
            "        [ 5,  6,  7,  8, 17, 18, 19, 20],\n",
            "        [ 9, 10, 11, 12, 21, 22, 23, 24]])\n"
          ]
        }
      ],
      "source": [
        "tensor1 = torch.tensor([\n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "\n",
        "tensor2 = torch.tensor([\n",
        "    [13, 14, 15, 16],\n",
        "    [17, 18, 19, 20],\n",
        "    [21, 22, 23, 24]\n",
        "])\n",
        "\n",
        "# dim : 텐서의 축\n",
        "# 0번 축을 기준으로 이어 붙입니다.\n",
        "result = torch.cat([tensor1, tensor2], dim=0)\n",
        "print(result)\n",
        "\n",
        "print()\n",
        "# 1번 축을 기준으로 이어 붙입니다.\n",
        "result = torch.cat([tensor1, tensor2], dim=1)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이어 붙이기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWs4lp_9mBH9"
      },
      "source": [
        "### 2-2) stack\n",
        "리스트 내의 텐서를 쌓아줍니다. 차원수가 증가합니다. 예를 들어 2차원 배열과 2차원 배열을 쌓은 3차원 배열을 만들어 줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSe0ReDKmHK2",
        "outputId": "69a5abda-3091-4819-dab6-5bf1892769e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 1,  2,  3,  4],\n",
              "         [ 5,  6,  7,  8],\n",
              "         [ 9, 10, 11, 12]],\n",
              "\n",
              "        [[13, 14, 15, 16],\n",
              "         [17, 18, 19, 20],\n",
              "         [21, 22, 23, 24]]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor1 = torch.tensor([\n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "\n",
        "tensor2 = torch.tensor([\n",
        "    [13, 14, 15, 16],\n",
        "    [17, 18, 19, 20],\n",
        "    [21, 22, 23, 24]\n",
        "])\n",
        "\n",
        "tensor3 = torch.stack([tensor1, tensor2])\n",
        "tensor3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "뒤에 쌓기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDwjwhpTi7E_"
      },
      "source": [
        "## 3) 텐서 자르기(slice)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WruuA0-ji-Ml",
        "outputId": "db1e3474-6896-44d6-ae40-1360f9fdb459"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 5])\n"
          ]
        }
      ],
      "source": [
        "tensor1 = torch.tensor([[1,2,3,4],\n",
        "                        [5,6,7,8]])\n",
        "\n",
        "tensor2 = tensor1[:, 0]\n",
        "print(tensor2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF5r5thEi-P1",
        "outputId": "017fe67a-2f52-4f95-b02b-a45b4e50b1b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[2],\n",
            "        [6]])\n"
          ]
        }
      ],
      "source": [
        "tensor3 = tensor1[:, 1:3:2]\n",
        "print(tensor3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> 이 구문에서 1:3:2는 다음을 의미합니다:\n",
        "\n",
        "1: 슬라이싱의 시작 인덱스입니다. 여기서는 인덱스 1부터 슬라이싱을 시작합니다.\n",
        "\n",
        "3: 슬라이싱의 끝 인덱스로, 이 인덱스는 포함되지 않습니다. 즉, 인덱스 3 전까지 선택합니다.\n",
        "\n",
        "2: 스텝(step) 값으로, 슬라이싱할 때 몇 개씩 건너뛰는지를 나타냅니다. 여기서는 2칸씩 건너뛰며 선택합니다.\n",
        "\n",
        "> 따라서 1:3:2는 \"인덱스 1부터 인덱스 3 전까지, 2칸씩 건너뛰면서\" 요소를 선택하는 슬라이싱 방식입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d2plWG3i-SN",
        "outputId": "560117a1-4c67-4bf2-ad80-0b65257e9685"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2, 3])\n"
          ]
        }
      ],
      "source": [
        "tensor3 = tensor1[0, 1:3]\n",
        "print(tensor3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8xkDzR5i-U2",
        "outputId": "46cfbcde-a1a6-48e4-cebc-7557afbe6dbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "tensor([1, 3])\n"
          ]
        }
      ],
      "source": [
        "tensor1 = torch.tensor([[[1, 2],\n",
        "                         [3, 4]],\n",
        "\n",
        "                        [[5, 6],\n",
        "                         [7, 8]],\n",
        "\n",
        "                        [[9, 10],\n",
        "                         [11,12]]])\n",
        "\n",
        "print(tensor1[0])\n",
        "print(tensor1[0, :])\n",
        "print(tensor1[0, :, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GS5jVIwWi-XG",
        "outputId": "dfaf0c3e-85ac-4f61-ace5-8c60e08a58dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 9, 10],\n",
            "        [11, 12]])\n",
            "tensor([[ 9, 10],\n",
            "        [11, 12]])\n",
            "tensor([[ 9, 10],\n",
            "        [11, 12]])\n"
          ]
        }
      ],
      "source": [
        "print(tensor1[-1])\n",
        "print(tensor1[-1, :])\n",
        "print(tensor1[-1, :, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8qu9-1Ji-ZW",
        "outputId": "d956eeed-d4f5-475e-9583-16ede82669bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 2, 2])\n",
            "torch.Size([3, 2])\n",
            "torch.Size([3, 1, 2])\n"
          ]
        }
      ],
      "source": [
        "print(tensor1[1:3, :, :].shape)\n",
        "print(tensor1[:, 1, :].shape)\n",
        "print(tensor1[:, :-1, :].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCPg76_wkbM2"
      },
      "source": [
        "### 3-1) split\n",
        "지정한 size만큼 tensor를 쪼개어 줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR8T54eKkgsN",
        "outputId": "266be453-7413-4034-dd78-03d11c2def68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 4])\n",
            "torch.Size([4, 4])\n",
            "torch.Size([4, 4])\n",
            "torch.Size([4, 4])\n",
            "torch.Size([1, 4])\n"
          ]
        }
      ],
      "source": [
        "tensor1 = torch.rand(17, 4)\n",
        "\n",
        "splits = tensor1.split(4, dim=0)\n",
        "for s in splits:\n",
        "  print(s.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZp95qepky9F"
      },
      "source": [
        "### 3-2) chunk\n",
        "지정한 개수만큼 쪼개어진 텐서를 만들어 냅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skcoaBG5k4Xl",
        "outputId": "a09302ea-fe2e-42c8-ff7c-c559d35b8a26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 4])\n",
            "torch.Size([5, 4])\n",
            "torch.Size([5, 4])\n",
            "torch.Size([2, 4])\n"
          ]
        }
      ],
      "source": [
        "tensor1 = torch.rand(17, 4)\n",
        "\n",
        "chunks = tensor1.chunk(4, dim=0)\n",
        "for c in chunks:\n",
        "  print(c.shape)\n",
        "\n",
        "# chunk(num_chunks, dim): 텐서를 지정된 차원(dim)을 기준으로 num_chunks 개의 조각으로 나누는 함수입니다.\n",
        "# 균등하게 나누려고 하지만 나머지가 있는 경우 일부 조각이 더 많은 크기를 가질 수 있습니다.\n",
        "# 슬라이싱과는 다르게 조각의 개수로 나누는 것이 핵심입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5ohgUBalMLu"
      },
      "source": [
        "### 3-3) index_select\n",
        "인덱스를 이용해 해당 위치의 텐서를 참조합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKXjGV36lT5N",
        "outputId": "0a3a0dad-6fe1-437e-a0a2-4ca0fcd9e5e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2, 0])\n",
            "tensor([[[ 9, 10],\n",
            "         [11, 12]],\n",
            "\n",
            "        [[ 1,  2],\n",
            "         [ 3,  4]]])\n"
          ]
        }
      ],
      "source": [
        "tensor1 = torch.tensor([[[1, 2],\n",
        "                         [3, 4]],\n",
        "\n",
        "                        [[5, 6],\n",
        "                         [7, 8]],\n",
        "\n",
        "                        [[9, 10],\n",
        "                         [11,12]]])\n",
        "\n",
        "indice = torch.tensor([2, 0])\n",
        "print(indice)\n",
        "\n",
        "tensor2 = tensor1.index_select(dim=0, index=indice)\n",
        "print(tensor2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DspSCPCkWhPz"
      },
      "source": [
        "## 4) 텐서 형변환(type casting)\n",
        "- 텐서의 자료형을 변환할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuCZAIOAWwv7",
        "outputId": "8e07f0d2-48d7-43b1-9d6c-77a248979cdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.int32\n",
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "tensor1 = torch.tensor([2], dtype=torch.int)\n",
        "tensor2 = torch.tensor([5.0])\n",
        "\n",
        "print(tensor1.dtype)\n",
        "print(tensor2.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHQ-2AL_W3ZU",
        "outputId": "7f7549c9-b2ff-4ffd-96ab-5899bfae2116"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([7.])\n",
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "print(tensor1 + tensor2)\n",
        "print((tensor1 + tensor2).dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXTlAeBXW7aT",
        "outputId": "5fbf9271-28b9-4e96-f909-b6c6cc4e4974"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([7], dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "print((tensor1 + tensor2.type(torch.int)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_uoDbe7XM37"
      },
      "source": [
        "## 5) 텐서의 모양 변경"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wg4BWsIZFeN"
      },
      "source": [
        "### 5-1) view\n",
        "- 텐서를 원하는 개수로 각 차원에 매핑하여 텐서의 차원을 시킬 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "BqGiUj1gaS1d"
      },
      "outputs": [],
      "source": [
        "tensor1 = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2vnGOd8XUoT",
        "outputId": "5019f452-1668-449c-eeff-2406eedad155"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor1 : tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
            "tensor2 : tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6],\n",
            "        [7, 8]])\n"
          ]
        }
      ],
      "source": [
        "tensor2 = tensor1.view(4, 2)\n",
        "\n",
        "print(f\"tensor1 : {tensor1}\")\n",
        "print(f\"tensor2 : {tensor2}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axAmTsyOXgob",
        "outputId": "d05ffc20-c033-4031-85cc-2fdfb48e9850"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[7, 2],\n",
            "        [3, 4],\n",
            "        [5, 6],\n",
            "        [7, 8]])\n"
          ]
        }
      ],
      "source": [
        "# tensor1의 값을 변경하면 tensor2도 변경이 된다.\n",
        "tensor1[0] = 7\n",
        "print(tensor2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\"tensor1의 값을 변경하면 tensor2도 변경이 된다.\"\n",
        "\n",
        "위 내용을 이해하려면, 메모리 구조를 이해해야 함(아래 내용 참고)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "tensor1과 tensor2의 관계는 C 언어에서 포인터가 가리키는 메모리와 유사합니다. \n",
        "\n",
        "\n",
        "구체적으로는, tensor2는 tensor1과 동일한 데이터를 다른 방식으로 해석한 **뷰(view)**에 불과합니다.\n",
        "\n",
        "-----------------------------\n",
        "PyTorch에서 view() 메소드는 새로운 텐서를 생성하는 것이 아니라, 기존 텐서의 메모리 레이아웃을 변경해서 반환합니다.\n",
        "\n",
        "\n",
        "즉, 메모리 공간을 공유하게 됩니다. C 언어에서 포인터가 가리키는 메모리를 변경하면 그 포인터를 사용하는 다른 참조들도 영향을 받는 것처럼, tensor1의 데이터를 \n",
        "\n",
        "\n",
        "변경하면 그 데이터를 기반으로 하는 tensor2도 영향을 받습니다.\n",
        "\n",
        "-----------------------------\n",
        "이것이 발생하는 이유는 두 텐서가 같은 메모리 주소를 참조하기 때문입니다. \n",
        "\n",
        "\n",
        "그래서 tensor1의 값을 변경하면 같은 메모리 공간을 공유하는 tensor2의 값도 변경되는 것입니다.\n",
        "\n",
        "-----------------------------\n",
        "\n",
        "이 현상을 피하려면 tensor2를 완전히 새로운 복사본으로 만들어야 합니다. 예를 들어, clone() 메소드를 사용하여 메모리를 따로 복사할 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhO1BsgwXm1b",
        "outputId": "ea8e6477-1795-4f0a-c5cf-a56cc5993f80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[7, 2],\n",
            "        [3, 4],\n",
            "        [5, 6],\n",
            "        [7, 8]])\n"
          ]
        }
      ],
      "source": [
        "# tensor1을 복사하여 변경하면 tensor1을 변경해도 tensor2는 변경이 안된다.\n",
        "tensor3 = tensor1.clone().view(4, 2)\n",
        "tensor1[0] = 20\n",
        "\n",
        "print(tensor3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQx5kq2qf2st",
        "outputId": "73e48b0e-34e7-4690-a64f-51d43347d989"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[20,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8]])\n"
          ]
        }
      ],
      "source": [
        "# -1을 이용하면 비워져 있는 차원의 값이 적절하게 채워진다.\n",
        "tensor4 = tensor1.view(-1, 4)\n",
        "print(tensor4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EDzu9lmXwk7"
      },
      "source": [
        "### 5-2) reshape\n",
        "- view()와 비슷하나, 텐서가 메모리 상에 연속적이지 않아도(not contiguous) shape이 변경 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "6CmLu4SKaokU"
      },
      "outputs": [],
      "source": [
        "tensor1 = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duKBFwYIZTRc",
        "outputId": "cf0cb886-4987-4a04-ec46-89d8d0922b57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor2 : tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6],\n",
            "        [7, 8]])\n"
          ]
        }
      ],
      "source": [
        "tensor2 = tensor1.reshape(4, 2)\n",
        "\n",
        "print(f\"tensor2 : {tensor2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> view(): \n",
        "\n",
        "원본 텐서가 메모리에서 연속적인 경우, 데이터를 공유하며 원본 텐서에 영향을 미칩니다. \n",
        "\n",
        "즉, view()로 만든 텐서를 수정하면 원본 텐서도 바뀔 수 있습니다.\n",
        "\n",
        "-------------------------------\n",
        "\n",
        "\n",
        "> reshape(): \n",
        "\n",
        "가능한 경우 view()처럼 데이터를 공유하지만, 원본 텐서가 연속적이지 않다면 새로운 메모리 공간을 할당하여 데이터를 복사합니다. \n",
        "\n",
        "따라서 원본 텐서와 데이터를 공유하지 않을 수 있으며, 원본에 영향을 주지 않습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKEaWkjhZe8M"
      },
      "source": [
        "# 텐서의 연산"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "z_-Wfoq9oIzn"
      },
      "outputs": [],
      "source": [
        "a = torch.tensor([[1, 2],\n",
        "                  [3, 4]])\n",
        "\n",
        "b = torch.tensor([[2, 2],\n",
        "                  [3, 3]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nc0AZ1pvoQoU",
        "outputId": "9e0648a0-ccd4-494d-8125-ab5a45c9dcf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[3, 4],\n",
            "        [6, 7]])\n"
          ]
        }
      ],
      "source": [
        "print(a + b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vkzqCAMoRZl",
        "outputId": "e961f855-bc30-4bda-cef7-b6f30cce501c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-1,  0],\n",
            "        [ 0,  1]])\n"
          ]
        }
      ],
      "source": [
        "print(a - b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cs4NoN9yoSA2",
        "outputId": "0600071c-447f-4033-98e5-29d89ddc4444"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 2,  4],\n",
            "        [ 9, 12]])\n"
          ]
        }
      ],
      "source": [
        "print(a * b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2oK9juXoSoN",
        "outputId": "c2c719ac-3908-4d2a-b480-1f105eb532b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.5000, 1.0000],\n",
            "        [1.0000, 1.3333]])\n"
          ]
        }
      ],
      "source": [
        "print(a / b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0xfsVfioTLd",
        "outputId": "a957abf7-18d5-49c9-864f-431ec0a9f5ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[False,  True],\n",
            "        [ True, False]])\n"
          ]
        }
      ],
      "source": [
        "print( a == b )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA0Lxu12oT1l",
        "outputId": "c146285a-78b5-4d36-da2f-45ce2f8ab1de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ True, False],\n",
            "        [False,  True]])\n"
          ]
        }
      ],
      "source": [
        "print( a != b )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwWmXH5noZkF",
        "outputId": "6c369fab-edd2-4ae2-80fc-457ffa963da0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1,  4],\n",
            "        [27, 64]])\n"
          ]
        }
      ],
      "source": [
        "print( a ** b )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRbt1hDSoarV"
      },
      "source": [
        "## Inplace 연산\n",
        "Inplace 연산은 텐서의 실제 값을 바꿔주는 연산을 의미합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-z2DgySol4t",
        "outputId": "4b22f224-dc7c-4dcd-b375-d34d3750eb0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "tensor([[ 2,  4],\n",
            "        [ 9, 12]])\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ],
      "source": [
        "print(a)\n",
        "print(a.mul(b))\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEvwgceBooXt",
        "outputId": "2f4705ba-6075-4cc6-e806-d0e22b79ae9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 2,  4],\n",
            "        [ 9, 12]])\n",
            "tensor([[ 2,  4],\n",
            "        [ 9, 12]])\n"
          ]
        }
      ],
      "source": [
        "# a와 b의 Element wise product를 수행한 후 도로 a에 넣습니다.\n",
        "# 연산 함수 뒤에 언더바(_)가 보통 붙습니다.\n",
        "print(a.mul_(b))\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyCEYT8uorr1"
      },
      "source": [
        "## 차원 감소 연산\n",
        "주로 합계나 평균 등 차원 축에 따라 연산이 된 후 감소가 되는 연산을 의미합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIaaKfhZo4DW",
        "outputId": "e77b402e-f2c1-477d-eee6-a3b693d5d1c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(10.)\n",
            "tensor(2.5000)\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([[1, 2],\n",
        "                  [3, 4]], dtype=torch.float)\n",
        "\n",
        "# 차원을 따로 지정하지 않으면 텐서 내 모든 데이터에 대한 연산이 이뤄진 후 스칼라 값으로 표현\n",
        "print(a.sum())\n",
        "print(a.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT1pTG_ZpGcN",
        "outputId": "b7ed4119-3871-46ef-c5db-d92efd322825"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([4., 6.])\n",
            "tensor([3., 7.])\n",
            "\n",
            "tensor([2., 3.])\n",
            "tensor([1.5000, 3.5000])\n"
          ]
        }
      ],
      "source": [
        "# 차원을 따로 지정하면, 지정한 차원에 맞게 연산\n",
        "print(a.sum(dim=0))\n",
        "print(a.sum(dim=1))\n",
        "\n",
        "print()\n",
        "\n",
        "print(a.mean(dim=0))\n",
        "print(a.mean(dim=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFrZWmsCpYIG"
      },
      "source": [
        "## 브로드캐스팅\n",
        "차원 수가 맞지 않아도 자동으로 텐서를 높은 차원으로 확장해 연산이 가능토록 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7Avi3LFpn2e",
        "outputId": "a1546b24-251a-4e4a-e313-408a1447ac6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 2]) torch.Size([1, 2])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([[1, 2]])\n",
        "b = torch.tensor([[3, 4]])\n",
        "\n",
        "print(a.shape, b.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGb67gvIpuxG",
        "outputId": "99a17686-f4b1-4a72-ea25-0c34a547f71c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[4, 6]])\n"
          ]
        }
      ],
      "source": [
        "print(a + b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juicbF1UpzRe"
      },
      "source": [
        "### tensor, scalar 연산"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaW0kw4fp3Mw",
        "outputId": "8bb55439-2209-4187-e8c4-f9b945768fc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[11, 12],\n",
            "        [13, 14]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([[1, 2],\n",
        "                  [3, 4]])\n",
        "\n",
        "print(a + 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4Ba5i9-p5ku"
      },
      "source": [
        "### tensor, vector 연산"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BeS0UyQqDII",
        "outputId": "9739611f-d1f5-4e3d-ee57-8d07ace12b9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2])\n",
            "tensor([[11, 22],\n",
            "        [13, 24]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([[1, 2],\n",
        "                [3, 4]])\n",
        "\n",
        "b = torch.tensor([10, 20])\n",
        "\n",
        "print(b.shape)\n",
        "print(a + b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtZqLgCRqHYG",
        "outputId": "5676ebea-9042-4937-ebc3-4543fdbda382"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 2])\n",
            "tensor([[11, 22],\n",
            "        [13, 24]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([[1, 2],\n",
        "                [3, 4]])\n",
        "\n",
        "b = torch.tensor([[10, 20]])\n",
        "print(b.shape)\n",
        "print(a + b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaB_2e4EqOFm",
        "outputId": "848a4dc1-e3c8-479a-f47c-88ccde0fbf4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 1])\n",
            "tensor([[11, 12],\n",
            "        [23, 24]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([[1, 2],\n",
        "                [3, 4]])\n",
        "\n",
        "b = torch.tensor([[10],\n",
        "                [20]]) \n",
        "print(b.shape)\n",
        "print(a + b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhl6gzSaqSaG"
      },
      "source": [
        "### tensor, tensor 연산"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ5TlISjqirQ",
        "outputId": "83319ed1-a6b1-4cf3-fee0-198a0c9af4f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 2]) torch.Size([2, 1])\n",
            "tensor([[11, 12],\n",
            "        [21, 22]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([[1, 2]])\n",
        "\n",
        "b = torch.tensor([[10],\n",
        "                  [20]])\n",
        "\n",
        "print(a.shape, b.shape)\n",
        "print(a + b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SyJmKFPqpgm",
        "outputId": "13801574-a843-4e35-e0c1-80272ce0e65e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[101, 202],\n",
            "         [103, 204]],\n",
            "\n",
            "        [[105, 206],\n",
            "         [107, 208]],\n",
            "\n",
            "        [[109, 210],\n",
            "         [111, 212]]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([[[1, 2],\n",
        "                   [3, 4]],\n",
        "\n",
        "                   [[5, 6],\n",
        "                    [7, 8]],\n",
        "\n",
        "                   [[9, 10],\n",
        "                    [11,12]]])\n",
        "\n",
        "b = torch.tensor([100, 200])\n",
        "\n",
        "print(a+b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixnqf9Lqq8He",
        "outputId": "9fe0fbd0-fdf0-491c-d659-a638f5ed940a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[101, 202],\n",
            "         [303, 404]],\n",
            "\n",
            "        [[105, 206],\n",
            "         [307, 408]],\n",
            "\n",
            "        [[109, 210],\n",
            "         [311, 412]]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([[[1, 2],\n",
        "                   [3, 4]],\n",
        "\n",
        "                   [[5, 6],\n",
        "                    [7, 8]],\n",
        "\n",
        "                   [[9, 10],\n",
        "                    [11,12]]])\n",
        "\n",
        "b = torch.tensor([[100, 200],\n",
        "                  [300, 400]])\n",
        "\n",
        "print(a+b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGqxMMsQq-xe",
        "outputId": "fbe78d00-968b-4a6b-e7cd-3cdb89ac7b70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[101, 102],\n",
            "         [303, 304]],\n",
            "\n",
            "        [[105, 106],\n",
            "         [307, 308]],\n",
            "\n",
            "        [[109, 110],\n",
            "         [311, 312]]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([[[1, 2],\n",
        "                   [3, 4]],\n",
        "\n",
        "                   [[5, 6],\n",
        "                    [7, 8]],\n",
        "\n",
        "                   [[9, 10],\n",
        "                    [11,12]]])\n",
        "\n",
        "b = torch.tensor([[100],\n",
        "                  [300]])\n",
        "\n",
        "print(a+b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeahm4PHrL1V"
      },
      "source": [
        "# 파이토치의 여러 함수들"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtG63ItWNcT8"
      },
      "source": [
        "## expand\n",
        "설정한 차원의 방향으로 텐서를 복사하면서 확장합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ3fo8drtYrg",
        "outputId": "c1d09f27-28a5-4578-a4ed-b9b578fc3512"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 1, 2])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[[1, 2]],\n",
        "                  [[3, 4]]])\n",
        "\n",
        "print(x.size()) # x.shape과 같다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aWWInTYNWoz",
        "outputId": "b8884b45-d8a8-42af-80b3-ef9ffb0909b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[1, 2],\n",
            "         [1, 2],\n",
            "         [1, 2]],\n",
            "\n",
            "        [[3, 4],\n",
            "         [3, 4],\n",
            "         [3, 4]]])\n",
            "torch.Size([2, 3, 2])\n"
          ]
        }
      ],
      "source": [
        "y = x.expand(2, 3, 2)\n",
        "print(y)\n",
        "print(y.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QohfmYw8NoXb",
        "outputId": "6e1b532b-a501-4954-c293-f9a937740146"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[1, 2],\n",
            "         [1, 2],\n",
            "         [1, 2]],\n",
            "\n",
            "        [[3, 4],\n",
            "         [3, 4],\n",
            "         [3, 4]]])\n",
            "torch.Size([2, 3, 2])\n"
          ]
        }
      ],
      "source": [
        "# 위의 expand를 cat으로 구현해 보기\n",
        "z = torch.cat([x, x, x], dim=1)\n",
        "print(z)\n",
        "print(z.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BqHivFPNsGj"
      },
      "source": [
        "## randperm\n",
        "설정한 숫자만큼의 무작위 순열을 만들어 냅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHUdqNSJONuC",
        "outputId": "799e7f59-91a0-4b24-d889-79fc876c6399"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 3, 4, 5, 2, 8, 0, 6, 7, 9])\n",
            "torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randperm(10)\n",
        "\n",
        "print(x)\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkejm3fWOQ9D"
      },
      "source": [
        "## argmax\n",
        "설정한 차원에서 가장 큰 값이 들어있는 인덱스를 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9CQ3ekZOdKS",
        "outputId": "8975b0db-57b5-463d-aaf2-e2e01694f9fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ 5, 18,  6],\n",
            "         [12, 16,  3],\n",
            "         [ 1, 24,  8]],\n",
            "\n",
            "        [[23, 20,  7],\n",
            "         [10,  9, 26],\n",
            "         [19, 11, 13]],\n",
            "\n",
            "        [[25, 21,  0],\n",
            "         [14, 15, 22],\n",
            "         [ 4, 17,  2]]])\n",
            "torch.Size([3, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randperm(3**3).reshape(3, 3, -1)\n",
        "\n",
        "print(x)\n",
        "print(x.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQUmQisrOiEa",
        "outputId": "209dd29d-5ed4-4032-ccd1-548d1b1b03fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 1, 1],\n",
            "        [0, 2, 0],\n",
            "        [0, 2, 1]])\n",
            "torch.Size([3, 3])\n"
          ]
        }
      ],
      "source": [
        "# -1번 방향(스칼라 축)에서 가장 큰 값의 인덱스를 추출하기\n",
        "y = x.argmax(dim=-1)\n",
        "\n",
        "print(y)\n",
        "print(y.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCtX15FPOsy6",
        "outputId": "096a9743-49e0-4112-b17b-89a9ee3beb72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2, 2],\n",
            "        [0, 0, 1],\n",
            "        [0, 0, 1]])\n",
            "torch.Size([3, 3])\n"
          ]
        }
      ],
      "source": [
        "# 1번 방향에서 가장 큰 값의 인덱스를 추출하기\n",
        "z = x.argmax(dim=1)\n",
        "\n",
        "print(z)\n",
        "print(z.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fy46YB4NOy1C"
      },
      "source": [
        "## topk\n",
        "가장 큰 k개의 값과, 그 값의 인덱스를 튜플 형식으로 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiwXLm3mTXCv",
        "outputId": "b23e4817-df75-4f84-902b-052ac685cba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[18],\n",
            "         [16],\n",
            "         [24]],\n",
            "\n",
            "        [[23],\n",
            "         [26],\n",
            "         [19]],\n",
            "\n",
            "        [[25],\n",
            "         [22],\n",
            "         [17]]])\n",
            "torch.Size([3, 3, 1])\n"
          ]
        }
      ],
      "source": [
        "values, indices = torch.topk(x, k=1, dim=-1)\n",
        "\n",
        "print(values)\n",
        "print(values.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKJW0L-xTbyI",
        "outputId": "cc578ede-c69e-4629-868b-91bf1106135f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[1],\n",
            "         [1],\n",
            "         [1]],\n",
            "\n",
            "        [[0],\n",
            "         [2],\n",
            "         [0]],\n",
            "\n",
            "        [[0],\n",
            "         [2],\n",
            "         [1]]])\n",
            "torch.Size([3, 3, 1])\n"
          ]
        }
      ],
      "source": [
        "print(indices)\n",
        "print(indices.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWMrToz3TgUQ"
      },
      "source": [
        "### topk를 이용해 정렬하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATSupkY1VvmA",
        "outputId": "5e2b26ba-c695-44b3-e8fa-717c17e1ab47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[18,  6,  5],\n",
            "         [16, 12,  3],\n",
            "         [24,  8,  1]],\n",
            "\n",
            "        [[23, 20,  7],\n",
            "         [26, 10,  9],\n",
            "         [19, 13, 11]],\n",
            "\n",
            "        [[25, 21,  0],\n",
            "         [22, 15, 14],\n",
            "         [17,  4,  2]]])\n"
          ]
        }
      ],
      "source": [
        "target_dim = -1\n",
        "values, indices = torch.topk(\n",
        "    x,\n",
        "    k=x.size(target_dim),\n",
        "    largest=True # 큰 것 부터 뽑아내기, 즉 내림차순 정렬, False로 하면 작은 것 부터 뽑아내기 때문에 오름차순이 된다.\n",
        ")\n",
        "\n",
        "print(values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrWxeTK-V3YP"
      },
      "source": [
        "### sort를 이용해 topk 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsSQQPNeWBHA",
        "outputId": "3c8e8eb8-86cd-4b54-ebba-924863c42cc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[18],\n",
            "         [16],\n",
            "         [24]],\n",
            "\n",
            "        [[23],\n",
            "         [26],\n",
            "         [19]],\n",
            "\n",
            "        [[25],\n",
            "         [22],\n",
            "         [17]]])\n"
          ]
        }
      ],
      "source": [
        "k = 1\n",
        "values, indices = torch.sort(x, dim=-1, descending=True)\n",
        "values, indices = values[:, :, :k], indices[:, :, k]\n",
        "\n",
        "print(values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ge9yHv_xWKUP"
      },
      "source": [
        "## squeeze, unsqueeze\n",
        "\n",
        "- squeeze : 개수가 하나인 차원을 삭제합니다.\n",
        "- unsqueeze : 원하는 곳에 하나의 차원을 추가합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8130AJ7DWdee",
        "outputId": "f5efe780-4cb2-4981-cd79-363fc73753a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[1, 2],\n",
            "         [3, 4]]])\n",
            "torch.Size([1, 2, 2])\n"
          ]
        }
      ],
      "source": [
        "# squeeze\n",
        "x = torch.tensor([[[1, 2],\n",
        "                   [3, 4]]])\n",
        "\n",
        "print(x)\n",
        "print(x.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6re6PTdcXmgm",
        "outputId": "c4cb8778-df16-4c35-8e19-63bffaa1a28e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "torch.Size([2, 2])\n"
          ]
        }
      ],
      "source": [
        "print(x.squeeze())\n",
        "print(x.squeeze().shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qErrAVxAXwVG",
        "outputId": "a8826cea-0b77-4d2a-aa5d-d12ebcf03dd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "torch.Size([2, 2])\n"
          ]
        }
      ],
      "source": [
        "print(x.squeeze(0))\n",
        "print(x.squeeze(0).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDQIS2dUX1nO",
        "outputId": "a938b680-d9d5-4b44-e9ff-0e13bd6bbdad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[1, 2],\n",
            "         [3, 4]]])\n",
            "torch.Size([1, 2, 2])\n"
          ]
        }
      ],
      "source": [
        "print(x.squeeze(1))\n",
        "print(x.squeeze(1).shape) # 인덱스 1번 위치에는 element가 2개 이므로 squeeze가 일어나지 않는다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjTWjCPiX3Zd",
        "outputId": "1f17f07d-278b-4eed-b4b4-62e087d7bc8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "torch.Size([2, 2])\n"
          ]
        }
      ],
      "source": [
        "# unsqueeze\n",
        "x = torch.tensor([[1, 2],\n",
        "                  [3, 4]])\n",
        "\n",
        "print(x)\n",
        "print(x.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VEplhL7YJvO",
        "outputId": "32321c1e-17c7-44a6-9c70-8b50e7417941"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[1, 2],\n",
            "         [3, 4]]])\n",
            "torch.Size([1, 2, 2])\n"
          ]
        }
      ],
      "source": [
        "print(x.unsqueeze(0))\n",
        "print(x.unsqueeze(0).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEbRlAIaYOk-",
        "outputId": "becef1c4-7ef2-4598-e767-807140ca3fc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[1, 2]],\n",
            "\n",
            "        [[3, 4]]])\n",
            "torch.Size([2, 1, 2])\n"
          ]
        }
      ],
      "source": [
        "print(x.unsqueeze(1))\n",
        "print(x.unsqueeze(1).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3Ii7lflJrQh"
      },
      "source": [
        "# 자동 미분\n",
        "- PyTorch에서는 텐서를 연산한 후 해당 연산에 대한 미분을 자동으로 수행하는 기능을 제공합니다.\n",
        "- 이 기능에 의해 딥러닝이 가능하게 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XqsdA7BMFt7"
      },
      "source": [
        "## backward 사용하기\n",
        "- 역전파(backaward)를 하기 위해 미분을 하는 과정입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "aWgcu6d8JsnX",
        "outputId": "2304380e-1153-4fef-ff9d-b1ac1a120c90"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Only Tensors of floating point and complex dtype can require gradients",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[73], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# requires_grad=True 옵션을 이용해 텐서의 기울기를 구할 수 있도록 합니다. 즉 미분이 됩니다.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 텐서의 숫자는 반드시 정수가 아닌 \"실수\"여야 합니다.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(x)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 아래 에러는 의도한 에러임\u001b[39;00m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Only Tensors of floating point and complex dtype can require gradients"
          ]
        }
      ],
      "source": [
        "# requires_grad=True 옵션을 이용해 텐서의 기울기를 구할 수 있도록 합니다. 즉 미분이 됩니다.\n",
        "x = torch.tensor([1], requires_grad=True) # 텐서의 숫자는 반드시 정수가 아닌 \"실수\"여야 합니다.\n",
        "print(x)\n",
        "\n",
        "# 아래 에러는 의도한 에러임"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 위 에러는 파이토치(PyTorch)에서 requires_grad=True 옵션을 사용하는 텐서가 실수형 또는 복소수형 데이터 타입을 가져야 한다는 것을 알려주는 에러입니다. \n",
        "# 파이토치에서 자동 미분 기능은 주로 실수와 복소수와 같은 연속적인 데이터 타입에 대해 작동하기 때문에, 정수형 텐서에는 미분을 적용할 수 없습니다.\n",
        "# 정수는 불연속적인 값이기 때문에, **기울기(gradient)**를 구하는 것이 의미가 없습니다. \n",
        "# 따라서, requires_grad=True를 설정할 수 있는 텐서는 실수형 또는 복소수형이어야 합니다.\n",
        "\n",
        "# 왜 실수형이어야 할까?\n",
        "\n",
        "# 기울기(gradient)는 연속적인 함수에서 변화율을 의미하며, 이는 함수의 기울기를 나타냅니다. \n",
        "# 예를 들어, 미분을 통해 함수의 기울기를 구하면, 그 함수가 어떻게 변하는지 알 수 있습니다. \n",
        "# 그러나 정수형 값은 불연속적이기 때문에, 기울기 개념이 의미가 없습니다.\n",
        "\n",
        "# 예를 들어, 다음과 같은 함수에서 미분을 생각해 봅시다:\n",
        "# 𝑓(𝑥)=𝑥**2 \n",
        "# 이 함수는 연속적이므로 실수 값에서 미분이 가능합니다.\n",
        "# 하지만 정수형 값은 불연속적이므로 미분할 수 없습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZW2G-iyKppt",
        "outputId": "5aaefcb2-de9c-4d40-d381-0f8652f556fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1.], requires_grad=True)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJnY6CDyKxdx",
        "outputId": "f0c94974-e05f-4125-c627-19e511116a1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.], grad_fn=<PowBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# 텐서 x 제곱하여 y 텐서 생성\n",
        "y = x**2\n",
        "print(y) # PowBackward0 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "# grad_fn=<PowBackward0>는 파이토치(PyTorch)에서 자동 미분(Autograd) 시스템이 활성화되었음을 나타내며, 텐서 y가 어떤 연산의 결과로 생성되었는지를 추적합니다. \n",
        "# 구체적으로, PowBackward0는 거듭제곱 연산(즉, ** 연산자)의 기울기(gradient)를 계산할 때 사용되는 함수입니다.\n",
        "\n",
        "# 자세한 설명:\n",
        "\n",
        "        # requires_grad=True 설정:\n",
        "\n",
        "    # 텐서 x에 requires_grad=True를 설정하면, 파이토치의 자동 미분 시스템이 그 텐서에서 발생하는 모든 연산을 추적합니다.\n",
        "    # 이때 x로부터 파생되는 새로운 텐서들도 자동으로 그 연산의 그래프 정보를 저장하게 됩니다.\n",
        "\n",
        "        # y = x**2:\n",
        "\n",
        "    # 여기서 y는 x의 거듭제곱 연산을 통해 생성된 텐서입니다.\n",
        "    # 이때 파이토치는 내부적으로 연산 그래프를 구축하여, 이 텐서가 어떻게 생성되었는지를 추적합니다.\n",
        "    # y는 연산 x**2의 결과로 생성되었으며, 이 연산이 역전파(backpropagation) 과정에서 사용되도록 기록됩니다.\n",
        "\n",
        "        # grad_fn 속성:\n",
        "\n",
        "    # y는 연산의 결과로 생성된 텐서이기 때문에, 자동으로 grad_fn 속성을 가지게 됩니다.\n",
        "    # grad_fn은 이 텐서가 어떤 연산의 결과로 나왔는지를 설명하는 정보입니다.\n",
        "    # 구체적으로, grad_fn=<PowBackward0>는 y가 거듭제곱 연산(**2)을 통해 생성되었음을 나타내며, 나중에 역전파할 때 이 정보를 바탕으로 기울기를 계산합니다.\n",
        "\n",
        "# PowBackward0의 의미:\n",
        "\n",
        "# PowBackward0는 텐서가 **거듭제곱 연산(x ** 2)**을 통해 생성되었음을 나타냅니다.\n",
        "# PowBackward0는 역전파 과정에서 이 거듭제곱 연산의 기울기를 계산하는 함수입니다. \n",
        "# 즉, y.backward()가 호출되면, 이 PowBackward0 함수가 기울기를 계산하는 데 사용됩니다.\n",
        "\n",
        "# 요약:\n",
        "\n",
        "# **grad_fn=<PowBackward0>**는 해당 텐서가 거듭제곱 연산(**)의 결과로 생성되었음을 나타내며, \n",
        "# 역전파(backpropagation) 시 이 연산에 대한 기울기를 계산하는 함수가 등록되었음을 의미합니다.\n",
        "\n",
        "# 자동 미분 기능이 활성화되었기 때문에, requires_grad=True로 설정된 텐서에서 발생한 연산들은 모두 추적되고, 역전파 과정에서 사용될 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCKY_3D1LG7e"
      },
      "source": [
        "$x^2$를 미분하여 도함수를 구하면 $2x$가 됩니다. 이를 파이토치에서는 `backward()` 함수로 구해낼 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMhH1AcELXny",
        "outputId": "b6a69378-8b9e-4784-de53-0ae070f584d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "미분 수행 전 :  None\n",
            "미분 수행 후 :  tensor([2.])\n"
          ]
        }
      ],
      "source": [
        "print(\"미분 수행 전 : \", x.grad)\n",
        "y.backward() # 미분 수행\n",
        "print(\"미분 수행 후 : \", x.grad)  # y=x^2을 미분한 2x의 x값에 1을 대입한 기울기 값. 즉 x=1일 때 x^2의 기울기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> 미분 수행 전: \n",
        "\n",
        "아직 미분을 수행하지 않았으므로 x.grad 값은 None입니다.\n",
        "\n",
        "> 미분 수행 후: \n",
        "\n",
        "y.backward()를 호출한 후, 파이토치의 자동 미분 시스템이 𝑦=𝑥**2을 𝑥에 대해 미분하여 2x라는 결과를 계산하고, x = 1일 때의 기울기 2가 x.grad에 저장됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W77iALhjLlfi"
      },
      "source": [
        "## 예시 1 - 중간 미분\n",
        "- 일반적으로 제일 마지막 연산 과정의 미분만을 수행합니다.\n",
        "  - 이 때 제일 마지막 연산 과정에 의해 등장한 텐서를 `Leaf Tensor`라고 합니다.\n",
        "  - Leaf Tensor로 부터 Root Tensor의 미분 값만 확인할 수 있습니다.\n",
        "- 하지만 중간 과정을 담당하는 텐서의 미분을 직접 수행하기 위해서는 `retain_grad()`를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25Za-8IQMO8R",
        "outputId": "52694470-97ca-4c4e-f9ab-364263615f37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.], grad_fn=<PowBackward0>)\n",
            "tensor([3.], grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1.], requires_grad=True)\n",
        "y=x**2\n",
        "print(y)\n",
        "\n",
        "z=3*y\n",
        "print(z) # MulBackward0 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "buPZar41MW3w",
        "outputId": "2ff32cd9-9df8-403a-e4d2-4d3e66de06be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "z 미분 결과 :  tensor([6.])\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[80], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m z\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz 미분 결과 : \u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m.\u001b[39mgrad)\n\u001b[0;32m----> 5\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# y에 대한 미분은 사용 불가. 중간 연산 과정에 대한 미분은 따로 설정이 필요함. 또한 z.grad에 의해 이미 도함수는 모든 연산 과정에서 구해진 상태!\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my 미분 결과 : \u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m.\u001b[39mgrad)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 아래의 에러는 의도한 에러: retain_grad를 설명하기 위함\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/ml-env/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/ml-env/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
          ]
        }
      ],
      "source": [
        "# 미분 수행 1. 제일 마지막 연산인 z 부터 미분\n",
        "z.backward()\n",
        "print(\"z 미분 결과 : \", x.grad)\n",
        "\n",
        "y.backward() # y에 대한 미분은 사용 불가. 중간 연산 과정에 대한 미분은 따로 설정이 필요함. 또한 z.grad에 의해 이미 도함수는 모든 연산 과정에서 구해진 상태!\n",
        "print(\"y 미분 결과 : \", x.grad)\n",
        "\n",
        "# 아래의 에러는 의도한 에러: retain_grad를 설명하기 위함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MuwuG1lM2iT",
        "outputId": "a673b59e-e74e-479d-e3fc-57465eb5ca67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.], grad_fn=<PowBackward0>)\n",
            "tensor([3.], grad_fn=<MulBackward0>)\n",
            "z에 대한 x의 변화량 tensor([6.])\n",
            "z에 대한 y의 변화량 tensor([3.])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1.], requires_grad=True)\n",
        "y=x**2\n",
        "print(y)\n",
        "y.retain_grad() # 중간 연산 과정 텐서의 미분을 보기 위함.\n",
        "\n",
        "z=3*y\n",
        "print(z)\n",
        "\n",
        "z.backward()\n",
        "print(\"z에 대한 x의 변화량\", x.grad)\n",
        "print(\"z에 대한 y의 변화량\", y.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOG40FS8NvRm"
      },
      "source": [
        "항상 제일 마지막 연산에서 `backward()`를 수행해야 하는건 아닙니다. 원하는 위치에서 미분을 할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uObzq5_qOS3-",
        "outputId": "44828ee5-3a71-4050-febb-598feff7ef9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y에 대한 x의 변화량 :  tensor([2.])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1.], requires_grad=True)\n",
        "y = x ** 2\n",
        "z = 3 * y\n",
        "\n",
        "y.backward() # y에서부터 미분을 수행.\n",
        "print(\"y에 대한 x의 변화량 : \", x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LYhyI8RQLj-"
      },
      "source": [
        "## 예시 2 - 편미분"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7qwNc8AO4ob",
        "outputId": "c966d7d3-32b8-4e95-8298-f8a5a1538207"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([3.], grad_fn=<AddBackward0>)\n",
            "x의 변화량 :  tensor([4.])\n",
            "y의 변화량 :  tensor([2.])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1.], requires_grad=True)\n",
        "y = torch.tensor([1.], requires_grad=True)\n",
        "\n",
        "z = 2*x**2 + y**2\n",
        "print(z)\n",
        "\n",
        "z.backward()\n",
        "\n",
        "print(\"x의 변화량 : \", x.grad)\n",
        "print(\"y의 변화량 : \", y.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye2xbRi4X3yj"
      },
      "source": [
        "## 예시 3 - 스칼라를 벡터로 미분"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhm_BctfYTZ6",
        "outputId": "a27aca0e-2f2e-4069-e225-9ebc91224182"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(14., grad_fn=<SumBackward0>)\n",
            "tensor([2., 4., 6.])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1., 2., 3.], requires_grad=True)\n",
        "y = torch.sum(x ** 2) # x1**2 + x2**2 + x3**2\n",
        "y.backward()\n",
        "\n",
        "print(y)\n",
        "print(x.grad) # 스칼라를 벡터로 미분"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y0P0Ke-YiQV"
      },
      "source": [
        "## 예시 4 - 미분 중간 취소\n",
        "- 텐서를 미분 가능한 상태에서 미분이 불가능한 상태로 만듭니다 연산 중간에 `requires_grade=False`로 설정하는 것이 가능합니다.\n",
        "- 보통 전이학습에서 사용되는 기법입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lbHjomPY3U1",
        "outputId": "5726dd14-e9d5-495c-cdb0-7f0546d3cbfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.])\n",
            "tensor([1.])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1.], requires_grad=True)\n",
        "x.requires_grad = False\n",
        "\n",
        "print(x)\n",
        "# 전이 학습(Transfer Learning)\n",
        "y = x**2\n",
        "print(y)\n",
        "# Error!!!\n",
        "# y.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjmqkfUbZBeh",
        "outputId": "c390a1aa-bc4e-42a4-8740-293a3be1f53d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2.])\n",
            "tensor([4.])\n"
          ]
        }
      ],
      "source": [
        "# 또는 detach()를 사용합니다.\n",
        "x = torch.tensor([2.], requires_grad=True)\n",
        "x = x.detach()\n",
        "\n",
        "print(x)\n",
        "y = x**2\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F0MsaxIZ0D4",
        "outputId": "d7376119-6cb7-4f17-abb0-2d1410f1b6f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "tensor([4.])\n",
            "True\n",
            "tensor([4.], grad_fn=<PowBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# torch.no_grad\n",
        "x = torch.tensor([2.], requires_grad=True)\n",
        "\n",
        "# requires_grad=False 없이 with 구문 내에서만 잠깐 미분을 하지 않도록 설정할 수 있게\n",
        "with torch.no_grad():\n",
        "    y = x**2\n",
        "    print(x.requires_grad)\n",
        "    print(y)\n",
        "\n",
        "print(x.requires_grad)\n",
        "y=x**2\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VX7bH23ha6Dc"
      },
      "source": [
        "# Torcchviz를 이용한 미분 과정 시각화.\n",
        "- 실제 딥러닝을 훈련하는 과정을 시각화 하기 위한 툴들이 많이 있습니다.\n",
        "- Torchviz는 그냥 장난감 같은 패키지 이므로, 참고만 해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDYv9geLabtf",
        "outputId": "4f92416e-fc31-4583-a724-8269b314e068"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchviz in /Users/khb43/anaconda3/envs/ml-env/lib/python3.8/site-packages (0.0.2)\n",
            "Requirement already satisfied: torch in /Users/khb43/anaconda3/envs/ml-env/lib/python3.8/site-packages (from torchviz) (2.0.1)\n",
            "Requirement already satisfied: graphviz in /Users/khb43/anaconda3/envs/ml-env/lib/python3.8/site-packages (from torchviz) (0.20.3)\n",
            "Requirement already satisfied: filelock in /Users/khb43/anaconda3/envs/ml-env/lib/python3.8/site-packages (from torch->torchviz) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /Users/khb43/anaconda3/envs/ml-env/lib/python3.8/site-packages (from torch->torchviz) (4.5.0)\n",
            "Requirement already satisfied: sympy in /Users/khb43/anaconda3/envs/ml-env/lib/python3.8/site-packages (from torch->torchviz) (1.13.2)\n",
            "Requirement already satisfied: networkx in /Users/khb43/anaconda3/envs/ml-env/lib/python3.8/site-packages (from torch->torchviz) (3.1)\n",
            "Requirement already satisfied: jinja2 in /Users/khb43/anaconda3/envs/ml-env/lib/python3.8/site-packages (from torch->torchviz) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/khb43/anaconda3/envs/ml-env/lib/python3.8/site-packages (from jinja2->torch->torchviz) (2.1.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/khb43/anaconda3/envs/ml-env/lib/python3.8/site-packages (from sympy->torch->torchviz) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "## torchviz를 이용한 미분 과정 시각화\n",
        "!pip install torchviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "F2a_GvXTa4_J",
        "outputId": "a5b9cc0b-db92-4381-9350-22ab12596458"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": [
              "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
              "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
              " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
              "<!-- Generated by graphviz version 12.0.0 (20240704.0754)\n",
              " -->\n",
              "<!-- Pages: 1 -->\n",
              "<svg width=\"108pt\" height=\"337pt\"\n",
              " viewBox=\"0.00 0.00 108.00 336.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
              "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 332.5)\">\n",
              "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-332.5 104,-332.5 104,4 -4,4\"/>\n",
              "<!-- 6268571872 -->\n",
              "<g id=\"node1\" class=\"node\">\n",
              "<title>6268571872</title>\n",
              "<polygon fill=\"#caff70\" stroke=\"black\" points=\"77,-32.75 23,-32.75 23,0 77,0 77,-32.75\"/>\n",
              "<text text-anchor=\"middle\" x=\"50\" y=\"-7.25\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
              "</g>\n",
              "<!-- 6242178432 -->\n",
              "<g id=\"node2\" class=\"node\">\n",
              "<title>6242178432</title>\n",
              "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"94,-89.5 6,-89.5 6,-68.75 94,-68.75 94,-89.5\"/>\n",
              "<text text-anchor=\"middle\" x=\"50\" y=\"-76\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n",
              "</g>\n",
              "<!-- 6242178432&#45;&gt;6268571872 -->\n",
              "<g id=\"edge5\" class=\"edge\">\n",
              "<title>6242178432&#45;&gt;6268571872</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M50,-68.36C50,-61.89 50,-53.05 50,-44.55\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-44.55 50,-34.55 46.5,-44.55 53.5,-44.55\"/>\n",
              "</g>\n",
              "<!-- 6242178528 -->\n",
              "<g id=\"node3\" class=\"node\">\n",
              "<title>6242178528</title>\n",
              "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"94,-146.25 6,-146.25 6,-125.5 94,-125.5 94,-146.25\"/>\n",
              "<text text-anchor=\"middle\" x=\"50\" y=\"-132.75\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
              "</g>\n",
              "<!-- 6242178528&#45;&gt;6242178432 -->\n",
              "<g id=\"edge1\" class=\"edge\">\n",
              "<title>6242178528&#45;&gt;6242178432</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M50,-125.09C50,-118.47 50,-109.47 50,-101.27\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-101.34 50,-91.34 46.5,-101.34 53.5,-101.34\"/>\n",
              "</g>\n",
              "<!-- 6242178288 -->\n",
              "<g id=\"node4\" class=\"node\">\n",
              "<title>6242178288</title>\n",
              "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"94,-203 6,-203 6,-182.25 94,-182.25 94,-203\"/>\n",
              "<text text-anchor=\"middle\" x=\"50\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n",
              "</g>\n",
              "<!-- 6242178288&#45;&gt;6242178528 -->\n",
              "<g id=\"edge2\" class=\"edge\">\n",
              "<title>6242178288&#45;&gt;6242178528</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M50,-181.84C50,-175.22 50,-166.22 50,-158.02\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-158.09 50,-148.09 46.5,-158.09 53.5,-158.09\"/>\n",
              "</g>\n",
              "<!-- 6242178576 -->\n",
              "<g id=\"node5\" class=\"node\">\n",
              "<title>6242178576</title>\n",
              "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"100,-259.75 0,-259.75 0,-239 100,-239 100,-259.75\"/>\n",
              "<text text-anchor=\"middle\" x=\"50\" y=\"-246.25\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
              "</g>\n",
              "<!-- 6242178576&#45;&gt;6242178288 -->\n",
              "<g id=\"edge3\" class=\"edge\">\n",
              "<title>6242178576&#45;&gt;6242178288</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M50,-238.59C50,-231.97 50,-222.97 50,-214.77\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-214.84 50,-204.84 46.5,-214.84 53.5,-214.84\"/>\n",
              "</g>\n",
              "<!-- 6252477472 -->\n",
              "<g id=\"node6\" class=\"node\">\n",
              "<title>6252477472</title>\n",
              "<polygon fill=\"lightblue\" stroke=\"black\" points=\"77,-328.5 23,-328.5 23,-295.75 77,-295.75 77,-328.5\"/>\n",
              "<text text-anchor=\"middle\" x=\"50\" y=\"-303\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n",
              "</g>\n",
              "<!-- 6252477472&#45;&gt;6242178576 -->\n",
              "<g id=\"edge4\" class=\"edge\">\n",
              "<title>6252477472&#45;&gt;6242178576</title>\n",
              "<path fill=\"none\" stroke=\"black\" d=\"M50,-295.48C50,-288.1 50,-279.18 50,-271.24\"/>\n",
              "<polygon fill=\"black\" stroke=\"black\" points=\"53.5,-271.41 50,-261.41 46.5,-271.41 53.5,-271.41\"/>\n",
              "</g>\n",
              "</g>\n",
              "</svg>\n"
            ],
            "text/plain": [
              "<graphviz.graphs.Digraph at 0x1741014c0>"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchviz import make_dot\n",
        "x = torch.tensor([1.], requires_grad=True)\n",
        "\n",
        "make_dot((x**2 + 1)**2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
