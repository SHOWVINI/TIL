{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\", # 데이터를 저장할 root 디렉토리\n",
    "    train=True, # 훈련용 데이터 설정\n",
    "    download=True, # 다운로드\n",
    "    transform=ToTensor() # 이미지 변환. 여기서는 TorchTesnor로 변환시킵니다.\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_dataloader  = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # nn.Sequential을 이용해 연속되는 레이어의 구조를 구성\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        y = self.linear_relu_stack(x)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model running on: mps\n",
      "==========================================================================\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# MPS 지원 여부 확인\n",
    "if torch.backends.mps.is_available():\n",
    "    device = 'mps'  # MPS 사용\n",
    "elif torch.cuda.is_available():\n",
    "    device = 'cuda'  # CUDA 사용 가능 시\n",
    "else:\n",
    "    device = 'cpu'  # 그 외에는 CPU 사용\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(f\"Model running on: {device}\")\n",
    "\n",
    "print(\"==========================================================================\")\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위 코드까지는 모두 03. PyTorch Modeling ⭐️(240923) 내용에서 배운 코드\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 훈련\n",
    "\n",
    "파이토치의 모델 훈련을 위해서는 손실함수, 최적화 함수를 등록해야 합니다. 특히 최적화 함수를 사용하기 위해서는 `model.parameters()` 메소드를 이용해 최적화 대상 파라미터를 지정해주면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 짱짱 중요함\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer : 경사하강법을 수행하기 위한 함수. 경사하강법은 어디에 수행해? W, b -> parameters\n",
    "# model에서 파라미터를 꺼내다가 최적화 함수에 등록\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 과정(훈련 루프 정의)\n",
    "#  1. dataloader에서 데이터를 꺼낸다.\n",
    "#  2. 데이터를 모델에 통과시킨다. (순전파를 통한 추론 - prediction(inference))\n",
    "#  3. 얻어낸 예측값을 이용해서 loss를 계산\n",
    "#  4. 역전파를 통한 미분값을 계산\n",
    "#  5. 얻어낸 미분 값으로 경사하강법을 수행(최적화)\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    # 데이터 로더에 있는 데이터 세트의 길이 가져오기\n",
    "    size = len(dataloader.dataset)\n",
    "    # 중요! model을 훈련 모드로 설정. ⭐️\n",
    "    model.train()\n",
    "\n",
    "    # 데이터 꺼내기. for문을 사용하면 자동으로 next(iter(dataloader))가 실행 된다.\n",
    "    for  batch, (X, y) in enumerate(dataloader):\n",
    "        # 현재 데이터 로더에 있는 데이터는 cpu에 존재하고 있기 때문에 이 데이터들을 gpu로 옮긴다.\n",
    "        #   모델이 위치한 곳과 데이터가 위치한 곳을 동일하게 맞춰준다.\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 순전파 수행\n",
    "        pred = model(X)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = loss_fn(pred, y) # 자동으로 소프트맥스가 적용됨.\n",
    "\n",
    "        # 역전파 수행(미분값 얻어내기)\n",
    "        optimizer.zero_grad() # 기존에 남아있던 기울기를 제거( 이전 배치의 기울기가 남아있으면 정확한 기울기를 구해내기가 힘들어요)\n",
    "        loss.backward() # 역전파. loss가 Leaf\n",
    "        optimizer.step() # 구한 미분값을 토대로 최적화를 수행(경사하강법)\n",
    "\n",
    "        # 배치가 100번 돌 때마다 화면에 출력\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"Train Loss : {loss:>7f} [ {current:>5d} / {size:>5d} ]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론을 위한 테스트 과정(테스트 루프) 정의\n",
    "# 1. 테스트 데이터 로더에서 데이터 꺼내기\n",
    "# 2. 데이터를 모델에 통과(순전파)시켜서 예측값 얻어내기\n",
    "# 3. 성능(metric) 계산. \n",
    "    # - Loss, Accuracy 계산\n",
    "    # - 배치 별 평균 성능 계산\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # 중요! 평가모드(추론모드) 설정\n",
    "    model.eval()\n",
    "\n",
    "    # 추론 과정은 기울기를 구할 필요가 없어요\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "\n",
    "            # 모델과 데이터는 항상 같은 환경에서 사용되어야 한다.\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # 예측\n",
    "            pred = model(X)\n",
    "\n",
    "            # Loss 계산\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "            # 맞춘거 개수 합치기\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    # 배치 개수 구하기\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    # 배치 별 loss, accuracy의 평균 구하기\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "\n",
    "    print(f\"Test Error : \\n Accuracy : {(100*correct):>0.1f}%, Avg Loss : {test_loss:>8f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 1\n",
      "-------------------------------------------\n",
      "Train Loss : 2.327557 [     0 / 60000 ]\n",
      "Train Loss : 1.475532 [  6400 / 60000 ]\n",
      "Train Loss : 0.959251 [ 12800 / 60000 ]\n",
      "Train Loss : 0.864645 [ 19200 / 60000 ]\n",
      "Train Loss : 0.917247 [ 25600 / 60000 ]\n",
      "Train Loss : 0.727044 [ 32000 / 60000 ]\n",
      "Train Loss : 0.748282 [ 38400 / 60000 ]\n",
      "Train Loss : 0.684356 [ 44800 / 60000 ]\n",
      "Train Loss : 0.817204 [ 51200 / 60000 ]\n",
      "Train Loss : 0.661446 [ 57600 / 60000 ]\n",
      "Test Error : \n",
      " Accuracy : 78.1%, Avg Loss : 0.653175\n",
      "\n",
      "Epochs 2\n",
      "-------------------------------------------\n",
      "Train Loss : 0.693672 [     0 / 60000 ]\n",
      "Train Loss : 0.684818 [  6400 / 60000 ]\n",
      "Train Loss : 0.785157 [ 12800 / 60000 ]\n",
      "Train Loss : 0.639671 [ 19200 / 60000 ]\n",
      "Train Loss : 0.789536 [ 25600 / 60000 ]\n",
      "Train Loss : 0.525099 [ 32000 / 60000 ]\n",
      "Train Loss : 0.581941 [ 38400 / 60000 ]\n",
      "Train Loss : 0.540539 [ 44800 / 60000 ]\n",
      "Train Loss : 0.629552 [ 51200 / 60000 ]\n",
      "Train Loss : 0.676652 [ 57600 / 60000 ]\n",
      "Test Error : \n",
      " Accuracy : 80.9%, Avg Loss : 0.552657\n",
      "\n",
      "Epochs 3\n",
      "-------------------------------------------\n",
      "Train Loss : 0.593938 [     0 / 60000 ]\n",
      "Train Loss : 0.631554 [  6400 / 60000 ]\n",
      "Train Loss : 0.531406 [ 12800 / 60000 ]\n",
      "Train Loss : 0.533367 [ 19200 / 60000 ]\n",
      "Train Loss : 0.564645 [ 25600 / 60000 ]\n",
      "Train Loss : 0.344503 [ 32000 / 60000 ]\n",
      "Train Loss : 0.458828 [ 38400 / 60000 ]\n",
      "Train Loss : 0.601293 [ 44800 / 60000 ]\n",
      "Train Loss : 0.448898 [ 51200 / 60000 ]\n",
      "Train Loss : 1.007072 [ 57600 / 60000 ]\n",
      "Test Error : \n",
      " Accuracy : 82.5%, Avg Loss : 0.510383\n",
      "\n",
      "Epochs 4\n",
      "-------------------------------------------\n",
      "Train Loss : 0.542532 [     0 / 60000 ]\n",
      "Train Loss : 0.518331 [  6400 / 60000 ]\n",
      "Train Loss : 0.502425 [ 12800 / 60000 ]\n",
      "Train Loss : 0.310850 [ 19200 / 60000 ]\n",
      "Train Loss : 0.404814 [ 25600 / 60000 ]\n",
      "Train Loss : 0.570816 [ 32000 / 60000 ]\n",
      "Train Loss : 0.975966 [ 38400 / 60000 ]\n",
      "Train Loss : 0.464084 [ 44800 / 60000 ]\n",
      "Train Loss : 0.492164 [ 51200 / 60000 ]\n",
      "Train Loss : 0.409925 [ 57600 / 60000 ]\n",
      "Test Error : \n",
      " Accuracy : 83.3%, Avg Loss : 0.483722\n",
      "\n",
      "Epochs 5\n",
      "-------------------------------------------\n",
      "Train Loss : 0.515938 [     0 / 60000 ]\n",
      "Train Loss : 0.545891 [  6400 / 60000 ]\n",
      "Train Loss : 0.483325 [ 12800 / 60000 ]\n",
      "Train Loss : 0.355481 [ 19200 / 60000 ]\n",
      "Train Loss : 0.472774 [ 25600 / 60000 ]\n",
      "Train Loss : 0.360622 [ 32000 / 60000 ]\n",
      "Train Loss : 0.629766 [ 38400 / 60000 ]\n",
      "Train Loss : 0.556370 [ 44800 / 60000 ]\n",
      "Train Loss : 0.341288 [ 51200 / 60000 ]\n",
      "Train Loss : 0.360048 [ 57600 / 60000 ]\n",
      "Test Error : \n",
      " Accuracy : 83.9%, Avg Loss : 0.462446\n",
      "\n",
      "Epochs 6\n",
      "-------------------------------------------\n",
      "Train Loss : 0.354617 [     0 / 60000 ]\n",
      "Train Loss : 0.716172 [  6400 / 60000 ]\n",
      "Train Loss : 0.436709 [ 12800 / 60000 ]\n",
      "Train Loss : 0.362609 [ 19200 / 60000 ]\n",
      "Train Loss : 0.546441 [ 25600 / 60000 ]\n",
      "Train Loss : 0.392426 [ 32000 / 60000 ]\n",
      "Train Loss : 0.449287 [ 38400 / 60000 ]\n",
      "Train Loss : 0.420256 [ 44800 / 60000 ]\n",
      "Train Loss : 0.425242 [ 51200 / 60000 ]\n",
      "Train Loss : 0.417906 [ 57600 / 60000 ]\n",
      "Test Error : \n",
      " Accuracy : 84.3%, Avg Loss : 0.447076\n",
      "\n",
      "Epochs 7\n",
      "-------------------------------------------\n",
      "Train Loss : 0.286688 [     0 / 60000 ]\n",
      "Train Loss : 0.519653 [  6400 / 60000 ]\n",
      "Train Loss : 0.347317 [ 12800 / 60000 ]\n",
      "Train Loss : 0.271860 [ 19200 / 60000 ]\n",
      "Train Loss : 0.502299 [ 25600 / 60000 ]\n",
      "Train Loss : 0.304479 [ 32000 / 60000 ]\n",
      "Train Loss : 0.369527 [ 38400 / 60000 ]\n",
      "Train Loss : 0.369377 [ 44800 / 60000 ]\n",
      "Train Loss : 0.447218 [ 51200 / 60000 ]\n",
      "Train Loss : 0.481436 [ 57600 / 60000 ]\n",
      "Test Error : \n",
      " Accuracy : 84.6%, Avg Loss : 0.434315\n",
      "\n",
      "Epochs 8\n",
      "-------------------------------------------\n",
      "Train Loss : 0.334602 [     0 / 60000 ]\n",
      "Train Loss : 0.356023 [  6400 / 60000 ]\n",
      "Train Loss : 0.593819 [ 12800 / 60000 ]\n",
      "Train Loss : 0.304136 [ 19200 / 60000 ]\n",
      "Train Loss : 0.481894 [ 25600 / 60000 ]\n",
      "Train Loss : 0.486034 [ 32000 / 60000 ]\n",
      "Train Loss : 0.398222 [ 38400 / 60000 ]\n",
      "Train Loss : 0.254574 [ 44800 / 60000 ]\n",
      "Train Loss : 0.325828 [ 51200 / 60000 ]\n",
      "Train Loss : 0.361732 [ 57600 / 60000 ]\n",
      "Test Error : \n",
      " Accuracy : 85.1%, Avg Loss : 0.425452\n",
      "\n",
      "Epochs 9\n",
      "-------------------------------------------\n",
      "Train Loss : 0.332403 [     0 / 60000 ]\n",
      "Train Loss : 0.669142 [  6400 / 60000 ]\n",
      "Train Loss : 0.556977 [ 12800 / 60000 ]\n",
      "Train Loss : 0.449648 [ 19200 / 60000 ]\n",
      "Train Loss : 0.177484 [ 25600 / 60000 ]\n",
      "Train Loss : 0.369353 [ 32000 / 60000 ]\n",
      "Train Loss : 0.424436 [ 38400 / 60000 ]\n",
      "Train Loss : 0.365252 [ 44800 / 60000 ]\n",
      "Train Loss : 0.613959 [ 51200 / 60000 ]\n",
      "Train Loss : 0.368061 [ 57600 / 60000 ]\n",
      "Test Error : \n",
      " Accuracy : 85.1%, Avg Loss : 0.418998\n",
      "\n",
      "Epochs 10\n",
      "-------------------------------------------\n",
      "Train Loss : 0.414199 [     0 / 60000 ]\n",
      "Train Loss : 0.414404 [  6400 / 60000 ]\n",
      "Train Loss : 0.408864 [ 12800 / 60000 ]\n",
      "Train Loss : 0.384606 [ 19200 / 60000 ]\n",
      "Train Loss : 0.529584 [ 25600 / 60000 ]\n",
      "Train Loss : 0.493101 [ 32000 / 60000 ]\n",
      "Train Loss : 0.343639 [ 38400 / 60000 ]\n",
      "Train Loss : 0.270614 [ 44800 / 60000 ]\n",
      "Train Loss : 0.489248 [ 51200 / 60000 ]\n",
      "Train Loss : 0.419380 [ 57600 / 60000 ]\n",
      "Test Error : \n",
      " Accuracy : 85.4%, Avg Loss : 0.408174\n",
      "\n",
      "Done!!!\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(f\"Epochs {i + 1}\\n-------------------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "\n",
    "print(\"Done!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
